{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Water Body Polygons\n",
    "\n",
    "**What does this notebook do?** This notebook uses output `NetCDF` files of WOFS summaries from `datacube-stats` to generate polygons of water bodies in the landscape. This code follows the following workflow:\n",
    "* Generate a list of netCDF files within a specified folder location\n",
    "* Opens each netCDF file and:\n",
    "    * Keep only pixels observed at least x times\n",
    "    * Keep only pixels identified as wet at least x% of the time\n",
    "    * Convert the raster data into polygons\n",
    "* Append the polygon set to a shapefile\n",
    "* Remove artificial polygon borders created at tile boundaries by merging polygons that intersect across Albers Tile boundaries\n",
    "* Filter the combined polygon dataset (note that this step happens after the merging of Albers tile boundary polygons to ensure that artifacts are not created by part of a polygon being filtered out, while the remainder of the polygon that sits on a separate tile is treated differently).\n",
    "    * Filter the polygons based on size\n",
    "    * Remove polygons that intersect with Australia's coastline and estuaries\n",
    "    * Remove erroneous 'water' polygons within high-rise CBD areas\n",
    "    * Optional filtering for proximity to major rivers (as identified by the Geofabric dataset)\n",
    "* Save out the final polygon set to a shapefile\n",
    "\n",
    "**Required inputs:** \n",
    "* NetCDF files with WOfS outputs that will be used to define the persistent water body polygons\n",
    "    * Variable name: `TileFolder`\n",
    "    * This folder can be either a custom extraction of datacube-stats (as was done here), or you can choose to use the WOfS summary tiles for all of Australia (see [below for further information](#Tiles)).\n",
    "* A coastline polygon to filter out polygons generated from ocean pixels.\n",
    "    * Variable name: `LandSeaMaskFile`\n",
    "    * Here we use the [GEODATA COAST 100K 2004 dataset](https://data.gov.au/dataset/geodata-coast-100k-2004)\n",
    "* Estuary data layer to supplement the coastline polygon, which does not identify estuaries as 'ocean'\n",
    "    * Variable name: `EstuariesFile`\n",
    "    * Here we generated this layer from the [OzCoasts Geomorphic habitat datasets](http://www.ozcoasts.gov.au/search_data/datasets.jsp). Each of the state datasets were downloaded, and only `channel` and `Central Basin` features were retained. These correspond to the locations of open water (including large river channels) within estuary systems (see [below for further information](#Estuaries)).\n",
    "* Urban high rise polygon dataset\n",
    "    * Variable name: `UrbanMaskFile`\n",
    "    * WOfS has a known limitation, where deep shadows thrown by tall CBD buildings are misclassified as water. This means that our algorithm is defining 'water bodies' around these misclassified shadows in capital cities. [See below](#Urban) for a discussion of how an urban mask is produced. \n",
    "    \n",
    "**Optional inputs**\n",
    "* River line dataset for filtering out polygons comprised of river segments.\n",
    "    * Variable name: `MajorRiversDataset`\n",
    "    * The option to filter out major rivers is provided, and so this dataset is optional if `FilterOutRivers = False`.\n",
    "    * Here we use the [Bureau of Meteorology's Geofabric v 3.0.5 Beta (Suface Hydrology Network)](ftp://ftp.bom.gov.au/anon/home/geofabric/), filtered to only keep features tagged as `major rivers`. \n",
    "    * There are some identified issues with this data layer that make the filtering using this data inconsistent (see [the discussion below](#rivers))\n",
    "    * We therefore turn this off during the production of the water bodies shapefile. \n",
    "    \n",
    "\n",
    "**Code history**\n",
    "\n",
    "This notebook is an updated version of `FindLotsOfDamsUsingWOFLsInaLoop.ipynb`. This copy was created to maintain the prototype workflow, while updating the operational workflow for water body polygon production.\n",
    "\n",
    "**Date:** May 2019\n",
    "\n",
    "**Author:** Claire Krause\n",
    "\n",
    "**Quality Check Performed, March 2019:** Imam Alam, Alex Vincent, Bex Dunn, Damien Ayers\n",
    "\n",
    "**DEA module and environment version used**: `/dea-env/20190329`, `/dea/20190329` (See the accompanying [GenerateWaterBodyPolygonsRequirements.txt](files/GenerateWaterBodyPolygonsRequirements.txt) for a complete list of python libraries loaded into the environment)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Tags: :index:`fiona`, :index:`geopandas`, :index:`Geotiff`, :index:`masking`, :index:`rasterio`, :index:`shapefile`, :index:`WOfS`, :index:`WOFL`, :index:`write_geotiff`, :index:`shapely`, :index:`descartes`, :index:`water_classifier_and_wofs`, :index:`raster to polygons`, :index:`polygons`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water Observations from Space inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Waterbody Area Mapping and Monitoring (WAMM) service provides insights into both the location and dynamics of water bodies across Australia. The [Water Observations from Space (WOfS) product](https://www.sciencedirect.com/science/article/pii/S0034425715301929) is used to map the locations of water bodies across Australia. The analysis was done on a per pixel basis prior to combining adjoining pixels into polygon objects (i.e. drawing a boundary around them and considering them as a single object rather than a series of individual pixels).  \n",
    "\n",
    "**Pixels were included in this analysis, where during the period from 1987 to 2018, pixels were classified as 'wet' using the WOfS product, at least 10% of the time. The rationale for these parameters are explored in detail [here](WAMMSensitivityAnalysis.ipynb), but are summarised below:**\n",
    "\n",
    "### Analysis date range\n",
    "\n",
    "All available observations were included within this analysis (1987 to 2018), with the exception of the most recent months, which were excluded to end the analysis at the end of 2018. During the analysis period, three Landsat satellites were active: Landsat 5 (2000 - 2010), Landsat 7 (2000 - present), and Landsat 8 (2013 - present). Each satellite has a return period of ~16 days. \n",
    "\n",
    "Over the 18 year analysis period, across the three satellite platforms, each pixel across Australia was observed clearly, and classified approximately 420 times (average; min = 2, max = 1328, standard deviation = 195). Differences in the number of times each pixel was observed was caused by clouds (which meant the observation was not used), \n",
    "\n",
    "### Wetness threshold\n",
    "\n",
    "\n",
    "\n",
    "### Results \n",
    "\n",
    "The WOfS statistics return three results within each NetCDF file:\n",
    "- count_wet: Number of times a pixel was validly observed as wet.\n",
    "- count_clear: Number of times a pixel was validly observed (wet + dry)\n",
    "- frequency: Frequency of a wet observation (wet / clear)\n",
    "\n",
    "The NetCDF files contain one Australian Albers tile of data each, allowing us to split up the analysis on a tile-by-tile basis, prior to combining the data across the whole study region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab notebook\n",
    "\n",
    "import rasterio.features\n",
    "from shapely.geometry import Polygon, shape, mapping\n",
    "from shapely.ops import unary_union\n",
    "import geopandas as gp\n",
    "import fiona\n",
    "from fiona.crs import from_epsg\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os.path\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the functions for this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_list_of_albers_tiles(TileFolder = 'TileFolder'):\n",
    "    '''\n",
    "    Generate a list of Albers tiles to loop through for the water body analysis. This \n",
    "    function assumes that the list of tiles will be generated from a custom \n",
    "    datacube-stats run, and the file names will have the format\n",
    "    \n",
    "    */wofs_summary_8_-37_{date}.nc\n",
    "    \n",
    "    The tile number is expected in the 2nd and 3rd last positions when the string has been\n",
    "    broken using `_`. If this is not the case, then this code will not work, and will throw an error. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    TileFolder : str\n",
    "        This is the path to the folder of netCDF files for analysis. If this is not provided, or an\n",
    "        incorrect path name is provided, the code will exit with an error.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    CustomRegionAlbersTiles: list\n",
    "        List of Albers tiles across the analysis region. \n",
    "        E.g. ['8_-32', '9_-32', '10_-32', '8_-33', '9_-33']\n",
    "    \n",
    "    '''  \n",
    "    if os.path.exists(TileFolder) == False:\n",
    "        print('** ERROR ** \\n'\n",
    "            'You need to specify a folder of files for running a custom region')\n",
    "        return\n",
    "    \n",
    "    # Grab a list of all of the netCDF files in the custom folder\n",
    "    TileFiles = glob.glob(f'{TileFolder}*.nc')\n",
    "\n",
    "    CustomRegionAlbersTiles = set()\n",
    "    for filePath in TileFiles:\n",
    "        AlbersTiles = filePath.split('_')\n",
    "        \n",
    "        # Test that the albers tile numbers are actually where we expect them to be in the file name\n",
    "        try: \n",
    "            int(AlbersTiles[-3])\n",
    "            int(AlbersTiles[-2])\n",
    "        except ValueError:\n",
    "            print('** ERROR ** \\n'\n",
    "                'The netCDF files are expected to have the file format \"*/wofs_summary_8_-37_{date}.nc\",\\n'\n",
    "                'with the Albers tile numbers in the 2nd and 3rd last positions when separated on `_`. \\n'\n",
    "                'Please fix the file names, or alter the `Generate_list_of_albers_tiles` function.')\n",
    "            return\n",
    "\n",
    "        # Now that we're happy that the file is reading the correct Albers tiles\n",
    "        ThisTile = f'{AlbersTiles[-3]}_{AlbersTiles[-2]}'\n",
    "        CustomRegionAlbersTiles.add(ThisTile)\n",
    "    CustomRegionAlbersTiles = list(CustomRegionAlbersTiles)\n",
    "    return CustomRegionAlbersTiles\n",
    "\n",
    "def Generate_list_of_tile_datasets(ListofAlbersTiles, Year, TileFolder = 'TileFolder', CustomData = True):\n",
    "    '''\n",
    "    Generate a list of Albers tiles datasets to loop through for the water body analysis. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    CustomRegionAlbersTiles: list\n",
    "        List of albers tiles to loop through\n",
    "        E.g. ['8_-32', '9_-32', '10_-32', '8_-33', '9_-33']\n",
    "    Year: int\n",
    "        Year for the analysis. This will correspond to the netCDF files for analysis.\n",
    "    TileFolder : str\n",
    "        This is the path to the folder of netCDF files for analysis. If this is not provided, or an\n",
    "        incorrect path name is provided, the code will exit with an error.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Alltilespaths: list\n",
    "        List of file paths to files to be analysed.\n",
    "    \n",
    "    '''  \n",
    "    \n",
    "    if os.path.exists(TileFolder) == False:\n",
    "        print('** ERROR ** \\n'\n",
    "            'You need to specify a folder of files for running a custom region')\n",
    "        raise\n",
    "\n",
    "    Alltilespaths = []\n",
    "    \n",
    "    if CustomData:\n",
    "        for tile in ListofAlbersTiles:\n",
    "            Tiles = glob.glob(f'{TileFolder}*_{tile}_{Year}0101.nc')\n",
    "            Alltilespaths.append(Tiles[0]) # Assumes only one file will be returned\n",
    "    else:\n",
    "        for tile in ListofAlbersTiles:\n",
    "            Tiles = glob.glob(f'{TileFolder}wofs_filtered_summary_{tile}.nc')\n",
    "            Alltilespaths.append(Tiles[0]) # Assumes only one file will be returned\n",
    " \n",
    "    return Alltilespaths\n",
    "\n",
    "def Filter_shapefile_by_intersection(gpdData, gpdFilter, filtertype = 'intersects', invertMask = True, \n",
    "                                     returnInverse = False):\n",
    "    '''\n",
    "    Filter out polygons that intersect with another polygon shapefile. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    gpdData: geopandas dataframe\n",
    "        Polygon data that you wish to filter\n",
    "    gpdFilter: geopandas dataframe\n",
    "        Dataset you are using as a filter\n",
    "    \n",
    "    Optional\n",
    "    --------\n",
    "    filtertype: default = 'intersects'\n",
    "        Options = ['intersects', 'contains', 'within']\n",
    "    invertMask: boolean\n",
    "        Default = 'True'. This determines whether you want areas that DO ( = 'False') or DON'T ( = 'True')\n",
    "        intersect with the filter shapefile.\n",
    "    returnInnverse: boolean\n",
    "        Default = 'False'. If true, then return both parts of the intersection - those that intersect AND \n",
    "        those that don't as two dataframes.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    gpdDataFiltered: geopandas dataframe\n",
    "        Filtered polygon set, with polygons that intersect with gpdFilter removed.\n",
    "    IntersectIndex: list of indices of gpdData that intersect with gpdFilter\n",
    "    \n",
    "    Optional\n",
    "    --------\n",
    "    if 'returnInverse = True'\n",
    "    gpdDataFiltered, gpdDataInverse: two geopandas dataframes\n",
    "        Filtered polygon set, with polygons that DON'T intersect with gpdFilter removed.\n",
    "    '''    \n",
    "    \n",
    "    # Check that the coordinate reference systems of both dataframes are the same\n",
    "    \n",
    "    #assert gpdData.crs == gpdFilter.crs, 'Make sure the the coordinate reference systems of the two provided dataframes are the same'\n",
    "    \n",
    "    Intersections = gp.sjoin(gpdFilter, gpdData, how=\"inner\", op=filtertype)\n",
    "    \n",
    "    # Find the index of all the polygons that intersect with the filter\n",
    "    IntersectIndex = sorted(set(Intersections['index_right']))\n",
    "    \n",
    "    # Grab only the polygons NOT in the IntersectIndex\n",
    "    # i.e. that don't intersect with a river\n",
    "    if invertMask:\n",
    "        gpdDataFiltered = gpdData.loc[~gpdData.index.isin(IntersectIndex)]\n",
    "    else:\n",
    "        gpdDataFiltered = gpdData.loc[gpdData.index.isin(IntersectIndex)]\n",
    "    \n",
    "    if returnInverse:\n",
    "        # We need to use the indices from IntersectIndex to find the inverse dataset, so we\n",
    "        # will just swap the '~'.\n",
    "        \n",
    "        if invertMask:\n",
    "            gpdDataInverse = gpdData.loc[gpdData.index.isin(IntersectIndex)]\n",
    "        else:\n",
    "            gpdDataInverse = gpdData.loc[~gpdData.index.isin(IntersectIndex)]\n",
    "            \n",
    "        return gpdDataFiltered, IntersectIndex, gpdDataInverse\n",
    "    else:    \n",
    "        \n",
    "        return gpdDataFiltered, IntersectIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up all the parameters for the script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter results based on number of valid observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of valid WOfS observations for each pixel varies depending on the frequency of clouds and cloud shadow, and the proximity to high slope and terrain shadow, and the seasonal change in solar angle. \n",
    "\n",
    "The `count_clear` parameter provides a count of the number of valid observations each pixel recorded over the analysis period. We can use this parameter to mask out pixels that were infrequently observed. If this mask is not applied, pixels that were observed only once could be included, if that observation was wet (i.e. a single wet observation means the calculation of the frequency statistic would be (1 wet observation) / (1 total observation) = 100% frequency of wet observations).\n",
    "\n",
    "Here we set the minimum number of observations to be four per year. For our 19 year analysis, this means the minimum number of valid observations is 76."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinimumValidObs = 76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How wet does a pixel need to be to be included?   ************FIX DOCO******************\n",
    "The value set here will be the minimum amount of time (as a decimal between 0 and 1) that you want water to be detected before it is included in the analysis. \n",
    "\n",
    "E.g. If this was set to 0.10, any pixels that are wet *at least* 10% of the time will be included. If you are looking for persistant water bodies, you will want to set this threshold higher. If you don't want to use this filter, set this value to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AtLeastThisWet = [0.05, 0.10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='size'></a>\n",
    "### How big/small should the polygons be?\n",
    "This filtering step can remove very small and/or very large polygons. The size listed here is in m2. A single pixel in Landsat data is 25 m X 25 m = 625 m2. \n",
    "\n",
    "**MinSize**\n",
    "\n",
    "E.g. A minimum size of 6250 means that polygons need to be at least 10 pixels to be included. If you don't want to use this filter, set this value to 0.\n",
    "\n",
    "**MaxSize**\n",
    "\n",
    "E.g. A maximum size of 1 000 000 means that you only want to consider polygons less than 1 km2. If you don't want to use this filter, set this number to something stupidly large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinSize = 3120 # 5 pixels\n",
    "MaxSize = math.inf # No upper limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rivers'></a>\n",
    "### Do you want to filter out polygons that intersect with major rivers?\n",
    "\n",
    "**Note that for the Water Body Polygon dataset, we set this filter to False (`FilterOutRivers = False`). The code has been kept here in case it's of use for further filtering of the results later on.**\n",
    "\n",
    "We use the [Bureau of Meteorology's Geofabric v 3.0.5 Beta (Suface Hydrology Network)](ftp://ftp.bom.gov.au/anon/home/geofabric/) to filter out polygons that intersect with major rivers. This is done to remove river segments from the polygon dataset. We use the `SH_Network AHGFNetworkStream any` layer within the `SH_Network_GDB_V2_1_1.zip` geodatabase, and filter the dataset to only keep rivers tagged as `major`. It is this filtered dataset we use here.\n",
    "\n",
    "Note that we reproject this dataset to `epsg 3577`, Australian Albers coordinate reference system. If this is not correct for your analysis, you can change this in the cell below.\n",
    "\n",
    "If you don't want to filter out polygons that intersect with rivers, set this parameter to `False`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note when using the Geofabric to filter out rivers\n",
    "\n",
    "The option to filter out rivers was switched off for the production of our water bodies dataset. During testing, the Geofabric dataset was shown to lead to inconsistencies in what was removed, and what remained within the dataset. \n",
    "\n",
    "* The Geofabric continues the streamline through on-river dams, which means these polygons are filtered out. This may not be the desired result. \n",
    "\n",
    "![Stream and Dam intersection](OnRiverDam.JPG \"An in-river dam that would be removed by the river filter, but may not be the desired result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FilterOutRivers = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "raw_mimetype": "text/x-python"
   },
   "outputs": [],
   "source": [
    "# Where is this file located?\n",
    "MajorRiversDataset = '/g/data/r78/cek156/ShapeFiles/Geofabric_v2_1_1/SH_Network_GDB_V2_1_1_Major_Filtered.shp'\n",
    "\n",
    "# Read in the major rivers dataset (if you are using it)\n",
    "if FilterOutRivers:\n",
    "    MajorRivers = gp.GeoDataFrame.from_file(MajorRiversDataset) \n",
    "    MajorRivers = MajorRivers.to_crs({'init':'epsg:3577'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Tiles'></a>\n",
    "### Set up the input datasets for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllOfAustraliaAllTime = False\n",
    "\n",
    "CustomData = True\n",
    "AutoGenerateTileList = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to perform the analysis for all of Australia, using the published WOfS all time summaries, set `AllofAustraliaAllTime = True`. \n",
    "(*Note there is a bug with this option at the moment - the all time summaries have different variable names than the datacube stats outputs, so this needs to be fixed*)\n",
    "\n",
    "If `CustomData = True`, you will need to specify the location of the data you would like to use for this analysis, setting `TileFolder` below, under the `if CustomData` code section below.  \n",
    "\n",
    "If `CustomData = False`, the code will automatically look at the published WOfS all time summaries. (*Note there is a bug with this option at the moment - the all time summaries have different variable names than the datacube stats outputs, so this needs to be fixed*)\n",
    "\n",
    "If you would like to automatically generate a list of tiles using the outputs of an analysis (e.g. we have previously run a custom `datacube-stats` analysis using this region, and so we can generate a list of tiles that we know covers this area using the outputs of this analysis), set `AutoGenerateTileList = True` and update the location of the output file directory.\n",
    "\n",
    "If you would like to manually feed in a list of albers tiles, set `AutoGenerateTileList = False`, and feed in a list of tiles in the format:\n",
    "\n",
    "```\n",
    "ListofAlbersTiles = ['7_-34', '10_-40', '16_-34']\n",
    "```\n",
    "<br/>    \n",
    "**NOTE** For testing and debugging, set `CustomData = True` and `AutoGenerateTileList = False`, then enter a list of tiles to run using the `ListofAlbersTiles` described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where are the files on which to perform the analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CustomData:\n",
    "    TileFolder = '/g/data/r78/cek156/datacube_stats/WOFSDamsAllTimeNSWMDB/'\n",
    "else:\n",
    "    TileFolder = '/g/data/fk4/datacube/002/WOfS/WOfS_Filt_Stats_25_2_1/netcdf/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if AutoGenerateTileList:\n",
    "    ListofAlbersTiles = Generate_list_of_albers_tiles(TileFolder)\n",
    "else:\n",
    "    ListofAlbersTiles = ['19_-40', '8_-32', '10_-30', '14_-31', '13_-31', '18_-38', '19_-33', '9_-31', '20_-34', \n",
    "                         '6_-39', '17_-31', '12_-40', '13_-39', '10_-38', '6_-41', '16_-32', '9_-40', '10_-31', \n",
    "                         '16_-37', '10_-39', '16_-35', '7_-38', '10_-37', '17_-39', '9_-34', '19_-35', '15_-33', \n",
    "                         '15_-30', '11_-32', '20_-39', '17_-30', '13_-40', '7_-41', '17_-29', '12_-33', '15_-28',\n",
    "                         '16_-40', '6_-35', '17_-40', '13_-38', '17_-42', '14_-39', '13_-29', '17_-37', '16_-38',\n",
    "                         '9_-32', '16_-34', '9_-41', '11_-31', '7_-36', '16_-39', '18_-30', '9_-37', '20_-37',\n",
    "                         '13_-32', '7_-40', '18_-41', '20_-32', '8_-41', '14_-28', '18_-39', '14_-43', '12_-39',\n",
    "                         '20_-36', '8_-34', '17_-41', '12_-41', '18_-31', '11_-38', '18_-34', '14_-35', '12_-42',\n",
    "                         '19_-39', '12_-34', '10_-42', '11_-35', '17_-35', '15_-41', '18_-33', '6_-37', '13_-41',\n",
    "                         '10_-40', '14_-33', '13_-37', '8_-36', '6_-36', '16_-43', '18_-36', '14_-40', '15_-43',\n",
    "                         '12_-30', '5_-39', '8_-39', '18_-35', '15_-39', '15_-29', '7_-34', '11_-34', '14_-41',\n",
    "                         '15_-42', '16_-29', '16_-28', '14_-37', '8_-33', '6_-38', '19_-38', '13_-33', '16_-36',\n",
    "                         '15_-37', '12_-38', '7_-35', '18_-40', '12_-31', '16_-41', '14_-38', '19_-37', '10_-34',\n",
    "                         '14_-32', '12_-32', '14_-42', '15_-35', '16_-31', '19_-36', '7_-37', '11_-41', '14_-36',\n",
    "                         '13_-35', '16_-42', '13_-36', '6_-40', '17_-36', '10_-41', '18_-37', '14_-29', '14_-30',\n",
    "                         '20_-38', '17_-38', '12_-36', '10_-35', '9_-42', '21_-33', '12_-37', '17_-32', '15_-31',\n",
    "                         '10_-36', '15_-36', '19_-34', '17_-34', '12_-35', '20_-40', '20_-33', '19_-31', '20_-35',\n",
    "                         '16_-30', '18_-32', '12_-29', '11_-30', '15_-32', '16_-33', '8_-37', '10_-33', '13_-34', \n",
    "                         '11_-33', '13_-30', '11_-36', '8_-40', '11_-40', '10_-32', '9_-38', '11_-42', '11_-39',\n",
    "                         '15_-34', '21_-34', '13_-42', '9_-35', '8_-42', '17_-33', '8_-38', '13_-28', '15_-38',\n",
    "                         '9_-36', '8_-35', '11_-37', '14_-34', '15_-40', '9_-33', '19_-32', '9_-39', '7_-39']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='coastline'></a>\n",
    "### Set up a land/sea mask\n",
    "\n",
    "Use the [GEODATA COAST 100K 2004 dataset](https://data.gov.au/dataset/geodata-coast-100k-2004) as a coarse approximation of the mean high water coastline to remove ocean from water layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='dddb8016-2718-4d0e-9a65-53cbf729e403'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6fcba7b588>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LandSeaMaskFile = '/g/data/r78/rt1527/datasets/Coastlines/australia/cstauscd_r.shp'\n",
    "\n",
    "Coastline = gp.read_file(LandSeaMaskFile)\n",
    "Coastline = Coastline.to_crs({'init': 'epsg:3577'})\n",
    "Coastline = Coastline[(Coastline.FEAT_CODE == 'island') | (Coastline.FEAT_CODE == 'mainland')]\n",
    "Coastline.plot(figsize=(5, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Estuaries'></a>\n",
    "\n",
    "### Estuaries need to be handled separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An estuary data layer was generated from the [OzCoasts Geomorphic habitat datasets](http://www.ozcoasts.gov.au/search_data/datasets.jsp). Each of the state datasets were downloaded, and only `channel` and `Central Basin` features were retained. These correspond to the locations of open water (including large river channels) within estuary systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EstuariesFile = '/g/data/r78/cek156/ShapeFiles/OzCoastsCoastalWaterwaysGeomorphicHabitatMapping/Aus_geohab_av.shp'\n",
    "\n",
    "Estuaries = gp.read_file(EstuariesFile)\n",
    "Estuaries = Estuaries.to_crs({'init': 'epsg:3577'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Urban'></a>\n",
    "\n",
    "### Read in a mask for high-rise CBDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOfS has a known limitation, where deep shadows thrown by tall CBD buildings are misclassified as water. This means that our algorithm is defining 'water bodies' around these misclassified shadows in capital cities. \n",
    "\n",
    "To address this problem, we use the [Australian Bureau of Statistics Statistical Area 3 shapefile (2016)](http://www.abs.gov.au/AUSSTATS/abs@.nsf/DetailsPage/1270.0.55.001July%202016?OpenDocument#Data) to define a spatial footprint for Australia's CBD areas. \n",
    "\n",
    "We use the following polygons as our CBD filter:\n",
    "\n",
    "|SA3_CODE1|SA3_NAME16|\n",
    "|---------|----------|\n",
    "|11703    |Sydney Inner City|\n",
    "|20604    |Melbourne City|\n",
    "|30501    |Brisbane Inner|\n",
    "|30901    |Broadbeach - Burleigh|\n",
    "|30910    |Surfers Paradise|\n",
    "|40101    |Adelaide City|\n",
    "|50302    |Perth City|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "UrbanMaskFile = '/g/data/r78/cek156/ShapeFiles/ABS_1270055001_sa3_2016_aust_shape/HighRiseCBD_ABS_sa3.shp'\n",
    "\n",
    "CBDs = gp.read_file(UrbanMaskFile)\n",
    "CBDs = CBDs.to_crs({'init': 'epsg:3577'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through each tile and polygonise the annual WOfS data\n",
    "\n",
    "Within this cell, you need to set up:\n",
    "- years to analyse: `for year in range(2000,2019)` - note that the last year is NOT included in the analysis\n",
    "- WaterBodiesShp: The name and filepath of the intermediate output polygon set\n",
    "- WOFSshpMerged: The name and filepath of the final corrected output polygon set\n",
    "- AlbersBuffer: The file location of a shapefile that is a 1 pixel buffer around the Albers tile boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up some file names for the inputs and outputs\n",
    "\n",
    "# The name and filepath of the intermediate output polygon set\n",
    "WaterBodiesShp = f'/g/data/r78/cek156/dea-notebooks/WaterbodyAreaMappingandMonitoring/MDBANSWAllTime01-005HybridWaterbodies/Temp'\n",
    "# Set up an empty list for the dynamic file names to be written in to. This will let us call these\n",
    "# files again fpr subsequent steps.\n",
    "FileNames = []\n",
    "\n",
    "# The name and filepath of the final corrected output polygon set\n",
    "WOFSshpMerged = f'/g/data/r78/cek156/dea-notebooks/WaterbodyAreaMappingandMonitoring/MDBANSWAllTime01-005HybridWaterbodies/NSWMDBWaterBodies.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Does the analysis a year at a time. If there is a singple year only, set the year range to be \n",
    "# `range(year, year + 1)`\n",
    "\n",
    "for year in range(2000,2001):\n",
    "    \n",
    "    ### Get the list of netcdf file names to loop through\n",
    "    if AllOfAustraliaAllTime:\n",
    "        # Grab everything from the published WOfS all time summaries\n",
    "        Alltiles = glob.glob(f'{TileFolder}/')\n",
    "    else:\n",
    "        Alltiles = Generate_list_of_tile_datasets(ListofAlbersTiles, year, TileFolder, CustomData)            \n",
    "        \n",
    "    for WOFSfile in Alltiles: \n",
    "        try:\n",
    "            # Read in the data\n",
    "            # Note that the netCDF files we are using here contain a variable called 'frequency',\n",
    "            # which is what we are using to define our water polygons.\n",
    "            # If you use a different netCDF input source, you may need to change this variable name here\n",
    "            WOFSnetCDFData = xr.open_rasterio(f'NETCDF:{WOFSfile}:frequency')\n",
    "            # Remove the superfluous time dimension\n",
    "            WOFSnetCDFData = WOFSnetCDFData.squeeze()\n",
    "            \n",
    "            # Open the clear count variable to generate the minimum observation mask\n",
    "            WOFSvalidcount = xr.open_rasterio(f'NETCDF:{WOFSfile}:count_clear')\n",
    "            WOFSvalidcount = WOFSvalidcount.squeeze()\n",
    "\n",
    "            # Filter our WOfS classified data layer to remove noise\n",
    "            # Remove any pixels not abserved at least MinimumValidObs times\n",
    "            WOFSValidFiltered = WOFSvalidcount >= MinimumValidObs\n",
    "            \n",
    "            for Thresholds in AtLeastThisWet:\n",
    "                # Remove any pixels that are wet < AtLeastThisWet% of the time\n",
    "                WOFSfiltered = WOFSnetCDFData > Thresholds\n",
    "\n",
    "                # Now find pixels that meet both the MinimumValidObs and AtLeastThisWet criteria\n",
    "                # Change all zeros to NaN to create a nan/1 mask layer\n",
    "                # Pixels == 1 now represent our water bodies\n",
    "                WOFSfiltered = WOFSfiltered.where((WOFSfiltered !=0) & (WOFSValidFiltered !=0))\n",
    "\n",
    "                # Convert the raster to polygons\n",
    "                # We use a mask of '1' to only generate polygons around values of '1' (not NaNs)\n",
    "                WOFSpolygons = rasterio.features.shapes(WOFSfiltered.data.astype('float32'), \n",
    "                                                        mask = WOFSfiltered.data.astype('float32') == 1,\n",
    "                                                        transform = WOFSnetCDFData.transform)\n",
    "                # The rasterio.features.shapes returns a tuple. We only want to keep the geometry portion,\n",
    "                # not the value of each polygon (which here is just 1 for everything)\n",
    "                WOFSbreaktuple = (a for a, b in WOFSpolygons)\n",
    "\n",
    "                # Put our polygons into a geopandas geodataframe\n",
    "                PolygonGP = gp.GeoDataFrame(list(WOFSbreaktuple))\n",
    "\n",
    "                # Grab the geometries and convert into a shapely geometry\n",
    "                # so we can quickly calcuate the area of each polygon\n",
    "                PolygonGP['geometry'] = None\n",
    "                for ix, poly in PolygonGP.iterrows():\n",
    "                    poly['geometry'] = shape(poly)\n",
    "\n",
    "                # Set the geometry of the dataframe to be the shapely geometry we just created    \n",
    "                PolygonGP = PolygonGP.set_geometry('geometry')\n",
    "                # We need to add the crs back onto the dataframe\n",
    "                PolygonGP.crs = {'init': 'epsg:3577'}\n",
    "\n",
    "                # Combine any overlapping polygons\n",
    "                MergedPolygonsGeoms = unary_union(PolygonGP['geometry'])\n",
    "\n",
    "                # Turn the combined multipolygon back into a geodataframe\n",
    "                MergedPolygonsGPD = gp.GeoDataFrame([poly for poly in MergedPolygonsGeoms])\n",
    "                # Rename the geometry column\n",
    "                MergedPolygonsGPD.columns = ['geometry']\n",
    "                # We need to add the crs back onto the dataframe\n",
    "                MergedPolygonsGPD.crs = {'init': 'epsg:3577'}\n",
    "\n",
    "                # Calculate the area of each polygon again now that overlapping polygons\n",
    "                # have been merged\n",
    "                MergedPolygonsGPD['area'] = MergedPolygonsGPD['geometry'].area\n",
    "\n",
    "                # Save the polygons to a shapefile\n",
    "                schema = {'geometry': 'Polygon','properties': {'area': 'str'}}\n",
    "                \n",
    "                # Generate our dynamic filename\n",
    "                FileName = f'{WaterBodiesShp}_{Thresholds}.shp'\n",
    "                # Append the file name to the list so we can call it later on\n",
    "                FileNames.append(FileName)\n",
    "\n",
    "                if os.path.isfile(FileName):\n",
    "                    with fiona.open(FileName, \"a\", crs = from_epsg(3577), \n",
    "                                    driver = 'ESRI Shapefile', schema = schema) as output:\n",
    "                        for ix, poly in MergedPolygonsGPD.iterrows():\n",
    "                                        output.write(({'properties': {'area': poly['area']},\n",
    "                                                       'geometry': mapping(shape(poly['geometry']))})) \n",
    "                else:\n",
    "                    with fiona.open(FileName, \"w\", crs = from_epsg(3577), \n",
    "                                    driver = 'ESRI Shapefile', schema = schema) as output:\n",
    "                        for ix, poly in MergedPolygonsGPD.iterrows():\n",
    "                            output.write(({'properties': {'area': poly['area']},\n",
    "                                           'geometry': mapping(shape(poly['geometry']))}))\n",
    "\n",
    "        except:\n",
    "            print(f'There is something wrong with {WOFSfile}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge polygons between thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge polygons that have an edge at a tile boundary\n",
    "\n",
    "Now that we have all of the polygons across our whole region of interest, we need to check for artifacts in the data caused by tile boundaries. \n",
    "\n",
    "Load in a shapefile of the albers tile boundaries we have created a shapefile that consists of the albers tile boundaries, plus a 1 pixel (25 m) buffer. This shapefile will help us to find any polygons that have a\n",
    "boundary at the edge of an albers tile. We can then find where polygons touch across this boundary, and join them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlbersBuffer = gp.read_file(\n",
    "    '/g/data/r78/cek156/ShapeFiles/AlbersBuffer25m.shp')\n",
    "\n",
    "# We are using the more severe wetness threshold as the main polygon dataset.\n",
    "WaterPolygons = gp.read_file(FileNames[-1])\n",
    "\n",
    "# Find where the albers polygon overlaps with our dam polygons\n",
    "BoundaryMergedDams, IntersectIndexes, NotBoundaryDams= Filter_shapefile_by_intersection(WaterPolygons, AlbersBuffer, \n",
    "                                                                      invertMask=False, \n",
    "                                                                      returnInverse=True)\n",
    "\n",
    "# Now combine overlapping polygons in `BoundaryDams`\n",
    "UnionBoundaryDams = BoundaryMergedDams.unary_union\n",
    "\n",
    "# `Explode` the multipolygon back out into individual polygons\n",
    "UnionGDF = gp.GeoDataFrame(crs=WaterPolygons.crs, geometry=[UnionBoundaryDams])\n",
    "MergedDams = UnionGDF.explode()\n",
    "\n",
    "# Then combine our new merged polygons with the `NotBoundaryDams`\n",
    "# Combine New merged polygons with the remaining polygons that are not near the tile boundary\n",
    "AllTogether = gp.GeoDataFrame(pd.concat([NotBoundaryDams, MergedDams],\n",
    "                                        ignore_index=True, sort=True)).set_geometry('geometry')\n",
    "\n",
    "# Calculate the area of each polygon\n",
    "AllTogether['area'] = AllTogether.area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the combined polygons by:\n",
    "- **Area:**\n",
    "Based on the `MinSize` and `MaxSize` parameters set [here](#size).\n",
    "- **Coastline:**\n",
    "Using the `Coastline` dataset loaded [here](#coastline).\n",
    "- **Estuaries:**\n",
    "Using the `Estuaries` dataset loaded [here](#Estuaries).\n",
    "- **CBD location:**\n",
    "Using the `CBDs` dataset loaded [here](#Urban)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/dea-env/20190329/lib/python3.6/site-packages/geopandas/tools/sjoin.py:44: UserWarning: CRS of frames being joined does not match!\n",
      "  warn('CRS of frames being joined does not match!')\n"
     ]
    }
   ],
   "source": [
    "# Filter out any polygons smaller than MinSize, and greater than MaxSize\n",
    "WaterBodiesBig = AllTogether.loc[((AllTogether['area'] > MinSize) & (AllTogether['area'] <= MaxSize))]\n",
    "\n",
    "# Filter out any ocean in the pixel\n",
    "WaterBodiesLand, IntersectIndexes = Filter_shapefile_by_intersection(WaterBodiesBig, Coastline, \n",
    "                                                   invertMask = False)\n",
    "\n",
    "# Filter out the estuaries\n",
    "WaterBodiesNotEstuaries, IntersectIndexes = Filter_shapefile_by_intersection(WaterBodiesLand, Estuaries)\n",
    "\n",
    "# WOfS has a known bug where deep shadows from high-rise CBD buildings are misclassified\n",
    "# as water. We will use the ABS sa3 dataset to filter out Brisbane, Gold Coast, Sydney, \n",
    "# Melbourne, Adelaide and Perth CBDs. \n",
    "NotCities, IntersectIndexes = Filter_shapefile_by_intersection(WaterBodiesNotEstuaries, CBDs)\n",
    "\n",
    "# Hybrid thresholds\n",
    "WaterPolygons005 = gp.read_file('/g/data/r78/cek156/dea-notebooks/Dams/Dams2000to2018NSWMDB/Temp_0.05.shp')\n",
    "# Find where the albers polygon overlaps with our dam polygons\n",
    "BoundaryMergedDams, IntersectIndexes = Filter_shapefile_by_intersection(WaterPolygons005,\n",
    "                                                                        NotCities)\n",
    "\n",
    "WaterPolygons005ToUse = WaterPolygons005.loc[WaterPolygons005.index.isin(IntersectIndexes)]\n",
    "\n",
    "CombinedPolygons = gp.GeoDataFrame(pd.concat([WaterPolygons005ToUse, NotCities], ignore_index=True))\n",
    "CombinedPolygonsUnion = CombinedPolygons.unary_union\n",
    "\n",
    "# `Explode` the multipolygon back out into individual polygons\n",
    "UnionGDF = gp.GeoDataFrame(crs=WaterPolygons005.crs, geometry=[CombinedPolygonsUnion])\n",
    "HybridDams = UnionGDF.explode()\n",
    "\n",
    "# Here is where we do the river filtering (if FilterOutRivers == True)\n",
    "if FilterOutRivers:\n",
    "    WaterBodiesBigRiverFiltered, IntersectIndexes = Filter_shapefile_by_intersection(HybridDams, MajorRivers)\n",
    "else:\n",
    "    # If river filtering is turned off, then we just keep all the same polygons\n",
    "    WaterBodiesBigRiverFiltered = HybridDams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out the final results to a shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "WaterBodiesBigRiverFiltered.crs = {'init': 'epsg:3577'}\n",
    "WaterBodiesBigRiverFiltered.to_file(WOFSshpMerged, driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
