{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAHTS stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "\n",
    "First we import the required Python packages, then we connect to the database, and load the catalog of virtual products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext line_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import deacoastlines_statistics as dcl_stats\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "from rasterio.transform import array_bounds\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "sys.path.append('../Scripts')\n",
    "from dea_spatialtools import subpixel_contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in contours\n",
    "study_area = 7832\n",
    "output_name = 'multi'\n",
    "water_index = 'mndwi'\n",
    "index_threshold = 0.00\n",
    "baseline_year = '2018'\n",
    "\n",
    "# Create output folder\n",
    "output_dir = f'output_data/{output_name}_{study_area}/vectors'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(f'{output_dir}/shapefiles', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DEA CoastLines rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_ds = dcl_stats.load_rasters(output_name, study_area, water_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load external data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bounding box to load data for\n",
    "bbox = gpd.GeoSeries(box(*array_bounds(height=yearly_ds.sizes['y'], \n",
    "                                       width=yearly_ds.sizes['x'], \n",
    "                                       transform=yearly_ds.transform)), \n",
    "                     crs=yearly_ds.crs)\n",
    "\n",
    "# Estaury mask\n",
    "estuary_gdf = (gpd.read_file('input_data/estuary_mask.shp', bbox=bbox)\n",
    "               .to_crs(yearly_ds.crs))\n",
    "\n",
    "# Rocky shore mask\n",
    "smartline_gdf = (gpd.read_file('input_data/Smartline.gdb', bbox=bbox)\n",
    "                 .to_crs(yearly_ds.crs))\n",
    "\n",
    "# Tide points\n",
    "points_gdf = (gpd.read_file('input_data/tide_points_coastal.geojson', bbox=bbox)\n",
    "          .to_crs(yearly_ds.crs))\n",
    "\n",
    "# Study area polygon\n",
    "comp_gdf = (gpd.read_file('input_data/50km_albers_grid.shp', bbox=bbox)\n",
    "            .set_index('id')\n",
    "            .to_crs(str(yearly_ds.crs)))\n",
    "\n",
    "# Mask to study area\n",
    "study_area_poly = comp_gdf.loc[study_area]\n",
    "\n",
    "# Load climate indices\n",
    "climate_df = pd.read_csv('input_data/climate_indices.csv', index_col='year')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract shoreline contours\n",
    "\n",
    "### Extract ocean-masked contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating in single z-value, multiple arrays mode\n"
     ]
    }
   ],
   "source": [
    "# Mask dataset to focus on coastal zone only\n",
    "masked_ds = dcl_stats.contours_preprocess(yearly_ds, \n",
    "                                          water_index, \n",
    "                                          index_threshold, \n",
    "                                          estuary_gdf, \n",
    "                                          points_gdf)\n",
    "\n",
    "# Extract contours\n",
    "contours_gdf = subpixel_contours(da=masked_ds,\n",
    "                                 z_values=index_threshold,\n",
    "                                 min_vertices=10,\n",
    "                                 dim='year').set_index('year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute statistics\n",
    "### Measure distances from baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract statistics modelling points along baseline contour\n",
    "points_gdf = dcl_stats.stats_points(contours_gdf, baseline_year, distance=30)\n",
    "\n",
    "# Make a copy of the points GeoDataFrame to hold tidal data\n",
    "tide_points_gdf = points_gdf.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute annual coastline movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\r"
     ]
    }
   ],
   "source": [
    "# Calculate annual movements and residual tide heights for every contour\n",
    "# compared to the baseline year\n",
    "points_gdf, tide_points_gdf = dcl_stats.annual_movements(yearly_ds, \n",
    "                                                         points_gdf, \n",
    "                                                         tide_points_gdf, \n",
    "                                                         contours_gdf, \n",
    "                                                         baseline_year,\n",
    "                                                         water_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing annual movements with time\n",
      "Comparing annual movements with tide heights\n",
      "Comparing annual movements with SOI\n",
      "Comparing annual movements with IOD\n",
      "Comparing annual movements with SAM\n",
      "Comparing annual movements with IPO\n",
      "Comparing annual movements with PDO\n"
     ]
    }
   ],
   "source": [
    "points_gdf = dcl_stats.calculate_regressions(yearly_ds, \n",
    "                                             points_gdf, \n",
    "                                             tide_points_gdf, \n",
    "                                             climate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/g/data1a/r78/rt1527/dea-notebooks/MAHTS/output_data/outputs_7832_multi.zip'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract a 50 m buffer around rocky shore features which is used to clip stats\n",
    "rocky_shore_buffer = dcl_stats.rocky_shores_buffer(smartline_gdf=smartline_gdf, buffer=50)\n",
    "\n",
    "# Clip stats to study area extent, remove rocky shores and export to GeoJSON\n",
    "stats_path = f'{output_dir}/stats_{study_area}_{output_name}_{water_index}_{index_threshold:.2f}'\n",
    "points_gdf = points_gdf[points_gdf.intersects(study_area_poly['geometry'])]\n",
    "points_gdf = points_gdf[~points_gdf.intersects(rocky_shore_buffer.geometry.unary_union)]\n",
    "points_gdf.to_file(f'{stats_path}.geojson', driver='GeoJSON')\n",
    "\n",
    "# Clip annual shoreline contours to study area extent and export to GeoJSON\n",
    "contour_path = f'{output_dir}/contours_{study_area}_{output_name}_{water_index}_{index_threshold:.2f}'\n",
    "contours_gdf['geometry'] = contours_gdf.intersection(study_area_poly['geometry'])\n",
    "contours_gdf.reset_index().to_file(f'{contour_path}.geojson', driver='GeoJSON')\n",
    "\n",
    "# Export stats and contours as ESRI shapefiles\n",
    "contour_path = contour_path.replace('vectors', 'vectors/shapefiles')\n",
    "stats_path = stats_path.replace('vectors', 'vectors/shapefiles')\n",
    "contours_gdf.to_file(f'{contour_path}.shp')\n",
    "points_gdf.to_file(f'{stats_path}.shp')\n",
    "\n",
    "# Create a zip file containing all vector files\n",
    "shutil.make_archive(base_name=f'output_data/outputs_{study_area}_{output_name}', \n",
    "                    format='zip', \n",
    "                    root_dir=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** March 2020"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
