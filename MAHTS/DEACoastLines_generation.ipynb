{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAHTS generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "* Take full time series of NDWI in dask\n",
    "* Compute 2D tides for every timestep\n",
    "* Compute median of tides from entire tide timeseries\n",
    "* For each year in dask NDWI timeseries:\n",
    "    * Mask pixels where tide > overall median\n",
    "    * `.compute()` and take median \n",
    "    \n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "\n",
    "First we import the required Python packages, then we connect to the database, and load the catalog of virtual products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/dea-env/20200313/lib/python3.6/site-packages/distributed/dashboard/core.py:79: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:40051</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:42795/status' target='_blank'>http://127.0.0.1:42795/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>30.67 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:40051' processes=1 threads=8, memory=30.67 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext line_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import deacoastlines_generation as dcl_gen\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datacube\n",
    "import geopandas as gpd\n",
    "from functools import partial\n",
    "\n",
    "sys.path.append('../Scripts')\n",
    "from dea_plotting import display_map\n",
    "\n",
    "dc = datacube.Datacube(app='MAHTS_testing', env='c3-samples')\n",
    "\n",
    "from datacube.utils.dask import start_local_dask\n",
    "client = start_local_dask(mem_safety_margin='3gb')\n",
    "display(client)\n",
    "\n",
    "import datetime\n",
    "start_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load supplementary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tide points are used to model tides across the extent of the satellite data\n",
    "points_gdf = gpd.read_file('input_data/tide_points_coastal.geojson')\n",
    "\n",
    "# Albers grid cells used to process the analysis\n",
    "gridcell_gdf = (gpd.read_file('input_data/50km_albers_grid_clipped.shp')\n",
    "            .to_crs(epsg=4326)\n",
    "            .set_index('id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "### Create query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7fa684c92240>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_area = 5898\n",
    "output_name = 'test'\n",
    "\n",
    "# If output folder doesn't exist, create it\n",
    "output_dir = f'output_data/{study_area}_{output_name}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "study_area_geopoly = dcl_gen.get_geopoly(study_area, gridcell_gdf)\n",
    "query = {'geopolygon': study_area_geopoly,\n",
    "         'time': ('2019', '2019'),\n",
    "         'cloud_cover': [0, 90],\n",
    "         'dask_chunks': {'time': 1, 'x': 1000, 'y': 1000}}\n",
    "\n",
    "# Preview study area\n",
    "display_map(x=(query['geopolygon'].envelope.left, \n",
    "               query['geopolygon'].envelope.right), \n",
    "            y=(query['geopolygon'].envelope.top, \n",
    "               query['geopolygon'].envelope.bottom))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load virtual product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n",
      "    ga_ls7e_ard_3\n",
      "    ga_ls8c_ard_3\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 21 time steps as a dask array\n",
      "Dropping bands ['nbar_blue', 'nbar_green', 'nbar_red', 'nbar_nir', 'nbar_swir_1', 'nbar_swir_2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:  (time: 21, x: 1741, y: 1166)\n",
       "Coordinates:\n",
       "  * x        (x) float64 4.538e+05 4.538e+05 4.538e+05 ... 5.059e+05 5.06e+05\n",
       "  * time     (time) datetime64[ns] 2019-01-01T00:21:52.187764 ... 2019-08-05T00:09:38.063853\n",
       "  * y        (y) float64 -4.189e+06 -4.189e+06 ... -4.224e+06 -4.224e+06\n",
       "Data variables:\n",
       "    mndwi    (time, y, x) float32 dask.array&lt;chunksize=(1, 1000, 1000), meta=np.ndarray&gt;\n",
       "Attributes:\n",
       "    crs:      epsg:32654</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 21, x: 1741, y: 1166)\n",
       "Coordinates:\n",
       "  * x        (x) float64 4.538e+05 4.538e+05 4.538e+05 ... 5.059e+05 5.06e+05\n",
       "  * time     (time) datetime64[ns] 2019-01-01T00:21:52.187764 ... 2019-08-05T00:09:38.063853\n",
       "  * y        (y) float64 -4.189e+06 -4.189e+06 ... -4.224e+06 -4.224e+06\n",
       "Data variables:\n",
       "    mndwi    (time, y, x) float32 dask.array<chunksize=(1, 1000, 1000), meta=np.ndarray>\n",
       "Attributes:\n",
       "    crs:      epsg:32654"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load virtual product    \n",
    "ds = dcl_gen.load_mndwi(dc, \n",
    "                        query, \n",
    "                        yaml_path='deacoastlines_virtual_products.yaml',\n",
    "                        virtual_products=False)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidal modelling\n",
    "### Model tides at point locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidepoints_gdf = dcl_gen.model_tides(ds, points_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate tides into each satellite timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallelising 7 processes\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import xarray as xr\n",
    "\n",
    "pool = multiprocessing.Pool(multiprocessing.cpu_count() - 1)\n",
    "print(f'Parallelising {multiprocessing.cpu_count() - 1} processes')\n",
    "out_list = pool.map(partial(dcl_gen.interpolate_tide,\n",
    "                      tidepoints_gdf=tidepoints_gdf,\n",
    "                      factor=50, dask=False), \n",
    "                    iterable=[(group.x.values, \n",
    "                               group.y.values, \n",
    "                               group.time.values) \n",
    "                              for (i, group) in ds.groupby('time')])\n",
    "\n",
    "# Combine to match the original dataset\n",
    "ds['tide_m'] = xr.concat(out_list, dim=ds['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:  (time: 21, x: 1741, y: 1166)\n",
       "Coordinates:\n",
       "  * x        (x) float64 4.538e+05 4.538e+05 4.538e+05 ... 5.059e+05 5.06e+05\n",
       "  * time     (time) datetime64[ns] 2019-01-01T00:21:52.187764 ... 2019-08-05T00:09:38.063853\n",
       "  * y        (y) float64 -4.189e+06 -4.189e+06 ... -4.224e+06 -4.224e+06\n",
       "Data variables:\n",
       "    mndwi    (time, y, x) float32 dask.array&lt;chunksize=(1, 1000, 1000), meta=np.ndarray&gt;\n",
       "    tide_m   (time, y, x) float32 -0.20306547 -0.20302454 ... -0.18102819\n",
       "Attributes:\n",
       "    crs:      epsg:32654</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 21, x: 1741, y: 1166)\n",
       "Coordinates:\n",
       "  * x        (x) float64 4.538e+05 4.538e+05 4.538e+05 ... 5.059e+05 5.06e+05\n",
       "  * time     (time) datetime64[ns] 2019-01-01T00:21:52.187764 ... 2019-08-05T00:09:38.063853\n",
       "  * y        (y) float64 -4.189e+06 -4.189e+06 ... -4.224e+06 -4.224e+06\n",
       "Data variables:\n",
       "    mndwi    (time, y, x) float32 dask.array<chunksize=(1, 1000, 1000), meta=np.ndarray>\n",
       "    tide_m   (time, y, x) float32 -0.20306547 -0.20302454 ... -0.18102819\n",
       "Attributes:\n",
       "    crs:      epsg:32654"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(group.x.values, group.y.values, group.x.time) for (i, group) in ds.groupby('time')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(group.y.values, group.x.values) for (i, group) in ds.groupby('time')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate tides for each timestep into the spatial extent of the data\n",
    "interp_tide = partial(dcl_gen.interpolate_tide,\n",
    "                      tidepoints_gdf=tidepoints_gdf,\n",
    "                      factor=50, dask=False)\n",
    "ds['tide_m'] = dcl_gen.multiprocess_apply(ds=ds,\n",
    "                                          dim='time',\n",
    "                                          func=interp_tide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_tide = partial(dcl_gen.interpolate_tide,\n",
    "                      tidepoints_gdf=tidepoints_gdf,\n",
    "                      factor=40, dask=True)\n",
    "ds['tide_m'] = ds.groupby('time').apply(interp_tide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['tide_m'].compute().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tide_cutoff(da):\n",
    "    \n",
    "    print('Processing')\n",
    "    da = da.compute(scheduler='processes')\n",
    "    print(da.dtype)\n",
    "    \n",
    "    # Determine tide cutoff\n",
    "    tide_cutoff_buff = ((da.max(dim='time') - da.min(dim='time')) * 0.25)\n",
    "    tide_cutoff_min = 0.0 - tide_cutoff_buff\n",
    "    tide_cutoff_max = 0.0 + tide_cutoff_buff\n",
    "    \n",
    "    return tide_cutoff_min, tide_cutoff_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit -r 1 tide_cutoff(ds['tide_m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.isel(time=0).tide_m.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.isel(time=0).tide_m.compute().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def func(x, y):\n",
    "    return x*(1-x)*np.cos(4*np.pi*x) * np.sin(4*np.pi*y**2)**2\n",
    "\n",
    "grid_x, grid_y = np.mgrid[0:1:100j, 0:1:200j]\n",
    "points = np.random.rand(1000, 2).astype('float32')\n",
    "values = func(points[:,0], points[:,1])\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "grid_z0 = griddata(points, values, (grid_x, grid_y), method='nearest')\n",
    "grid_z0.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "from scipy.interpolate import Rbf\n",
    "\n",
    "# Set up interpolation data\n",
    "grid_x, grid_y = np.mgrid[0:1:20j, 0:1:20j]\n",
    "x = np.random.rand(20, 2)\n",
    "y = np.random.rand(20, 2)\n",
    "z = np.random.rand(20, 2)\n",
    "\n",
    "# Function to interpolate data\n",
    "@dask.delayed\n",
    "def _delayed_rbf(x, y, z, grid_y, grid_x):\n",
    "    rbf = Rbf(x, y, z)\n",
    "    return rbf(grid_y, grid_x).astype('float32')\n",
    "\n",
    "# Create Dask array\n",
    "dask_array = da.from_delayed(_delayed_rbf(x, y, z, grid_y, grid_x), \n",
    "                             shape=grid_x.shape, \n",
    "                             dtype='float32')\n",
    "\n",
    "# Test dtype of dask array\n",
    "print(dask_array.dtype)\n",
    "\n",
    "# Compute and test dtype\n",
    "print(dask_array.compute().dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_x = ds.x.values\n",
    "grid_y = ds.x.values\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "np.ones(shape=(len(grid_y), len(grid_x)))\n",
    "\n",
    "xr.DataArray(np.ones(shape=(len(grid_y), len(grid_x))),\n",
    "             coords=[grid_y, grid_x], \n",
    "             dims=['y', 'x'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.interpolate\n",
    "\n",
    "def interpolate_2d(ds, \n",
    "                   x_coords, \n",
    "                   y_coords, \n",
    "                   z_coords, \n",
    "                   grid_x,\n",
    "                   grid_y,\n",
    "                   method='linear',\n",
    "                   factor=1,\n",
    "                   **kwargs):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes points with X, Y and Z coordinates, and \n",
    "    interpolates Z-values across the extent of an existing xarray \n",
    "    dataset. This can be useful for producing smooth surfaces from point\n",
    "    data that can be compared directly against satellite data derived \n",
    "    from an OpenDataCube query.\n",
    "    \n",
    "    Supported interpolation methods include 'linear', 'nearest' and\n",
    "    'cubic (using `scipy.interpolate.griddata`), and 'rbf' (using \n",
    "    `scipy.interpolate.Rbf`).\n",
    "    \n",
    "    Last modified: March 2019\n",
    "    \n",
    "    Parameters\n",
    "    ----------  \n",
    "    ds : xarray DataArray or Dataset\n",
    "        A two-dimensional or multi-dimensional array from which x and y \n",
    "        dimensions will be copied and used for the area in which to \n",
    "        interpolate point data. \n",
    "    x_coords, y_coords : numpy array\n",
    "        Arrays containing X and Y coordinates for all points (e.g. \n",
    "        longitudes and latitudes).\n",
    "    z_coords : numpy array\n",
    "        An array containing Z coordinates for all points (e.g. \n",
    "        elevations). These are the values you wish to interpolate \n",
    "        between.\n",
    "    method : string, optional\n",
    "        The method used to interpolate between point values. This string\n",
    "        is either passed to `scipy.interpolate.griddata` (for 'linear', \n",
    "        'nearest' and 'cubic' methods), or used to specify Radial Basis \n",
    "        Function interpolation using `scipy.interpolate.Rbf` ('rbf').\n",
    "        Defaults to 'linear'.\n",
    "    factor : int, optional\n",
    "        An optional integer that can be used to subsample the spatial \n",
    "        interpolation extent to obtain faster interpolation times, then\n",
    "        up-sample this array back to the original dimensions of the \n",
    "        data as a final step. For example, setting `factor=10` will \n",
    "        interpolate data into a grid that has one tenth of the \n",
    "        resolution of `ds`. This approach will be significantly faster \n",
    "        than interpolating at full resolution, but will potentially \n",
    "        produce less accurate or reliable results.\n",
    "    **kwargs : \n",
    "        Optional keyword arguments to pass to either \n",
    "        `scipy.interpolate.griddata` (if `method` is 'linear', 'nearest' \n",
    "        or 'cubic'), or `scipy.interpolate.Rbf` (is `method` is 'rbf').\n",
    "      \n",
    "    Returns\n",
    "    -------\n",
    "    interp_2d_array : xarray DataArray\n",
    "        An xarray DataArray containing with x and y coordinates copied \n",
    "        from `ds_array`, and Z-values interpolated from the points data. \n",
    "    \"\"\"    \n",
    "  \n",
    "    # Extract xy and elev points\n",
    "    points_xy = np.vstack([x_coords, y_coords]).T\n",
    "    \n",
    "    # Extract x and y coordinates to interpolate into. \n",
    "    # If `factor` is greater than 1, the coordinates will be subsampled \n",
    "    # for faster run-times. If the last x or y value in the subsampled \n",
    "    # grid aren't the same as the last x or y values in the original \n",
    "    # full resolution grid, add the final full resolution grid value to \n",
    "    # ensure data is interpolated up to the very edge of the array\n",
    "    if ds.x[::factor][-1].item() == ds.x[-1].item():\n",
    "        x_grid_coords = ds.x[::factor].values\n",
    "    else:\n",
    "        x_grid_coords = ds.x[::factor].values.tolist() + [ds.x[-1].item()]\n",
    "        \n",
    "    if ds.y[::factor][-1].item() == ds.y[-1].item():\n",
    "        y_grid_coords = ds.y[::factor].values\n",
    "    else:\n",
    "        y_grid_coords = ds.y[::factor].values.tolist() + [ds.y[-1].item()]\n",
    "\n",
    "    # Create grid to interpolate into\n",
    "    grid_y, grid_x = np.meshgrid(x_grid_coords, y_grid_coords)\n",
    "        \n",
    "    # Apply scipy.interpolate.griddata interpolation methods\n",
    "    if method in ('linear', 'nearest', 'cubic'):       \n",
    "\n",
    "        # Interpolate x, y and z values \n",
    "        interp_2d = scipy.interpolate.griddata(points=points_xy, \n",
    "                                                values=z_coords, \n",
    "                                                xi=(grid_y, grid_x), \n",
    "                                                method=method,\n",
    "                                                **kwargs)\n",
    "        \n",
    "    # Apply Radial Basis Function interpolation\n",
    "    elif method == 'rbf':\n",
    "        \n",
    "        # Interpolate x, y and z values \n",
    "        rbf = scipy.interpolate.Rbf(x_coords, y_coords, z_coords, **kwargs)  \n",
    "        interp_2d = rbf(grid_y, grid_x).astype('float32')\n",
    "\n",
    "    # Create xarray dataarray from the data and resample to ds coords\n",
    "    interp_2d_da = xr.DataArray(interp_2d,\n",
    "                                coords=[y_grid_coords, x_grid_coords], \n",
    "                                dims=['y', 'x'])\n",
    "    \n",
    "    # If factor is greater than 1, resample the interpolated array to\n",
    "    # match the input `ds` array\n",
    "    if factor > 1: \n",
    "        interp_2d_da = interp_2d_da.interp_like(ds)\n",
    "\n",
    "    return interp_2d_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Plot \n",
    "# ds_i = ds['tide_m'].isel(time=50).compute()\n",
    "# ds_i.plot.imshow(robust=True, \n",
    "#                  cmap='viridis', \n",
    "#                  size=12, \n",
    "#                  vmin=ds_i.min().item(), \n",
    "#                  vmax=ds_i.max().item())\n",
    "# tidepoints_gdf.loc[str(ds_i.time.values)[0:10]].plot(ax=plt.gca(), \n",
    "#                                                      column='tide_m', \n",
    "#                                                      cmap='viridis', \n",
    "#                                                      markersize=100,\n",
    "#                                                      edgecolor='black',\n",
    "#                                                      vmin=ds_i.min().item(), \n",
    "#                                                      vmax=ds_i.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine tide cutoff\n",
    "tide_cutoff_buff = (\n",
    "    (ds['tide_m'].max(dim='time') - ds['tide_m'].min(dim='time')) * 0.25)\n",
    "tide_cutoff_min = 0.0 - tide_cutoff_buff\n",
    "tide_cutoff_max = 0.0 + tide_cutoff_buff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate yearly composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each year and export annual and 3-year gapfill composites\n",
    "dcl_gen.export_annual_gapfill(ds, \n",
    "                              output_dir, \n",
    "                              tide_cutoff_min, \n",
    "                              tide_cutoff_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{(datetime.datetime.now() - start_time).seconds / 60:.1f} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** March 2020"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
