{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import datacube\n",
    "from datacube.storage import masking\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datacube.utils import geometry\n",
    "from datacube.utils.geometry import CRS\n",
    "from datacube.helpers import write_geotiff\n",
    "import os\n",
    "\n",
    "sys.path.append('../../10_Scripts')\n",
    "import SpatialTools\n",
    "import gdal\n",
    "import DEADataHandling\n",
    "import DEAPlotting\n",
    "\n",
    "# Connect to datacube database\n",
    "dc = datacube.Datacube(app='Snow monitoring with Landsat')\n",
    "\n",
    "\n",
    "output='/g/data/r78/jt7365/dea-notebooks/SnowOFS/results/Tas/1200/phen/cm/'\n",
    "year='2016_2018_'\n",
    "elev = 1200\n",
    "\n",
    "# Set up centre of area to analyse, and a buffer in metres around this centrepoint. Generally,\n",
    "# aim to keep the buffer size to less than 10,000m to prevent having memory errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon, buffer_m, buffer_n = -41.85, 146.38, 8000, 8000 #tas cradle mountain/mt ossa region\n",
    "#lat, lon, buffer_m, buffer_n = -41.87, 146, 8000, 8000 # tas mt ossa\n",
    "#lat, lon, buffer_m, buffer_n = -41.56728, 147.67106, 10000, 10000 #tas ben lomond\n",
    "#lat, lon, buffer_m, buffer_n = -36.3, 148.35, 30000, 40000 #nsw\n",
    "\n",
    "# Set range of time to return data from both Landsat and Sentinel 2\n",
    "time_range = ('2016-01-01', '2018-12-31')\n",
    "\n",
    "resolution = (-25, 25)\n",
    "\n",
    "landsat_goodquality_prop = 0.3\n",
    "\n",
    "ndsi_threshold = 0.2\n",
    "ndvi_threshold = 0.3\n",
    "ndwi_threshold = 0.15\n",
    "red_threshold = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading landsat_ds\n",
      "Loading ls5\n",
      "    Skipping ls5; no valid data for query\n",
      "Loading ls7\n",
      "    Loading 22 filtered ls7 timesteps\n",
      "Loading ls8\n",
      "    Loading 24 filtered ls8 timesteps\n",
      "Combining and sorting ls7, ls8 data\n",
      "    Replacing invalid -999 values with NaN (data will be coerced to float64)\n"
     ]
    }
   ],
   "source": [
    "x, y = geometry.point(lon, lat, CRS('WGS84')).to_crs(CRS('EPSG:3577')).points[0]\n",
    "query = {'x': (x - buffer_m, x + buffer_m),\n",
    "         'y': (y - buffer_m, y + buffer_m),\n",
    "         'time': time_range,\n",
    "         'crs': 'EPSG:3577',\n",
    "         'output_crs': 'EPSG:3577',\n",
    "         'resolution': resolution}\n",
    "\n",
    "print('loading landsat_ds')\n",
    "snow_mask = dict(                cloud_acca='no_cloud',\n",
    "                                 #cloud_fmask='no_cloud',\n",
    "                                 cloud_shadow_acca='no_cloud_shadow',\n",
    "                                 #cloud_shadow_fmask='no_cloud_shadow',\n",
    "                                 blue_saturated=False,\n",
    "                                 green_saturated=False,\n",
    "                                 red_saturated=False,\n",
    "                                 nir_saturated=False,\n",
    "                                 swir1_saturated=False,\n",
    "                                 swir2_saturated=False,\n",
    "                                 contiguous=True)\n",
    "\n",
    "landsat_ds = DEADataHandling.load_clearlandsat(dc=dc,\n",
    "                                               product = 'nbar',\n",
    "                                               query=query,\n",
    "                                               mask_dict=snow_mask,\n",
    "                                               sensors=['ls5','ls7','ls8'],\n",
    "                                               bands_of_interest=['red', 'green', 'blue','nir', 'swir1'],\n",
    "                                               masked_prop=landsat_goodquality_prop,\n",
    "                                               mask_pixel_quality=True,\n",
    "                                               ls7_slc_off=True)\n",
    "\n",
    "# file = open(output+'nofimages.txt','a')\n",
    "# file.write(year+', '+str(len(landsat_ds.time))+'\\n')\n",
    "# file.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ndsi_ds = (landsat_ds.green -landsat_ds.swir1) / (landsat_ds.green + landsat_ds.swir1)\n",
    "ndvi_ds = (landsat_ds.nir - landsat_ds.red) / (landsat_ds.nir + landsat_ds.red)\n",
    "ndwi_ds = (landsat_ds.green - landsat_ds.nir)/(landsat_ds.green + landsat_ds.nir)\n",
    "\n",
    "valid_ds = np.isfinite(landsat_ds.swir1)\n",
    "\n",
    "snow_ds1 = ndsi_ds > ndsi_threshold\n",
    "noveg_ds = ndvi_ds < ndvi_threshold\n",
    "nowater_ds = ndwi_ds < ndwi_threshold\n",
    "red_ds = landsat_ds.red > red_threshold\n",
    "snow_ds = noveg_ds & snow_ds1 & nowater_ds & red_ds\n",
    "#snow_ds = noveg_ds & snow_ds1\n",
    "\n",
    "\n",
    "x, y = geometry.point(lon, lat, CRS('WGS84')).to_crs(CRS('EPSG:3577')).points[0]\n",
    "query1 = {'x': (x - buffer_m, x + buffer_m),\n",
    "         'y': (y - buffer_n, y + buffer_n),\n",
    "         #'time': time_range,\n",
    "         'crs': 'EPSG:3577',\n",
    "         'output_crs': 'EPSG:3577',\n",
    "         'resolution': resolution}\n",
    "\n",
    "# Load the DEM data\n",
    "dem_ds = dc.load(product='srtm_dem1sv1_0', **query1)\n",
    "dem_elev = dem_ds.dem > elev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snow_elev = snow_ds.where(dem_elev.squeeze(dim='time'))\n",
    "# valid_elev = valid_ds.where(dem_elev.squeeze(dim='time'))\n",
    "# snow_prop = snow_elev/valid_elev\n",
    "\n",
    "c=list(range(len(snow_ds.time)))\n",
    "snow_prop_elev=[]\n",
    "for i in c:\n",
    "    d = valid_ds.isel(time=i).values * dem_elev\n",
    "    f = snow_ds.isel(time=i).values * dem_elev\n",
    "    n = np.count_nonzero(d.values)\n",
    "    if n == 0:\n",
    "        n = n+1\n",
    "    snow =  np.count_nonzero(f.values) / n\n",
    "    snow_prop_elev.append(snow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask ndsi dataset with dem_1800, leaving values over 1800 m\n",
    "# ndsi_elev = ndsi_ds.where(dem_elev.squeeze(dim='time'))\n",
    "# calculate ndsi mean of valid pixels over 1800 m\n",
    "# mean_ndsi_elev = ndsi_elev.mean(dim=('x', 'y'))\n",
    "\n",
    "\n",
    "# df = pd.DataFrame({'time':snow_ds.time, 'snow_prop_1800':snow_prop_1800, 'pixel_prop':prop_, 'pixel_over_005':prop_rel})\n",
    "# df.to_csv(output+years+'NEWmask_frequency_prop.csv')\n",
    "\n",
    "# df = pd.DataFrame({'dayofyear':snow_ds['time.dayofyear'], 'proportion':snow_ds.values, 'year':ndsi_ds['time.year']})\n",
    "# df.to_csv(output+years+'phenology_freq_1800.csv')\n",
    "\n",
    "df = pd.DataFrame({'dayofyear':snow_ds['time.dayofyear'], 'snow_prop_elev':snow_prop_elev, 'year':snow_ds['time.year']})\n",
    "df.to_csv('phenology_freq_'+str(elev)+'.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
