{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of two time frames on where water was then compared to where water is now\n",
    "This notebook is similar to the inundation mapping notebook. It links stream gauge data to satellite data and retrieves only the satellite images taken when the gauge was reading high-flow, allowing the user to study floods. This notebook allows the user to compare two time-frames for example, before a legislation was enforced and after it was enforced. The notebook generates a red and blue image showing the change in water occurance on floodplains and dams according to a certain date. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and get data\n",
    "This notebook accesses some back-end Python and XML files that scrape gauge data from the BoM Water Data Online website. They are located in the folder called Scripts. For ease of use, we have cached all the data so the code will run even if the BoM website is down. If you want to access the live BoM website, you can go into Scripts and move the stations.pkl file out of there so the code can't find it, and then it will go look on the real website instead of in the cache.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import datacube\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "from datacube.storage import masking\n",
    "from datacube.utils import geometry \n",
    "from datacube.utils.geometry import CRS\n",
    "from datacube.helpers import write_geotiff\n",
    "\n",
    "sys.path.append('Scripts')\n",
    "import dea_bom\n",
    "\n",
    "dc = datacube.Datacube(app='Inundation_mapping')\n",
    "\n",
    "\n",
    "#retrieving data\n",
    "stations_pkl = Path('Scripts/stations.pkl')\n",
    "\n",
    "# If cache exists, get station data from cache\n",
    "if stations_pkl.exists():\n",
    "    print('Loading from cache')\n",
    "    stations = pickle.load(open(str(stations_pkl), 'rb'))\n",
    "else:\n",
    "    print('Fetching from BoM')\n",
    "    stations = dea_bom.get_stations()\n",
    "    pickle.dump(stations, open(str(stations_pkl), 'wb'))\n",
    "\n",
    "# Filter list to stations with available data\n",
    "stations_with_data = pickle.load(open(str('Scripts/stations_with_data.pkl'), 'rb'))\n",
    "stations = [i for i in stations if i.name in stations_with_data]\n",
    "\n",
    "# Preview the first five stations loaded\n",
    "print(f'{len(stations)} stations loaded; e.g.:')\n",
    "stations[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the map\n",
    "This cell generates a map with the gauges on it. Select a gauge to get flow data from. Make sure there is data available both before and after the legislation started. Click 'Done' once you have found a station with good data. If you forget to click 'Done', the rest of the code won't run. If you want to choose another gauge after you have clicked 'Done', re-run this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_data, station = dea_bom.ui_select_station(stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the Flow Duration Curve, Dask load satellite data and merge with gauge data\n",
    "The lat and lon of the gauge will be automatically selected, but is changeable in the first line of code below. The top 20% of flows will automatically be selected. This is also changeable in the line of code below that says # What part of the Flow Duration Curve do you want to look at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lat and lon takes the location of the gauge. You can change the lat \n",
    "# and lon to a different location if necessary, just comment out out this \n",
    "# lat, lon = pos line below and define your own.\n",
    "lat, lon = station.pos\n",
    "\n",
    "# lat =\n",
    "# lon =\n",
    "\n",
    "# The buffer is how many meters radius around the location you want to display.\n",
    "buffer = 10000\n",
    "\n",
    "# Rearranging data into a flow duration curve\n",
    "gauge_data = gauge_data.dropna()\n",
    "gauge_data = gauge_data.sort_values('Value')\n",
    "gauge_data['rownumber'] = np.arange(len(gauge_data))\n",
    "gauge_data['Exceedence'] = (1 - (gauge_data.rownumber / len(gauge_data))) * 100\n",
    "\n",
    "# What part of the Flow Duration Curve do you want to look at?\n",
    "xaxis_lower_parameter = 0\n",
    "xaxis_higher_parameter = 20\n",
    "\n",
    "# Plot the data on a log scale\n",
    "gauge_data.plot(x='Exceedence',\n",
    "                y='Value',\n",
    "                logy=True,\n",
    "                title='Selected range displayed on a log scale',\n",
    "                figsize=(10, 6))\n",
    "plt.axvspan(xaxis_lower_parameter,\n",
    "            xaxis_higher_parameter,\n",
    "            color='red',\n",
    "            alpha=0.2)\n",
    "plt.ylabel('Cubic meters per second (log)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query, Dask load and merge\n",
    "The output of this next box will tell you how many satellite passes you are about to load and the lat and lon of the area you are generating an image of. The query in this box should have the time set from 1987 to present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a query which defines the area and time period to load data for\n",
    "x, y = geometry.point(lon, lat, CRS('WGS84')).to_crs(CRS('EPSG:3577')).points[0]\n",
    "query = {'x': (x - buffer, x + buffer),\n",
    "         'y': (y - buffer, y + buffer),    \n",
    "         'time': ('1987-01-01', '2019-11-01'), # Change this date to match present day\n",
    "         'crs': 'EPSG:3577'} \n",
    "\n",
    "# Dask load wofs_albers data (this loads the dataset parameters only, \n",
    "# not the actual satellite data)\n",
    "wofs_albers = dc.load(product = 'wofs_albers', \n",
    "                      dask_chunks = {}, \n",
    "                      group_by='solar_day', \n",
    "                      **query)\n",
    "\n",
    "\n",
    "# Merging satellite data with gauge data by timestamp\n",
    "gauge_data_xr = gauge_data.to_xarray()\n",
    "merged_data = gauge_data_xr.interp(Timestamp=wofs_albers.time, method='nearest')\n",
    "\n",
    "# Here is where it takes into account user input for the FDC\n",
    "specified_level = merged_data.where((merged_data.Exceedence > xaxis_lower_parameter) & \n",
    "                                    (merged_data.Exceedence < xaxis_higher_parameter), \n",
    "                                    drop=True)\n",
    "\n",
    "# Get list of dates to keep\n",
    "date_list = specified_level.time.values\n",
    "\n",
    "print(f'You are about to load {specified_level.time.shape[0]} satellite passes')\n",
    "\n",
    "print(f'lat = {lat}')\n",
    "print(f'lon = {lon}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate images of before and after\n",
    "Now you will load and cloud mask those satellite passes and generate 3 images: one before and one after the dates that were specified in the query and a delta image, which shows the change in water frequency of before legislation minus after legislation on a blue to red scale. Blue means water occured after legislation and red means water occured before legislation but not after. This box is where you enter the epochs you are interested in comparing, where it says #Change according to date legislation became effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the passes that happened during the specified flow parameters\n",
    "specified_passes = wofs_albers.sel(time=date_list).compute()\n",
    "\n",
    "# Calculate the number of cloudy pixels per timestep\n",
    "cc = masking.make_mask(specified_passes.water, cloud=True)\n",
    "ncloud_pixels = cc.sum(dim=['x', 'y'])\n",
    "\n",
    "# Calculate the total number of pixels per timestep\n",
    "npixels_per_slice = (specified_passes.water.shape[1] * \n",
    "                     specified_passes.water.shape[2])\n",
    "\n",
    "# Calculate the proportion of cloudy pixels\n",
    "cloud_pixels_fraction = (ncloud_pixels / npixels_per_slice)\n",
    "\n",
    "# Filter out \"too cloudy\" passes (i.e. more than 50% cloud)\n",
    "clear_specified_passes = specified_passes.water.isel(\n",
    "    time=cloud_pixels_fraction < 0.5)\n",
    "\n",
    "\n",
    "# Split by date into before and after legislation about floodplain harvesting\n",
    "query_dates = clear_specified_passes\n",
    "\n",
    "before_legislation = query_dates.loc[dict(time=slice('1987-01-01', '2008-06-01'))] # Change according to date legislation became effective\n",
    "after_legislation = query_dates.loc[dict(time=slice('2008-06-02', '2019-11-13'))]\n",
    "\n",
    "#Create parameters for the image\n",
    "wet = (before_legislation == 128).sum(dim='time')\n",
    "dry = (before_legislation == 0).sum(dim='time')\n",
    "clear = wet + dry\n",
    "frequency_before = wet / clear\n",
    "frequency_before = frequency_before.fillna(0) #this is to get rid of the NAs that occur due to mountain shadows\n",
    "frequency_before = frequency_before.where(frequency_before !=0) #This is to tell it to make areas that were dry 100% of the time white\n",
    "\n",
    "#Plotting the image\n",
    "frequency_before.plot(figsize = (16, 12))\n",
    "plt.axis('off')\n",
    "plt.title('Before legislation started')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Create parameters for the image\n",
    "wet = (after_legislation == 128).sum(dim='time')\n",
    "dry = (after_legislation == 0).sum(dim='time')\n",
    "clear = wet + dry\n",
    "frequency_after = wet / clear\n",
    "frequency_after = frequency_after.fillna(0) #this is to get rid of the NAs that occur due to mountain shadows\n",
    "frequency_after = frequency_after.where(frequency_after !=0) #This is to tell it to make areas that were dry 100% of the time white\n",
    "\n",
    "#Plotting the image\n",
    "frequency_after.plot(figsize = (16, 12))\n",
    "plt.axis('off')\n",
    "plt.title('After legislation started')\n",
    "plt.show()\n",
    "\n",
    "delta = frequency_before - frequency_after\n",
    "\n",
    "# Plotting the image\n",
    "delta.plot(figsize = (16, 12), vmin = -0.25, vmax = 0.25, cmap = 'RdYlBu_r')\n",
    "plt.axis('off')\n",
    "plt.title(\"After minus before: Red means water is no longer there since legislation and blue means water has appeared there since legislation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the file as a GeoTIFF\n",
    "The ../ part of the file name means your .tif file will be saved one folder up from where this notebook is saved. Choose an appropriate file name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the output file name \n",
    "file_name = '../delta_image.tif'\n",
    "\n",
    "# Set up the file for writing\n",
    "delta_image = delta.to_dataset()\n",
    "delta_image.attrs=wofs_albers.attrs\n",
    "\n",
    "# Write GeoTIFF to a location\n",
    "write_geotiff(file_name, delta_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
