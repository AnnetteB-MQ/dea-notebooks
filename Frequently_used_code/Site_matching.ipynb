{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General advice (delete this cell before submitting for review)\n",
    "\n",
    "> * When choosing a location for your analysis, **select an area that has data on both the NCI and DEA Sandbox** to allow your code to be run on both environments. \n",
    "For example, you can check this for Landsat using the [DEA Explorer](https://explorer.sandbox.dea.ga.gov.au/ga_ls5t_ard_3/1990) (use the drop-down menu to view all products).\n",
    "As of September 2019, the `DEA Sandbox` has a single year of continental Landsat data for 2015-16, and the full 1987-onward time-series for three locations (Perth WA, Brisbane QLD, and western NSW).\n",
    "> * When adding **Products used**, embed the hyperlink to that specific product on the DEA Explorer using the `[product_name](product url)` syntax.\n",
    "> * When writing in Markdown cells, start each sentence on a **new line**.\n",
    "This makes it easy to see changes through git commits.\n",
    "> * Use Australian English in markdown cells and code comments.\n",
    "> * Check the [known issues](https://github.com/GeoscienceAustralia/dea-docs/wiki/Known-issues) for formatting regarding the conversion of notebooks to DEA docs using Sphinx.\n",
    "Things to be aware of:\n",
    "    * Sphinx is highly sensitive to bulleted lists:\n",
    "        * Ensure that there is an empty line between any preceding text and the list\n",
    "        * Only use the `*` bullet (`-` is not recognised)\n",
    "        * Sublists must be indented by 4 spaces\n",
    "    * Two kinds of formatting cannot be used simultaneously:\n",
    "        * Hyperlinked code: \\[\\`code_format\\`](hyperlink) fails\n",
    "        * Bolded code: \\*\\*\\`code_format\\`\\*\\* fails\n",
    "    * Headers must appear in heirachical order (`#`, `##`, `###`, `####`) and there can only be one title (`#`).\n",
    "> * Use the [PEP8 standard](https://www.python.org/dev/peps/pep-0008/) for code. To make sure all code in the notebook is consistent, you can use the `jupyterlab_code_formatter` tool: select each code cell, then click `Edit` and then one of the `Apply X Formatter` options (`YAPF` or `Black` are recommended). This will reformat the code in the cell to a consistent style.\n",
    "> * For additional guidance, refer to the style conventions and layouts in approved `develop` branch notebooks. \n",
    "Examples include\n",
    "    * [Frequently_used_code/Using_load_ard.ipynb](./Frequently_used_code/Using_load_ard.ipynb)\n",
    "    * [Real_world_examples/Coastal_erosion.ipynb](./Real_world_examples/Coastal_erosion.ipynb)\n",
    "    * [Scripts/dea_datahandling.py](./Scripts/dea_datahandling.py)\n",
    "> * The DEA Image placed in the title cell will display as long as the notebook is contained in one of the standard directories.\n",
    "It does not work in the highest level directory (hence why it doesn't display in the original template notebook).\n",
    "> * In the final notebook cell, include a set of relevant tags which are used to build the DEA User Guide's [Tag Index](https://docs.dea.ga.gov.au/genindex.html). \n",
    "Use all lower-case (unless the tag is an acronym), separate words with spaces (unless it is the name of an imported module), and [re-use existing tags](https://github.com/GeoscienceAustralia/dea-notebooks/wiki/List-of-tags).\n",
    "Ensure the tags cell below is in `Raw` format, rather than `Markdown` or `Code`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching satellite imagery for field data <img align=\"right\" src=\"../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatability:** Notebook currently compatible with the `NCI`|`DEA Sandbox` environment only\n",
    "* **Products used:** \n",
    "[s2a_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2a_ard_granule), \n",
    "[s2b_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2b_ard_granule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "An *optional* overview of the scientific, economic or environmental management issue or challenge being addressed by Digital Earth Australia. \n",
    "For `Beginners_Guide` or `Frequently_Used_Code` notebooks, this may include information about why the particular technique or approach is useful or required. \n",
    "If you need to cite a scientific paper or link to a website, use a persistent DOI link if possible and link in-text (e.g. [Dhu et al. 2017](https://doi.org/10.1080/20964471.2017.1402490))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "A _compulsory_ description of the notebook, including a brief overview of how Digital Earth Australia helps to address the problem set out above.\n",
    "It can be good to include a run-down of the tools/methods that will be demonstrated in the notebook:\n",
    "\n",
    "1. First we do this\n",
    "2. Then we do this\n",
    "3. Finally we do this\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "Provide any particular instructions that the user might need, e.g. To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Use standard import commands; some are shown below. \n",
    "Begin with any `iPython` magic commands, followed by standard Python packages, then any additional functionality you need from the `Scripts` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datacube\n",
    "from datacube.utils.geometry import CRS, point\n",
    "import dask\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import xarray as xr\n",
    "\n",
    "sys.path.append('../Scripts')\n",
    "from dea_plotting import rgb\n",
    "from dea_datahandling import load_ard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "Give your datacube app a unique name. \n",
    "Ideally, this will be the same as the notebook file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='DEA_notebooks_template')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters\n",
    "\n",
    "* `sample_loc_file`: Name and location of the csv file containing sampling locations with corresponding latitudes and longitudes (e.g. `../Supplementary_data/Site_matching/locations.csv`).\n",
    "* `sample_data_file`: Name and location of the csv file containing sampling dates for each location and sample measurements (e.g. `../Supplementary_data/Site_matching/dates.csv`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_loc_file = '../Supplementary_data/Site_matching/chlorophyll_sampling_coorong_locations.csv'\n",
    "sample_date_file = '../Supplementary_data/Site_matching/chlorophyll_sampling_coorong_dates.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the input data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the location csv\n",
    "locations = pd.read_csv(sample_loc_file)\n",
    "\n",
    "# View the first 5 entries\n",
    "locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load observations csv\n",
    "observations = pd.read_csv('../Supplementary_data/Site_matching/chlorophyll_sampling_coorong_dates.csv')\n",
    "\n",
    "# View the first 5 entries\n",
    "observations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the closest satellite data in time and space\n",
    "Use markdown text for detailed, descriptive text explaining what the code below does and why it is needed.\n",
    "\n",
    "* for each site:\n",
    "    * loop over each date and extract key satellite band values and the computed NDCI at the pixel closest to the specified lat,lon of the site\n",
    "    * return no observations if the closest date is more than +/-7 days out\n",
    "    * write this data to an output file for each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_dates = observations[\"Date\"].values\n",
    "\n",
    "products = ['s2a_ard_granule', 's2b_ard_granule']\n",
    "measurements = ['nbart_red_edge_1', 'nbart_red']\n",
    "\n",
    "# for site in locations.itertuples(index=False):\n",
    "#     print(site)\n",
    "    \n",
    "# Extract information from locations table\n",
    "site_latitude = -36.1614 #site.Lat\n",
    "site_longitude = 139.6389 #site.Long\n",
    "site_name = 'Coorong central lagoon 3.2km south Salt Creek' #site.SiteName\n",
    "\n",
    "# Convert from (long, lat) to (x, y) for finding nearest pixel to site\n",
    "site_point_ll = point(site_longitude, site_latitude, crs=CRS('EPSG:4326'))\n",
    "site_xy = site_point_ll.to_crs(CRS('EPSG:3577')).points[0]\n",
    "site_x = site_xy[0]\n",
    "site_y = site_xy[1]\n",
    "\n",
    "# Generate area to search over by adding buffer in degrees\n",
    "buffer = 0.001\n",
    "search_lon = (site_longitude - buffer, site_longitude + buffer)\n",
    "search_lat = (site_latitude - buffer, site_latitude + buffer)\n",
    "\n",
    "for date_string in site_dates:\n",
    "    target_date = datetime.strptime(date_string, '%d/%m/%Y')\n",
    "    print(target_date)\n",
    "\n",
    "    # Load masked data from both Sentinel satellites\n",
    "    ds_s2 = load_ard(dc, products=products, measurements=measurements, x=search_lon, y=search_lat, output_crs='EPSG:3577', resolution=(-10,10), lazy_load=True);\n",
    "\n",
    "    # Isolate the timestep that is closest to the sample date\n",
    "    ds_closestdate = ds_s2.sel(time=target_date, method='nearest')\n",
    "    \n",
    "    # Calculate the time-difference between sample date and closest date\n",
    "    time_delta = np.abs(pd.to_datetime(target_date) - ds_closestdate.time.values)\n",
    "\n",
    "    \n",
    "    if time_delta < timedelta(days=7):\n",
    "        ds_closestdate['ndci'] = (ds_closestdate.nbart_red_edge_1 - ds_closestdate.nbart_red)/(ds_closestdate.nbart_red_edge_1 + ds_closestdate.nbart_red)\n",
    "        ds_closest_pixel = ds_closestdate.sel(x=site_x, y=site_y, method='nearest')\n",
    "        ndci_value = ds_closest_pixel.ndci.values\n",
    "    else:\n",
    "        ndci_value = np.nan\n",
    "\n",
    "# print(ds_closestdate.time.values)\n",
    "\n",
    "# print(np.abs(pd.to_datetime(target_date) - ds_closestdate.time.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations[\"Date\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = datetime.strptime(observations[\"Date\"].values[30], '%d/%m/%Y')\n",
    "print(target_date)\n",
    "\n",
    "for row in locations.itertuples(index=False):\n",
    "    centre_lat = row.Lat\n",
    "    centre_lon = row.Long\n",
    "    site_name = row.SiteName\n",
    "    \n",
    "    print(centre_lat)\n",
    "    print(centre_lon)\n",
    "    \n",
    "    buffer = 0.01\n",
    "    lat = (centre_lat - buffer, centre_lat + buffer)\n",
    "    lon = (centre_lon - buffer, centre_lon + buffer)\n",
    "    print(lat)\n",
    "    print(lon)\n",
    "    \n",
    "    products = ['s2a_ard_granule', 's2b_ard_granule']\n",
    "    \n",
    "    measurements = ['nbart_red_edge_1', 'nbart_red']\n",
    "    \n",
    "    query = {'x': lon, 'y': lat, 'product': products, 'measurements': measurements}\n",
    "    \n",
    "    returned_data = dc.find_datasets(**query)\n",
    "    time_delta = [target_date - dataset.center_time.replace(tzinfo=None) for dataset in returned_data]\n",
    "    arg_min = np.argmin(np.abs(time_delta))\n",
    "    \n",
    "    print(arg_min)\n",
    "    print(returned_data[arg_min].center_time)\n",
    "\n",
    "#print(min(np.abs(time_delta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import Client\n",
    "\n",
    "# client = Client('dask-datacube-dask.labs:8786')\n",
    "\n",
    "test_centre_lat = -36.1614\n",
    "test_centre_lon = 139.6389\n",
    "\n",
    "test_lat = (-36.1714, -36.1514)\n",
    "test_lon = (139.6289, 139.6489)\n",
    "test_date = datetime.strptime(observations[\"Date\"].values[30], \"%d/%m/%Y\")\n",
    "\n",
    "measurements = [\"nbart_red_edge_1\", \"nbart_red\"]\n",
    "\n",
    "dask_query = {\n",
    "    \"x\": test_lon,\n",
    "    \"y\": test_lat,\n",
    "    \"product\": \"s2a_ard_granule\",\n",
    "    \"measurements\": measurements,\n",
    "    \"dask_chunks\": {\"time\": 1},\n",
    "    \"output_crs\": \"EPSG:3577\",\n",
    "    \"resolution\": (-10, 10)\n",
    "}\n",
    "\n",
    "test_data = dc.load(**dask_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datacube.utils.geometry import CRS, point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnt = point(test_lon[0], test_lat[0], CRS('epsg:4326'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnt.to_crs(CRS('epsg:3577')).points[0]\n",
    "\n",
    "closest_lat_crs = pnt.to_crs(CRS('epsg:3577')).points[0][1]\n",
    "closest_lon_crs = pnt.to_crs(CRS('epsg:3577')).points[0][0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest = test_data.sel(time=test_date, method='nearest')\n",
    "closest['ndci'] = (closest.nbart_red_edge_1 - closest.nbart_red)/(closest.nbart_red_edge_1 + closest.nbart_red)\n",
    "print(closest)\n",
    "\n",
    "# print(pd.to_datetime(test_date))\n",
    "# print(closest.time.values)\n",
    "# print(np.abs(pd.to_datetime(test_date) - closest.time.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_pixel_1 = closest.sel(x=closest_lon_crs, y=closest_lat_crs, method='nearest')\n",
    "print(closest_pixel_1.ndci.values)\n",
    "closest_pixel_2 = closest.sel(x=test_lon[0], y=test_lat[0], method='nearest')\n",
    "print(closest_pixel_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** October 2019\n",
    "\n",
    "**Compatible `datacube` version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`NCI compatible`, :index:`sandbox compatible`, :index:`sentinel 2`, :index:` landsat 8`, :index:`dea_plotting`, :index:`rgb`, :index:`NDVI`, :index:`time series`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
