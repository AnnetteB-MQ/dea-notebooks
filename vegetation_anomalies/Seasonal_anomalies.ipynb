{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonal Vegetation Anomalies\n",
    "\n",
    "Notebook is only compatible on the `NCI` as it uses Landsat Collection 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Understanding how the vegetated landscape responds to longer-term environmental drivers such as the El Nino Southern Oscillation (ENSO) or climate change, requires the calculation of seasonal anomalies. Seasonal anomalies subtract the long-term seasonal mean from a time-series, thus removing seasonal variability and highlighting change related to longer-term drivers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This notebook will calculate the seasonal anomaly for any given season and year. The long-term seasonal climatologies for the vegetation indices, `MSAVI`, and `NDVI`, have been pre-calculated and are stored on disk. Given an AOI, season, and year, the script will calculate the seasonal mean for one of these indices and subtract the seasonal mean from the long-term climatology, resulting in a map of vegetation anomalies for your AOI.  Optionally, the script will output a geotiff of the result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical details\n",
    "\n",
    "* **Products used:** ls5_nbart_albers, ls7_nbart_albers, ls8_nbart_albers\n",
    "* **Analyses used:** NDVI, MSAVI, seasonal anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "To run this analysis, go to the `Analysis Parameters` section and enter the relevant details, then run all the cells in the notebook. If running the analysis multiple times, only run the `Set up dask cluster` and `import libraries` cells once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from datacube.helpers import write_geotiff\n",
    "import matplotlib.pyplot as plt\n",
    "from dask.distributed import Client\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "from anomalies import calculate_anomalies\n",
    "from anomalies import load_landsat\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up local dask cluster\n",
    "\n",
    "Dask will create a local cluster of cpus for running this analysis in parallel. If you'd like to see what the dask cluster is doing, click on the hyperlink that prints after you run the cell and you can watch the cluster run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/distributed/dashboard/core.py:72: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:36306</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:43067/status' target='_blank'>http://127.0.0.1:43067/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>6</li>\n",
       "  <li><b>Cores: </b>6</li>\n",
       "  <li><b>Memory: </b>24.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:36306' processes=6 cores=6>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(n_workers=6, threads_per_worker=1, memory_limit='4GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Parameters\n",
    "\n",
    "The following cell sets the parameters, which define the area of interest and the season to conduct the analysis over. The parameters are:\n",
    "\n",
    "* `veg_index`: The vegetation index to use for the analysis, either `'msavi'` or `'ndvi'`.\n",
    "* `from_shape`: If providing a shapefile to the define the area of interest, set this parameter to `True`, otherwise set to `False`.\n",
    "* `shp_fpath`: If you set `from_shape` to True, provide a filepath to the shapefile.\n",
    "* `lat`, `lon`: If not using a shapefile to define the AOI, then use a latitide and longitude point. This point will be the centre point of your AOI.\n",
    "* `buffer`: The length, in decimal degrees, either side of the `lat` and `lon` point that will define the AOI box. Keep this below `0.5` to avoid long load times\n",
    "* `year`: The year of interest, e.g. `'2018'`\n",
    "* `season`:  The season of interest, must be one of `'DJF'`, `'MAM'`, `'JJA'`, or `'SON'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_index='msavi'\n",
    "from_shape = True\n",
    "shp_fpath = \"data/LGA_AOI_Chad.shp\"\n",
    "lat, lon = -34.347, 143.832\n",
    "buffer = 0.25\n",
    "year = '2017'\n",
    "season = 'DJF'\n",
    "chunk_size = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the anomaly for the AOI\n",
    "\n",
    "This may take a couple of minutes if the AOI is large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting data based on shapefile extent\n",
      "This script can only accept shapefiles with a single polygon feature; seasonal anomalies will calculated for the extent of the first geometry in the shapefile only.\n",
      "Loading ls5\n",
      "    Skipping ls5; no valid data for query\n",
      "Loading ls7\n",
      "    Skipping ls7; no valid data for query\n",
      "Loading ls8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-9f52bc10a98c>\", line 9, in <module>\n",
      "    chunk_size=chunk_size)\n",
      "  File \"src/anomalies.py\", line 220, in calculate_anomalies\n",
      "    dask_chunks = {'x': chunk_size, 'y': chunk_size})\n",
      "  File \"src/anomalies.py\", line 57, in load_landsat\n",
      "    **query)\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/datacube/api/core.py\", line 304, in load\n",
      "    grouped = self.group_datasets(observations, group_by)\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/datacube/api/core.py\", line 400, in group_datasets\n",
      "    for _, group in groupby(datasets, group_func)]\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/datacube/api/core.py\", line 400, in <listcomp>\n",
      "    for _, group in groupby(datasets, group_func)]\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/datacube/api/core.py\", line 392, in mk_group\n",
      "    dss = tuple(sorted(group, key=ds_sorter))\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/datacube/api/query.py\", line 319, in solar_day\n",
      "    solar_time = _convert_to_solar_time(utc, longitude)\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/datacube/api/query.py\", line 304, in _convert_to_solar_time\n",
      "    offset = datetime.timedelta(seconds=offset_seconds)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/inspect.py\", line 1488, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/inspect.py\", line 1446, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/posixpath.py\", line 403, in _joinrealpath\n",
      "    if isabs(rest):\n",
      "  File \"/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/posixpath.py\", line 67, in isabs\n",
      "    sep = _get_sep(s)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    }
   ],
   "source": [
    "anomalies = calculate_anomalies(veg_index=veg_index,\n",
    "                                from_shape=from_shape,\n",
    "                                shp_fpath=shp_fpath,\n",
    "                                lat=lat,\n",
    "                                lon=lon,\n",
    "                                buffer=buffer,\n",
    "                                year=year,\n",
    "                                season=season,\n",
    "                                chunk_size=chunk_size)\n",
    "\n",
    "anomalies = anomalies.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if veg_index == 'msavi':\n",
    "    anomalies.msavi_anomalies.plot(figsize=(10,10), vmin=-0.25, vmax=0.25, cmap='BrBG')\n",
    "if veg_index == 'ndvi':\n",
    "    anomalies.ndvi_anomalies.plot(figsize=(10,10), vmin=-0.25, vmax=0.25, cmap='BrBG')\n",
    "\n",
    "plt.title(season+ \" \" +year)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write geotiff to a location\n",
    "write_geotiff(veg_index+\"_\"+year+\"_\"+season+ '_anomalies.tif', anomalies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
