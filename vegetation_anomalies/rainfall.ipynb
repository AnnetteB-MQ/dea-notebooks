{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting seasonal rainfall anomalies\n",
    "\n",
    "This script takes as an input a `shapefile` with n number uniquely indentifiable polygons and exports a netcdf of per-pixel seasonal rainfall anomalies, and a csv of zonally averaged seasonal rainfall anomalies. Go to the `user inputs` section and enter the relevant information, then run the script.  The code is multiprocessed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "from datacube.utils import geometry\n",
    "from datacube.utils.geometry import CRS\n",
    "from dask.distributed import Client\n",
    "import fiona\n",
    "import rasterio.mask\n",
    "import rasterio.features\n",
    "import xarray as xr\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from multiprocessing import Pool\n",
    "\n",
    "#need a datacube confing:\n",
    "config = {\n",
    "    'db_hostname': 'agdcdev-db.nci.org.au',\n",
    "    'db_port': 6432,\n",
    "    'db_database': 'dg6911'\n",
    "}\n",
    "\n",
    "dc = datacube.Datacube(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up local dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete old client if one still exists\n",
    "client = locals().get('client', None)\n",
    "if client is not None:\n",
    "    client.close()\n",
    "    del client\n",
    "    \n",
    "client = Client(n_workers=4, threads_per_worker=1, memory_limit='6GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to shapefile\n",
    "shp_path = \"data/northern_basins.shp\"\n",
    "#time-range to extract from datacube\n",
    "time_range = ('1990-06-01', '2019-02-28')\n",
    "#time-range to calulate anomaly across\n",
    "anom_range = ('1990-06-01', '2011-02-28')\n",
    "#Attribute column in the shapefile that identified the polygon\n",
    "columnName = 'DNAME'\n",
    "#projection the output should be in\n",
    "projection = 'EPSG:3577'\n",
    "#resolution of the output\n",
    "resolution = (-750,750)\n",
    "#where should the results be stored\n",
    "output_dir = 'results/'\n",
    "#how many cpus should the analysis run on?\n",
    "ncpus = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract data and export to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RainfallFromShape(feat, crs, time_range, anom_range, colummName, output_dir, anomaly_type='standardised'):\n",
    "    \n",
    "    first_geom = feat['geometry']\n",
    "    poly_name = feat['properties'][columnName]\n",
    "    geom = geometry.Geometry(first_geom, crs=crs)\n",
    "\n",
    "    #generate query object\n",
    "    query = {'geopolygon': geom}\n",
    "    query['time'] = time_range\n",
    "    query['output_crs'] = CRS(projection)\n",
    "    query['resolution'] = resolution\n",
    "    query['dask_chunks'] = {'x':250, 'y':250}\n",
    "\n",
    "    #get rainfall data\n",
    "    print('Working on polygon: ' + poly_name)\n",
    "\n",
    "    accum_prcp = dc.load(product='accum_prcp_monthly', **query)\n",
    "    \n",
    "    #using plygon to mask extracted rainfall data\n",
    "    mask = rasterio.features.geometry_mask([geom.to_crs(accum_prcp.geobox.crs)for geoms in [geom]],\n",
    "                                                   out_shape=accum_prcp.geobox.shape,\n",
    "                                                   transform=accum_prcp.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=False)\n",
    "\n",
    "    mask_xr = xr.DataArray(mask, dims = ('y','x'))\n",
    "    accum_prcp = accum_prcp.where(mask_xr==False)\n",
    "\n",
    "    #resample to quarterly\n",
    "    prcp_quarterly = accum_prcp.resample(time='QS-JUN').sum('time')\n",
    "    #select out the time range to calculate anomaly over\n",
    "    prcp_quarterly_anom = prcp_quarterly.sel(time=slice(anom_range[0], anom_range[1]))\n",
    "    #calclate climatology mean \n",
    "    climatology_mean = prcp_quarterly_anom.groupby('time.season').mean('time')\n",
    "    \n",
    "    if anomaly_type == 'standardised':\n",
    "        climatology_std = prcp_quarterly_anom.groupby('time.season').std('time') \n",
    "        standard_anom = xr.apply_ufunc(\n",
    "                                    lambda x, m, s: (x - m) / s,\n",
    "                                    prcp_quarterly.groupby('time.season'),\n",
    "                                    climatology_mean, climatology_std,\n",
    "                                    dask='allowed')\n",
    "        #compute result\n",
    "        standard_anom = standard_anom.compute()\n",
    "        #export\n",
    "        standard_anom.to_netcdf(output_dir + poly_name + \"_rainfall_STDanomaly.nc\")\n",
    "   \n",
    "    else:\n",
    "        anomalies = prcp_quarterly_anom.groupby('time.season') - climatology_mean\n",
    "        #compute\n",
    "        anomalies = anomalies.compute()\n",
    "        #export\n",
    "        anomalies.to_netcdf(output_dir + poly_name + \"_rainfall_anomaly.nc\")\n",
    "      \n",
    "    #     df = anomalies.accum_prcp.mean(['x', 'y']).to_pandas()\n",
    "    #     df.to_csv(output_dir + poly_name + \"_rainfall_anomaly.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fiona.open(shp_path) as input:\n",
    "    crs = geometry.CRS(input.crs_wkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "p = Pool(ncpus)\n",
    "for feat in fiona.open(shp_path):\n",
    "        RainfallFromShape(feat, crs, time_range, anom_range, columnName, output_dir, anomaly_type='standardised') # single-cpu\n",
    "#     p.apply_async(RainfallFromShape, [feat, crs, time_range, columnName, output_dir]) # MULTIPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xr.open_dataarray('results/MURRAY-DARLING_rainfall_STDanomaly.nc').isel(time=114)\n",
    "x\n",
    "x.plot(figsize=(10,10), cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mean(['x', 'y']).mean()#plot(figsize=(15,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.isel(time=range(63,83)).plot(col='time', col_wrap=4, cmap='BrBG', vmin=-2.0, vmax=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
