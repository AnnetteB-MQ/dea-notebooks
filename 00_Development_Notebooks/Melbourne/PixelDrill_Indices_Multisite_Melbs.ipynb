{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel Drill for Indices outputs to CSV - Multi-site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Authors:  | Bex Dunn|\n",
    "|----------|----------------|\n",
    "| Created: | March 6, 2019 |\n",
    "| Last edited: | March 6, 2019 |\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "You need to run the following commands from the command line prior to launching jupyter notebooks from the same terminal so that the required libraries and paths are set:\n",
    "\n",
    "`module use /g/data/v10/public/modules/modulefiles` \n",
    "\n",
    "`module load dea`\n",
    "\n",
    "If you find an error or bug in this notebook, please either create an 'Issue' in the Github repository, or fix it yourself and create a 'Pull' request to contribute the updated notebook back into the repository (See the repository [README](https://github.com/GeoscienceAustralia/dea-notebooks/blob/master/README.rst) for instructions on creating a Pull request).\n",
    "\n",
    "__Background:__ Data from the [Landsat](https://landsat.usgs.gov/about-landsat) 5,7 and 8 satellite missions are accessible through [Digital Earth Australia](http://www.ga.gov.au/about/projects/geographic/digital-earth-australia) (DEA).\n",
    "\n",
    "__What does this notebook do?:__ This notebook takes a supplied CSV of site points. It runs a pixel drill through surface reflectance, calculates NDVI, Taselled cap wetness and greenness, and outputs a csv of values for each site and plots of each index for each site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tags**: :index:`Landsat`,:index:`Landsat5`,:index:`Landsat7`,:index:`Landsat8`, :index:`pixeldrill`, :index:`DEAPlotting`, :index:`datacube.utils.geometry`, :index:`query`,:index:`Scripts`,:index:`tasseled_cap`, :index:`NDVI`,                                                                                                           :index:`DEADataHandling`, :index:`DEAPlotting`, :index:`load_clearlandsat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import some modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "import datetime\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio.mask\n",
    "import rasterio.features\n",
    "import shapely\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datacube.storage import masking\n",
    "from datacube.utils import geometry\n",
    "\n",
    "sys.path.append('../../10_Scripts')\n",
    "import DEADataHandling, DEAPlotting, TasseledCapTools, BandIndices\n",
    "\n",
    "dc = datacube.Datacube(app='pixel drill')\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "#set up file to open "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath = '/g/data/r78/rjd547/Melbourne_water/50 more points to check.csv'\n",
    "### Convert csv latitude and longitude values into a geopandas geodatafrome\n",
    "\n",
    "sites = pd.read_csv(inpath, delimiter=\",\")\n",
    "#turn csv geometry into geopandas dataframe geometry using lambda functions and shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites['x']=sites['lat']\n",
    "sites['y']=sites['long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running for index 0\n",
      "/g/data/r78/rjd547/Melbourne_water/points/point_-38.27652174_145.57951719999997.csv\n",
      "Loading ls5\n",
      "    Loading 208 filtered ls5 timesteps\n",
      "Loading ls7\n",
      "    Loading 257 filtered ls7 timesteps\n",
      "Loading ls8\n",
      "    Loading 142 filtered ls8 timesteps\n",
      "Combining and sorting ls5, ls7, ls8 data\n",
      "    Replacing invalid -999 values with NaN (data will be coerced to float64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-690d9182493d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mtcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mtcis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtcw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtcg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m#     #make a new dataframe using the data from the xarray of ndvi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/xarray/core/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, dim, data_vars, coords, compat, positions, indexers, mode, concat_over, fill_value)\u001b[0m\n\u001b[1;32m    117\u001b[0m         raise TypeError('can only concatenate xarray Dataset and DataArray '\n\u001b[1;32m    118\u001b[0m                         'objects, got %s' % type(first_obj))\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/xarray/core/concat.py\u001b[0m in \u001b[0;36m_dataarray_concat\u001b[0;34m(arrays, dim, data_vars, coords, compat, positions, fill_value)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdata_vars\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'all'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         raise ValueError('data_vars is not a valid argument when '\n\u001b[1;32m    326\u001b[0m                          'concatenating DataArray objects')\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/xarray/core/common.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__float__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "sites['geometry']=sites.apply(lambda z: shapely.geometry.Point(z.x, z.y), axis=1)\n",
    "sites = gpd.GeoDataFrame(sites)\n",
    "sites.head()\n",
    "\n",
    "#define an output location\n",
    "output_loc = '/g/data/r78/rjd547/Melbourne_water/points/point_'\n",
    "\n",
    "### run this for multiple sites\n",
    "\n",
    "for site in range(0,1):#(len(sites)),1):    \n",
    "    print(f'running for index {site}')\n",
    "    lon = sites['x'][site]\n",
    "    lat = sites['y'][site]\n",
    "    query = {'lat':lat, \n",
    "          'lon':lon}               \n",
    "    #print(query)\n",
    "    outfilename=f'{output_loc}{lat}_{lon}.csv'\n",
    "    print (outfilename)\n",
    "\n",
    "    try:\n",
    "        ls578 = DEADataHandling.load_clearlandsat(dc=dc, query=query, product='nbart', ls7_slc_off=True)\n",
    "    except:\n",
    "        print ('nah')\n",
    "        ### Calculate NDVI \n",
    "\n",
    "    ### Calculate the tasseled cap indices\n",
    "    tci = TasseledCapTools.thresholded_tasseled_cap(ls578,wetness_threshold=-350, drop=True , drop_tc_bands=False)\n",
    "    tcw = tci.wetness\n",
    "    tcg = tci.greenness\n",
    "    tcb = tci.brightness \n",
    "\n",
    "    ### create and fill pandas dataframe to write to csv\n",
    "\n",
    "    #drop dimensions of length 1\n",
    "    tcw = tcw.squeeze(['x','y'])\n",
    "    tcg = tcg.squeeze(['x','y'])\n",
    "    tcb = tcb.squeeze(['x','y'])\n",
    "    \n",
    "    #     #make a new dataframe using the data from the xarray of ndvi\n",
    "    INDICIES = pd.DataFrame(data=[tcw.data,tcg.data,tcb.data], index=tcw.time.values,columns=['TCW','TCG','TCB'])\n",
    "    INDICIES.to_csv(outfilename)\n",
    "\n",
    "    !ls /g/data/r78/rjd547/Melbourne_water/points/*.csv     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
