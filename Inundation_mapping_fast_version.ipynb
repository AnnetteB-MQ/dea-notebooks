{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping waterbodies according to flow\n",
    "This notebook merges stream gauge data with satellite data. The user can select a part of the flow duration curve for a chosen gauge then display where the water goes at that flow range. This version was written for hydrologists. The publically available fully marked down version is in the Case_Studies file in your home directory of the sandbox. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a box, click on it and press 'Shift' + 'Enter'. If you ever want to clear it again, click on the Kernel tab in the top left and select Restart Kernal and Clear All Outputs... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Load key Python packages and supporting functions for the analysis. This notebook relies on a module called `dea_bom`, which is located in the `Scripts` directory. This box retrieves data from the Bureau of Meteorology (BOM) [Water Data Online](http://www.bom.gov.au/waterdata/) webpage using the `dea_bom` module.\n",
    "We restrict the list of gauges to locations that we have identified as having valid data. Please note that the data in this example is cached. If you wish to access the live BOM website, you will need to go into the Scripts folder and move the file called stations.pkl (which is the cache) out of there so the code can't find it, then it will go to the website instead of using that cahce. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import datacube\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "from datacube.storage import masking\n",
    "from datacube.utils import geometry \n",
    "from datacube.utils.geometry import CRS\n",
    "from datacube.helpers import write_geotiff\n",
    "\n",
    "sys.path.append('Scripts')\n",
    "import dea_bom\n",
    "\n",
    "dc = datacube.Datacube(app='Inundation_mapping')\n",
    "\n",
    "stations_pkl = Path('Scripts/stations.pkl')\n",
    "\n",
    "# If cache exists, get station data from cache\n",
    "if stations_pkl.exists():\n",
    "    print('Loading from cache')\n",
    "    stations = pickle.load(open(str(stations_pkl), 'rb'))\n",
    "else:\n",
    "    print('Fetching from BoM')\n",
    "    stations = dea_bom.get_stations()\n",
    "    pickle.dump(stations, open(str(stations_pkl), 'wb'))\n",
    "\n",
    "# Filter list to stations with available data\n",
    "stations_with_data = pickle.load(open(str('Scripts/stations_with_data.pkl'), 'rb'))\n",
    "stations = [i for i in stations if i.name in stations_with_data]\n",
    "\n",
    "# Preview the first five stations loaded\n",
    "print(f'{len(stations)} stations loaded; e.g.:')\n",
    "stations[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a map of stations and select a gauge that contains data\n",
    "\n",
    "Running this cell will generate a map displaying the locations of stream gauges in Australia. It will take about 20 seconds to load. Choose a gauge on the map by clicking on it. Note that after you click on a gauge it can take a second or two to respond. \n",
    "\n",
    "When you have the station you want, **click the Done button before moving onto the next box**. If you don't click Done then the rest of the code won't run. If you want to choose a different gauge after having pressed the `Done` button, you must re-run this box to regenerate the map then choose another gauge and press `Done` again. \n",
    "\n",
    "> **Note:** If all gauges you click on return \"0 observations\", this could indicate an issue with fetching data from the BOM webpage. In this case, re-start the notebook and try again later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_data, station = dea_bom.ui_select_station(stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a flow duration curve from the data selected above\n",
    "This box will generate a Flow Duration Curve from the gauge data. You can then choose which flow rate values to analyse. \n",
    "\n",
    "The code in the box below will automatically select the latitude and longitude of the selected gauge, but you can enter a different `lat` and `lon` if you want by editing the commented out `lat` and `lon` lines in the code below. \n",
    "The output will tell you what `lat` and `lon` has been selected. \n",
    "The `buffer`, which is the radius around the location point, is set to 8000 meters but you can change it if you like.\n",
    "\n",
    "> **Note:** If nothing happens when you run this cell, **return to the previous cell and click the Done button**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lat and lon takes the location of the gauge. You can change the lat \n",
    "# and lon to a different location if necessary, just comment out out this \n",
    "# lat, lon = pos line below and define your own.\n",
    "lat, lon = station.pos\n",
    "\n",
    "# lat =\n",
    "# lon =\n",
    "\n",
    "# The buffer is how many meters radius around the location you want to display.\n",
    "buffer = 8000\n",
    "\n",
    "# Rearranging data into a flow duration curve\n",
    "gauge_data = gauge_data.dropna()\n",
    "gauge_data = gauge_data.sort_values('Value')\n",
    "gauge_data['rownumber'] = np.arange(len(gauge_data))\n",
    "gauge_data['Exceedence'] = (1 - (gauge_data.rownumber / len(gauge_data))) * 100\n",
    "\n",
    "# Plotting the flow duration curve\n",
    "gauge_data.plot(x='Exceedence', y='Value', figsize=(11, 7))\n",
    "plt.ylabel('Cubic meters per second')\n",
    "plt.grid(True)\n",
    "plt.title('FDC')\n",
    "\n",
    "print(f'You have selected: lat = {lat}')\n",
    "print(f'You have selected: lon = {lon}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter the y-axis parameters in cubic meters per second\n",
    "Please change the y-axis parameters in the box below based on the FDC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What part of the Flow Duration Curve do you want to look at?\n",
    "yaxis_lower_parameter = 50\n",
    "yaxis_higher_parameter = 150\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot the data on a log scale\n",
    "gauge_data.plot(x='Exceedence',\n",
    "                y='Value',\n",
    "                logy=True,\n",
    "                title='Selected range displayed on a log scale',\n",
    "                figsize=(11, 7))\n",
    "plt.axhspan(yaxis_lower_parameter,\n",
    "            yaxis_higher_parameter,\n",
    "            color='red',\n",
    "            alpha=0.2)\n",
    "plt.ylabel('Cubic meters per second (log)');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the gauge data with the satellite data\n",
    "The output of this box will tell you how many satellite passes you are about to load. If you want more passes, you will have to broaden the FDC parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up a query which defines the area and time period to load data for\n",
    "x, y = geometry.point(lon, lat, CRS('WGS84')).to_crs(CRS('EPSG:3577')).points[0]\n",
    "query = {'x': (x - buffer, x + buffer),\n",
    "         'y': (y - buffer, y + buffer),    \n",
    "         'time': ('2016-01-01', '2019-10-01'), # Change this date accordingly\n",
    "         'crs': 'EPSG:3577'} \n",
    "\n",
    "# Dask load wofs_albers data (this loads the dataset parameters only, \n",
    "# not the actual satellite data)\n",
    "wofs_albers = dc.load(product = 'wofs_albers', \n",
    "                      dask_chunks = {}, \n",
    "                      group_by='solar_day', \n",
    "                      **query)\n",
    "\n",
    "# Merging satellite data with gauge data by timestamp\n",
    "gauge_data_xr = gauge_data.to_xarray()\n",
    "merged_data = gauge_data_xr.interp(Timestamp=wofs_albers.time, method='nearest')\n",
    "\n",
    "# Here is where it takes into account user input for the FDC\n",
    "specified_level = merged_data.where((merged_data.Value > yaxis_lower_parameter) & \n",
    "                                    (merged_data.Value < yaxis_higher_parameter), \n",
    "                                    drop=True)\n",
    "\n",
    "# Get list of dates to keep\n",
    "date_list = specified_level.time.values\n",
    "\n",
    "print(f'You are about to load {specified_level.time.shape[0]} satellite passes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the image\n",
    "This box includes a cloudmasking step. The output will tell you how many passes you got after cloudmasking. It will also generate a frequency image of what the water body looked like while the gauge was reading the specified flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the passes that happened during the specified flow parameters\n",
    "specified_passes = wofs_albers.sel(time=date_list).compute()\n",
    "\n",
    "# Calculate the number of cloudy pixels per timestep\n",
    "cc = masking.make_mask(specified_passes.water, cloud=True)\n",
    "ncloud_pixels = cc.sum(dim=['x', 'y'])\n",
    "\n",
    "# Calculate the total number of pixels per timestep\n",
    "npixels_per_slice = (specified_passes.water.shape[1] * \n",
    "                     specified_passes.water.shape[2])\n",
    "\n",
    "# Calculate the proportion of cloudy pixels\n",
    "cloud_pixels_fraction = (ncloud_pixels / npixels_per_slice)\n",
    "\n",
    "# Filter out \"too cloudy\" passes (i.e. more than 50% cloud)\n",
    "clear_specified_passes = specified_passes.water.isel(\n",
    "    time=cloud_pixels_fraction < 0.5)\n",
    "\n",
    "print(f'After cloud filtering, there are '\n",
    "      f'{clear_specified_passes.time.shape[0]} passes available, which were used to make this image\\n')\n",
    "\n",
    "\n",
    "\n",
    "# Identify all wet and dry pixels\n",
    "wet = masking.make_mask(clear_specified_passes, wet=True).sum(dim='time')\n",
    "dry = masking.make_mask(clear_specified_passes, dry=True).sum(dim='time')\n",
    "\n",
    "# Calculate how frequently each pixel was wet when it was observed\n",
    "clear = wet + dry\n",
    "frequency = wet / clear\n",
    "\n",
    "# Remove persistent NAs that occur due to mountain shadows\n",
    "frequency = frequency.fillna(0)  \n",
    "\n",
    "# Set pixels that remain dry 100% of the time to nodata so they appear white\n",
    "frequency = frequency.where(frequency != 0)  \n",
    "\n",
    "#Plotting the image\n",
    "frequency.plot(figsize = (16, 12))\n",
    "plt.axis('off')\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(16, 6))\n",
    "\n",
    "ax1 = frequency.plot(ax=ax[0])\n",
    "\n",
    "ax2 = gauge_data.plot(x='Exceedence', y='Value', ax=ax[1]) \n",
    "ax2 = plt.axhspan(yaxis_lower_parameter, yaxis_higher_parameter, color='red', alpha=0.2)\n",
    "ax2 = plt.title('This was the specified range for which the image was generated (FDC log)')\n",
    "ax2 = plt.ylabel('cubic meters per second (log)')\n",
    "ax2 = plt.xlabel('Exceedence')\n",
    "ax2 = plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the file as a GeoTIFF\n",
    "You might want to use this water frequency image in another workflow.\n",
    "The following code will export the image as a `.tif` GeoTIFF file that can be loaded into common GIS software (e.g. ArcMap or QGIS). \n",
    "\n",
    "Enter a name for the `.tif` file below. \n",
    "The `../` part of the name means it will save this file one directory up from where this notebook is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the output file name \n",
    "file_name = '../file_name_here.tif'\n",
    "\n",
    "# Set up the file for writing\n",
    "frequency_dataset = frequency.to_dataset()\n",
    "frequency_dataset.attrs=wofs_albers.attrs\n",
    "\n",
    "# Write GeoTIFF to a location\n",
    "write_geotiff(file_name, frequency_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
