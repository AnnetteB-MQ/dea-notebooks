{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing current and collection upgrade Landsat data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does this notebook do?** \n",
    "\n",
    "This notebook demonstrates how to load matching data from both the current collection and the collection upgrade databases, make both datasets consistent, then conduct some very basic comparisons of values for each band. This is intended to serve as a starting point for more advanced comparisons of the two collections. \n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "You need to run the following commands from the command line prior to launching jupyter notebooks from the same terminal so that the required libraries and paths are set:\n",
    "\n",
    "`module use /g/data/v10/public/modules/modulefiles` \n",
    "\n",
    "`module load dea` \n",
    "\n",
    "This notebook uses external functions `rgb` and `display_map`. These functions is available in the `10_Scripts` folder of the [dea-notebooks Github repository](https://github.com/GeoscienceAustralia/dea-notebooks/tree/master/10_Scripts). Note that these functions have been developed by DEA users, not the DEA development team, and so are provided without warranty. If you find an error or bug in the functions, please either create an 'Issue' in the Github repository, or fix it yourself and create a 'Pull' request to contribute the updated function back into the repository (See the repository [README](https://github.com/GeoscienceAustralia/dea-notebooks/blob/master/README.rst) for instructions on creating a Pull request).\n",
    "\n",
    "**Date:** February 2019\n",
    "\n",
    "**Author:** Robbi Bishop-Taylor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`collection_upgrade`, :index:`Scripts`, :index:`surface_reflectance`, :index:`Landsat`, :index:`Landsat8`, :index:`query`, :index:`dc.load`, :index:`rgb`, :index:`display_map`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database access\n",
    "Create a config file in your home directory named `.ard-interoperability_tmp.conf` containing the following info:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[datacube]\n",
    "db_hostname: agdcstaging-db.nci.org.au\n",
    "db_port:     6432\n",
    "db_database: ard_interop\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T23:21:03.503622Z",
     "start_time": "2019-03-27T23:21:01.765055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJCS[\"GDA_1994_MGA_Zone_54\",GEOGCS[\"GCS_GDA_1994\",DATUM[\"Geocentric_Datum_of_Australia_1994\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101],TOWGS84[0,0,0,0,0,0,0]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",500000.0],PARAMETER[\"False_Northing\",10000000.0],PARAMETER[\"Central_Meridian\",141.0],PARAMETER[\"Scale_Factor\",0.9996],PARAMETER[\"Latitude_Of_Origin\",0.0],UNIT[\"Meter\",1.0],AUTHORITY[\"EPSG\",\"28354\"]]\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import datacube \n",
    "import xarray as xr\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from datacube.storage import masking\n",
    "import fiona\n",
    "from datacube.utils import geometry\n",
    "\n",
    "dc = datacube.Datacube()\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../10_Scripts')\n",
    "import DEAPlotting, SpatialTools\n",
    "from datacube.storage.storage import write_dataset_to_netcdf\n",
    "\n",
    "output_dir = '/g/data/r78/vmn547/delwp/output'\n",
    "shape_file = '/g/data/r78/vmn547/delwp/SHPs_CKrause/GHCMA_Lower G3_region.shp'\n",
    "shp_name = shape_file.split('/')[-1].split('.')[0].replace(' ','_')\n",
    "with fiona.open(shape_file) as shapes:\n",
    "    crs = geometry.CRS(shapes.crs_wkt) \n",
    "    print(crs)\n",
    "    shapes_list = list(shapes)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up query and analysis parameters\n",
    "Here we set a centroid for the area we want to compare, and set up CRS, resolution and resampling that will be applied to both collectiondatasets. The values below extract both collections to match the collection upgrade CRS and resolution (UTM zone 56 S and 30m pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T23:21:25.701662Z",
     "start_time": "2019-03-27T23:21:24.741859Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Centre point of spatial query\n",
    "lat, lon = -33.324, 149.09\n",
    "time_period = ('1987-01-01', '2019-04-01')\n",
    "\n",
    "# Desired output resolution and projection for both datasets\n",
    "\n",
    "output_resolution = (30, 30)\n",
    "output_resamp_continuous = 'bilinear'\n",
    "output_resamp_categorical = 'nearest'\n",
    "\n",
    "product ='nbart'\n",
    "\n",
    "# Bands/measurements to load\n",
    "\n",
    "currentcollection_bands = ['red', 'blue', 'green', 'nir', 'swir1', 'swir2']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in current collection data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T23:26:17.001937Z",
     "start_time": "2019-03-27T23:26:02.953357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 6, x: 1456, y: 1115)\n",
       "Coordinates:\n",
       "  * y        (y) float64 -4.117e+06 -4.117e+06 ... -4.145e+06 -4.145e+06\n",
       "  * x        (x) float64 8.248e+05 8.248e+05 8.248e+05 ... 8.611e+05 8.612e+05\n",
       "  * time     (time) datetime64[ns] 2019-01-01T00:21:52 ... 2019-02-26T00:15:29.500000\n",
       "Data variables:\n",
       "    red      (time, y, x) float64 1.083e+03 1.097e+03 ... 2.007e+03 1.899e+03\n",
       "    blue     (time, y, x) float64 503.0 518.0 516.0 ... nan 1.229e+03 996.0\n",
       "    green    (time, y, x) float64 784.0 785.0 795.0 ... nan 1.554e+03 1.374e+03\n",
       "    nir      (time, y, x) float64 2.229e+03 2.263e+03 ... 3.092e+03 3.043e+03\n",
       "    swir1    (time, y, x) float64 3.238e+03 3.33e+03 ... 4.252e+03 4.267e+03\n",
       "    swir2    (time, y, x) float64 2.11e+03 2.225e+03 ... 3.148e+03 2.941e+03\n",
       "Attributes:\n",
       "    crs:      EPSG:3577"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "for shape in shapes_list:\n",
    "    first_geometry = shape['geometry']\n",
    "    shp_id = shape['properties']['ID']\n",
    "\n",
    "    geom = geometry.Geometry(first_geometry, crs=crs)\n",
    "    current_time = datetime.now()\n",
    "    time_period = ('2019-01-01', current_time.strftime('%m/%d/%Y'))\n",
    "    query = {'geopolygon': geom, 'time': time_period}\n",
    "    # Set up query\n",
    "\n",
    "    xarray_dict = {}\n",
    "    for sensor in ['ls5','ls7','ls8']:\n",
    "\n",
    "        # Load data \n",
    "        landsat_ds = dc.load(product = f'{sensor}_{product}_albers', \n",
    "                             measurements = currentcollection_bands,\n",
    "                             group_by = 'solar_day', \n",
    "                             **query)\n",
    "        \n",
    "        if len(landsat_ds.attrs)>0:\n",
    "            \n",
    "            # Load PQ data \n",
    "            landsat_pq = dc.load(product = f'{sensor}_pq_albers', \n",
    "                                 measurements = ['pixelquality'],\n",
    "                                 group_by = 'solar_day', \n",
    "                                 **query)                       \n",
    "\n",
    "            # Filter to subset of Landsat observations that have matching PQ data \n",
    "            time = (landsat_ds.time - landsat_pq.time).time\n",
    "            landsat_ds = landsat_ds.sel(time=time)\n",
    "            landsat_pq = landsat_pq.sel(time=time)\n",
    "\n",
    "            # Create PQ mask\n",
    "            good_quality = masking.make_mask(landsat_pq.pixelquality,\n",
    "                                             cloud_acca='no_cloud',\n",
    "                                             cloud_shadow_acca='no_cloud_shadow',\n",
    "                                             cloud_shadow_fmask='no_cloud_shadow',\n",
    "                                             cloud_fmask='no_cloud',\n",
    "                                             blue_saturated=False,\n",
    "                                             green_saturated=False,\n",
    "                                             red_saturated=False,\n",
    "                                             nir_saturated=False,\n",
    "                                             swir1_saturated=False,\n",
    "                                             swir2_saturated=False,\n",
    "                                             contiguous=True) \n",
    "\n",
    "            # Apply mask to set all PQ-affected pixels to NaN and set nodata to NaN\n",
    "            landsat_ds = landsat_ds.where(good_quality)\n",
    "            \n",
    "            # Add result to dict\n",
    "            xarray_dict[sensor] = landsat_ds\n",
    "        #fname = os.path.join(output_dir, f'{product}/collection2/c2_{sensor}_{product}_albers_2012_01_2019_02.nc')\n",
    "        #write_dataset_to_netcdf(landsat_ds,fname)\n",
    "    # Concatenate multiple sensors into one dataset\n",
    "    landsat_currentcollection = xr.concat(xarray_dict.values(), dim='time')\n",
    "    landsat_currentcollection = landsat_currentcollection.sortby('time')\n",
    "    fname = os.path.join(output_dir, f'c2_ls_{product}_albers_{shp_name}_{shp_id}_test.nc')\n",
    "    write_dataset_to_netcdf(landsat_currentcollection,fname)\n",
    "landsat_currentcollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
