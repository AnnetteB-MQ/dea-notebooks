{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General advice (delete this cell before submitting for review)\n",
    "\n",
    "> * When choosing a location for your analysis, **select an area that has data on both the NCI and DEA Sandbox** to allow your code to be run on both environments. \n",
    "For example, you can check this for Landsat using the [DEA Explorer](https://explorer.sandbox.dea.ga.gov.au/ga_ls5t_ard_3/1990) (use the drop-down menu to view all products).\n",
    "As of September 2019, the `DEA Sandbox` has a single year of continental Landsat data for 2015-16, and the full 1987-onward time-series for three locations (Perth WA, Brisbane QLD, and western NSW).\n",
    "> * When adding **Products used**, embed the hyperlink to that specific product on the DEA Explorer using the `[product_name](product url)` syntax.\n",
    "> * When writing in Markdown cells, start each sentence on a **new line**.\n",
    "This makes it easy to see changes through git commits.\n",
    "> * Use Australian English in markdown cells and code comments.\n",
    "> * Check the [known issues](https://github.com/GeoscienceAustralia/dea-docs/wiki/Known-issues) for formatting regarding the conversion of notebooks to DEA docs using Sphinx.\n",
    "Things to be aware of:\n",
    "    * Sphinx is highly sensitive to bulleted lists:\n",
    "        * Ensure that there is an empty line between any preceding text and the list\n",
    "        * Only use the `*` bullet (`-` is not recognised)\n",
    "        * Sublists must be indented by 4 spaces\n",
    "    * Two kinds of formatting cannot be used simultaneously:\n",
    "        * Hyperlinked code: \\[\\`code_format\\`](hyperlink) fails\n",
    "        * Bolded code: \\*\\*\\`code_format\\`\\*\\* fails\n",
    "    * Headers must appear in heirachical order (`#`, `##`, `###`, `####`) and there can only be one title (`#`).\n",
    "> * Use the [PEP8 standard](https://www.python.org/dev/peps/pep-0008/) for code. To make sure all code in the notebook is consistent, you can use the `jupyterlab_code_formatter` tool: select each code cell, then click `Edit` and then one of the `Apply X Formatter` options (`YAPF` or `Black` are recommended). This will reformat the code in the cell to a consistent style.\n",
    "> * For additional guidance, refer to the style conventions and layouts in approved `develop` branch notebooks. \n",
    "Examples include\n",
    "    * [Frequently_used_code/Using_load_ard.ipynb](./Frequently_used_code/Using_load_ard.ipynb)\n",
    "    * [Real_world_examples/Coastal_erosion.ipynb](./Real_world_examples/Coastal_erosion.ipynb)\n",
    "    * [Scripts/dea_datahandling.py](./Scripts/dea_datahandling.py)\n",
    "> * The DEA Image placed in the title cell will display as long as the notebook is contained in one of the standard directories.\n",
    "It does not work in the highest level directory (hence why it doesn't display in the original template notebook).\n",
    "> * In the final notebook cell, include a set of relevant tags which are used to build the DEA User Guide's [Tag Index](https://docs.dea.ga.gov.au/genindex.html). \n",
    "Use all lower-case (unless the tag is an acronym), separate words with spaces (unless it is the name of an imported module), and [re-use existing tags](https://github.com/GeoscienceAustralia/dea-notebooks/wiki/List-of-tags).\n",
    "Ensure the tags cell below is in `Raw` format, rather than `Markdown` or `Code`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Landsat Collection 3 vegetation-related indicies <img align=\"right\" src=\"../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatability:** Notebook currently compatible with the `NCI`|`DEA Sandbox` environment only\n",
    "* **Products used:** \n",
    "[ga_ls5t_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls5t_ard_3),\n",
    "[ga_ls7e_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls7e_ard_3),\n",
    "[ga_ls8c_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls8c_ard_3)\n",
    "* **Special requirements:** An _optional_ description of any special requirements, e.g. If running on the [NCI](https://nci.org.au/), ensure that `module load otps` is run prior to launching this notebook\n",
    "* **Prerequisites:** An _optional_ list of any notebooks that should be run or content that should be understood prior to launching this notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "An *optional* overview of the scientific, economic or environmental management issue or challenge being addressed by Digital Earth Australia. \n",
    "For `Beginners_Guide` or `Frequently_Used_Code` notebooks, this may include information about why the particular technique or approach is useful or required. \n",
    "If you need to cite a scientific paper or link to a website, use a persistent DOI link if possible and link in-text (e.g. [Dhu et al. 2017](https://doi.org/10.1080/20964471.2017.1402490))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "A _compulsory_ description of the notebook, including a brief overview of how Digital Earth Australia helps to address the problem set out above.\n",
    "It can be good to include a run-down of the tools/methods that will be demonstrated in the notebook:\n",
    "\n",
    "1. First we do this\n",
    "2. Then we do this\n",
    "3. Finally we do this\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "Provide any particular instructions that the user might need, e.g. To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import Python packages that are used for the analysis.\n",
    "\n",
    "Use standard import commands; some are shown below. \n",
    "Begin with any `iPython` magic commands, followed by standard Python packages, then any additional functionality you need from the `Scripts` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import datacube\n",
    "from datacube.storage import masking\n",
    "from datacube.helpers import write_geotiff\n",
    "\n",
    "# Load custom DEA notebook functions\n",
    "sys.path.append('../dea-notebooks/Scripts')\n",
    "import dea_datahandling\n",
    "import dea_plotting\n",
    "import DEADataHandling\n",
    "from dea_bandindices import calculate_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "\n",
    "Connect to the datacube so we can access DEA data.\n",
    "The `app` parameter is a unique name for the analysis which is based on the notebook file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dc_landsat3 = datacube.Datacube(app='NDVI_Export', env='c3-samples')\n",
    "except:\n",
    "    dc_landsat3 = datacube.Datacube(app='NDVI_Export')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the notebook\n",
    "\n",
    "If running this notebook locally, use the smaller spatial extent and subset of the time series. \n",
    "\n",
    "If running on gadi, the the temporal and spatial extent can be increased.  \n",
    "\n",
    "> **Note:** Landsat imagery is available from 1987 onwards. \n",
    "\n",
    "### Exporting data\n",
    "In order to use the datacube.helpers write_geotiff function to export a simple single-band, single time-slice geotiff the above xarray DataArrays need to be converted to xarray Datasets. \n",
    "\n",
    "We do this be using the xarray function .to_dataset. If you don't do this, the write_geotiff fucntion will return an error. \n",
    "\n",
    "We also need to reassign the coordinate reference system before the write_geotiff function will work. This is done by the .attrs function. We take the crs from the original imported data (ds). \n",
    "\n",
    "Each file will be exported as a geotiff and saved in the same directory as this notebook. It can be downloaded from this location to the GA network using FileZilla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters\n",
    "\n",
    "* `dry_month`: Specific month of the year that correspond with dry season/low rainfall conditions. Values range from 1-12. \n",
    "* `wet_month`: Specific month of the year that correspond with dry season/low rainfall conditions. Values range from 1-12. \n",
    "* `coords_lon`: Longitudinal coordinates that are used to define the area of interest and divide the area of interest into smalled sub-areas for looping.\n",
    "* `coords_lat`: Latitudinal coordinates that are used to define the area of interest and divide the area of interest into smalled sub-areas for looping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_month = 9\n",
    "wet_month = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create series of coordinates (with a fixed increment; 0.10 deg)\n",
    "coords_lon = np.arange(132.07, 135.46, 0.05)\n",
    "coords_lat = np.arange(-20.31, -23.10, -0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set variable for path to save files\n",
    "savefilepath = '/g/data/zk34/ljg547/Outputs/'\n",
    "\n",
    "# Set project naming convention. \n",
    "Proj = 'SSC_WDTT_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For loop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ga_ls5t_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Loading ga_ls7e_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Loading ga_ls8c_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Combining and sorting data\n",
      "    Returning 846 observations \n",
      "0 0\n",
      "Loading ga_ls5t_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Loading ga_ls7e_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Loading ga_ls8c_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Combining and sorting data\n",
      "    Returning 846 observations \n",
      "0 1\n",
      "Loading ga_ls5t_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Loading ga_ls7e_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Loading ga_ls8c_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Combining and sorting data\n",
      "    Returning 846 observations \n",
      "0 2\n",
      "Loading ga_ls5t_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Loading ga_ls7e_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Loading ga_ls8c_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Combining and sorting data\n",
      "    Returning 846 observations \n",
      "0 3\n",
      "Loading ga_ls5t_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Loading ga_ls7e_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Loading ga_ls8c_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Combining and sorting data\n",
      "    Returning 846 observations \n",
      "0 4\n",
      "Loading ga_ls5t_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Loading ga_ls7e_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Loading ga_ls8c_ard_3 data\n",
      "    Applying pixel quality/cloud mask\n",
      "    Applying invalid data mask\n",
      "    Applying contiguity mask\n",
      "Combining and sorting data\n",
      "    Returning 846 observations \n",
      "0 5\n",
      "Loading ga_ls5t_ard_3 data\n"
     ]
    }
   ],
   "source": [
    "for i in range(coords_lon.size-2):\n",
    "#    i = 11\n",
    "    for j in range(coords_lat.size-2):\n",
    "#        j = 13\n",
    "        query_3 = {'lon': coords_lon[i:(i+2)],\n",
    "        'lat': coords_lat[j:(j+2)],             # full study area\n",
    "#        'time':('2015-01', '2018-12'),       # subset of time-series\n",
    "        'time':('1987-01', '2018-12'),       # full time-series\n",
    "        'output_crs': 'EPSG:28352',\n",
    "        'resolution': (30, 30),\n",
    "        'group_by': 'solar_day'\n",
    "        }   \n",
    " \n",
    "        # Load Landsat data from Collection 3 using .load_ard.\n",
    "        # mask_dtype = np.float16 helps to keep the memory down, however, the data will need to be converted back to float34 later.\n",
    "        ds = dea_datahandling.load_ard(dc=dc_landsat3,\n",
    "        mask_dtype = np.float16,\n",
    "        products=['ga_ls5t_ard_3', 'ga_ls7e_ard_3', 'ga_ls8c_ard_3'], \n",
    "        measurements=['nbart_red','nbart_nir','nbart_green',\n",
    "                                              'nbart_blue','nbart_swir_1','nbart_swir_2'],\n",
    "        mask_contiguity='nbart_contiguity', \n",
    "        **query_3)\n",
    "    \n",
    "        ds_startDate = str(ds.isel(time=0).time.values)[0:10]\n",
    "        ds_startDate = str(ds_startDate[0:4] + f'{int(ds_startDate[6:7]):02d}' + \n",
    "                              f'{int(ds_startDate[9:10]):02d}')\n",
    "\n",
    "        ds_endDate = str(ds.isel(time=-1).time.values)[0:10]\n",
    "        ds_endDate = str(ds_endDate[0:4] + f'{int(ds_endDate[6:7]):02d}' + \n",
    "                              f'{int(ds_endDate[9:10]):02d}')\n",
    "        \n",
    "        # Calculate NDVI. NDVI is added to ds as a new band as shown in the below display\n",
    "        calculate_indices(ds,index = 'NDVI', collection = 'ga_ls_3',\n",
    "                normalise = True, deep_copy = False)\n",
    "        \n",
    "        ndvi = ds.NDVI\n",
    "    \n",
    "        # Dry Month\n",
    "        # Group available NDVI time-steps into dry month for later monthly averaging\n",
    "        ndvi_dryMonth = ndvi[ndvi['time.month'].isin(dry_month)]\n",
    "    \n",
    "        # Calculate median NDVI for the 'dry' month (through time and for each pixel)\n",
    "        median_ndvi_dry = ndvi_dryMonth.groupby('time.month').median(dim = 'time').median(dim='month')\n",
    "        \n",
    "        # Convert from float16 to float32\n",
    "        arr = median_ndvi_dry.astype(dtype='float32')\n",
    "        \n",
    "        # Convert from DataArray to Dataset\n",
    "        arr = arr.to_dataset(name='median_NDVI_dry')\n",
    "        \n",
    "        # Assign CRS from original DataArray\n",
    "        arr.attrs = ds.attrs\n",
    "         \n",
    "        # Generating naming convention for files based on Project area (Proj), specified dry season and time series start and end dates. \n",
    "        fname = str(savefilepath + Proj + 'medianNDVIDry_' +\n",
    "                      ds_startDate + '_' + ds_endDate + '_' + \n",
    "                      \"Lon\" + str(i) + \"Lat\" + str(j) + '.tif')   \n",
    "        \n",
    "        # Writing data to file\n",
    "        write_geotiff(dataset=arr, filename=fname)\n",
    "        \n",
    "        # Creating an associated metadata file. w - writes, r - reads, a- appends\n",
    "        f = open(savefilepath + Proj + 'medianNDVIDry_' +\n",
    "                      ds_startDate + '_' + ds_endDate + '_' + \n",
    "                      \"Lon\" + str(i) + \"Lat\" + str(j) + '.txt','w')  \n",
    "\n",
    "\n",
    "        f.write(\"Median NDVI for dry month \" + str(dry_month) + \" from \" + ds_startDate + \n",
    "               \"-\" + ds_endDate + \".\" + \"\\n\" \n",
    "               \"Coordinates are longitude: \" +  str(round(coords_lon[i],2)) + ' to ' + \n",
    "               str(round(coords_lon[i+2],2)) + \"; latitude: \" + str(round(coords_lat[j],2)) + \".\" +\n",
    "               str(round(coords_lat[j+2],2)) + \"\\n\" + \"\\n\" \n",
    "               \"This product was derived from NDVI_Export.ipynb\"\n",
    "            )\n",
    "        \n",
    "        f.close()\n",
    "    \n",
    "        # Wet month\n",
    "        # Group available NDVI time-steps into wet month for later monthly averaging\n",
    "        ndvi_wetMonth = ndvi[ndvi['time.month'].isin(wet_month)]\n",
    "    \n",
    "        # Calculate median NDVI for the 'wet' month (through time and for each pixel)\n",
    "        median_ndvi_wet = ndvi_wetMonth.groupby('time.month').median(dim = 'time').median(dim='month')\n",
    "        \n",
    "        # Convert from float16 to float32\n",
    "        arr = median_ndvi_wet.astype(dtype='float32')\n",
    "        \n",
    "        # Convert from DataArray to Dataset\n",
    "        arr = arr.to_dataset(name='median_NDVI_wet')\n",
    "        \n",
    "        # Assign CRS from original DataArray\n",
    "        arr.attrs = ds.attrs\n",
    "\n",
    "        # Generating naming convention for files based on Project area (Proj), specified wet season and time series start and end dates. \n",
    "        fname = str(savefilepath + Proj + 'medianNDVIWet_' +\n",
    "                      ds_startDate + '_' + ds_endDate + '_' + \n",
    "                      \"Lon\" + str(i) + \"Lat\" + str(j) + '.tif')    \n",
    "        \n",
    "        # Writing data to file\n",
    "        write_geotiff(dataset=arr, filename=fname)\n",
    "        \n",
    "        # Creating an associated metadata file. w - writes, r - reads, a- appends\n",
    "        f = open(savefilepath + Proj + 'medianNDVIWet_' +\n",
    "                      ds_startDate + '_' + ds_endDate + '_' + \n",
    "                      \"Lon\" + str(i) + \"Lat\" + str(j) + '.txt','w')  \n",
    "        \n",
    "        \n",
    "        f.write(\"Median NDVI for wet month \" + str(wet_month) + \" from \" + ds_startDate + \n",
    "               \"-\" + ds_endDate + \".\" + \"\\n\" \n",
    "               \"Coordinates are longitude: \" +  str(round(coords_lon[i],2)) + ' to ' + \n",
    "               str(round(coords_lon[i+2],2)) + \"; latitude: \" + str(round(coords_lat[j],2)) + \".\" +\n",
    "               str(round(coords_lat[j+2],2)) + \"\\n\" + \"\\n\" \n",
    "               \"This product was derived from NDVI_Export.ipynb\"\n",
    "            )\n",
    "        \n",
    "        f.close()        \n",
    "        \n",
    "        print(i,j)\n",
    "        \n",
    "\n",
    "print(\"--end--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** October 2019\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`NCI compatible`, :index:`sandbox compatible`, :index:`sentinel 2`, :index:`landsat 8`, :index:`dea_plotting`, :index:`rgb`, :index:`NDVI`, :index:`time series`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
