{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from osgeo import gdal, ogr, gdal_array\n",
    "import dask\n",
    "import datacube \n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from datacube.storage import masking\n",
    "from datacube.utils import geometry\n",
    "import os\n",
    "\n",
    "#import custom functions\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "from reproject_image_to_master import reproject_image_to_master\n",
    "import DEAPlotting, SpatialTools, BandIndices, DEADataHandling\n",
    "from load_data import load_data\n",
    "from transform_tuple import transform_tuple\n",
    "from query_from_shp import query_from_shp\n",
    "from load_masked_FC import load_masked_FC\n",
    "\n",
    "from rsgislib.segmentation import segutils\n",
    "from rasterstats import zonal_stats\n",
    "from imageSeg import imageSeg\n",
    "import fiona\n",
    "import rasterio.features\n",
    "from osgeo import gdal\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where is your data and results folder?\n",
    "data = 'data/'\n",
    "results = 'results/'\n",
    "\n",
    "#do I need to load in new data from the datacube\n",
    "#or have you already saved it previously?\n",
    "load_fresh_data = True\n",
    "\n",
    "sensors = ['ls8']\n",
    "\n",
    "#are we using a polygon to mask the AOI?\n",
    "polygon_mask = False\n",
    "shp_fpath = 'data/spatial/wagga_paddockDrill_AOI_epsg3577.shp'\n",
    "\n",
    "#If not using a polygon then enter your AOI coords\n",
    "#below:\n",
    "lat, lon = -35.1, 147.1\n",
    "latLon_adjust = 0.15\n",
    "\n",
    "#Input your area of interest's name, coords, and \n",
    "#the year you're interested in?\n",
    "AOI = 'WaggaWagga'\n",
    "year= '2018'\n",
    "time_period = ('2018-01-01', '2018-12-31')\n",
    "\n",
    "#-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a folder to keep things neat\n",
    "directory = results + AOI + \"_\" + year\n",
    "if not os.path.exists(directory):\n",
    "    os.mkdir(directory)\n",
    "\n",
    "results = results + AOI + \"_\" + year + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data from one year for image seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_fresh_data == True:\n",
    "    if polygon_mask == True:\n",
    "        #set up query\n",
    "        query = query_from_shp(shp_fpath, time_period[0], time_period[1], dask_chunks = 0)\n",
    "        #landsat\n",
    "        \n",
    "        landsat = load_data(dc_name = 'irrigated_areas', sensors=sensors,\n",
    "                  export_name = data + AOI + \"_\" + year + '.nc', query=query)\n",
    "        #wofs\n",
    "        dc = datacube.Datacube(app='wofs')\n",
    "        del query['time'] \n",
    "        wofs_alltime = dc.load(product = 'wofs_summary', **query)\n",
    "        \n",
    "        #masking the returned array to the polygon area\n",
    "        with fiona.open(shp_fpath) as shapes:\n",
    "                crs = geometry.CRS(shapes.crs_wkt)\n",
    "                first_geometry = next(iter(shapes))['geometry']\n",
    "                geom = geometry.Geometry(first_geometry, crs=crs)\n",
    "\n",
    "        mask = rasterio.features.geometry_mask([geom.to_crs(landsat.geobox.crs) for geoms in [geom]],\n",
    "                                                   out_shape=landsat.geobox.shape,\n",
    "                                                   transform=landsat.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "        # Mask the xarrays\n",
    "        landsat = landsat.where(mask)\n",
    "        #wofs_alltime = wofs_alltime.where(mask)\n",
    "        #datacube.storage.storage.write_dataset_to_netcdf(landsat, results + AOI + \"_\" + year + '.nc')\n",
    "    else:\n",
    "        # Set up query\n",
    "        query = {'lon': (lon - latLon_adjust, lon + latLon_adjust),\n",
    "                 'lat': (lat - latLon_adjust, lat + latLon_adjust),\n",
    "                 'time': time_period}\n",
    "#         query['dask_chunks']= {'x': 500, 'y': 500}\n",
    "\n",
    "        #landsat\n",
    "        dc = datacube.Datacube(app='fc')\n",
    "#         data = DEADataHandling.load_clearlandsat(dc, query,product='fc', ls7_slc_off =True, masked_prop=0.90)\n",
    "        data = DEADataHandling.load_clearlandsat(dc, query, ls7_slc_off =True, masked_prop=0.70)\n",
    "        \n",
    "#         landsat = load_data(dc_name = 'irrigated_areas', sensors=sensors,\n",
    "#                   export_name = data + AOI + \"_\" + year + '.nc', query=query)\n",
    "        #wofs\n",
    "#         dc = datacube.Datacube(app='wofs')\n",
    "#         del query['time'] \n",
    "#         wofs_alltime = dc.load(product = 'wofs_summary', **query)\n",
    "        \n",
    "else:\n",
    "    #load in data from saved netcdf file\n",
    "    landsat = xr.open_dataset(\"data/wagga_Summer2017-18.nc\")\n",
    "    \n",
    "    #landsat = xr.open_dataset('data/' + AOI +  \"_\" + year + '.nc')\n",
    "    #load wofs for masking\n",
    "    query_wofs = {'lon': (lon - latLon_adjust, lon + latLon_adjust),\n",
    "                 'lat': (lat - latLon_adjust, lat + latLon_adjust)} \n",
    "    dc = datacube.Datacube(app='wofs')\n",
    "    wofs_alltime = dc.load(product = 'wofs_summary', **query_wofs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If using FC and quickshift for image seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['UE', 'data_perc'])\n",
    "BS = data.BS[0].values\n",
    "NPV = data.NPV[0].values\n",
    "PV = data.PV[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.stack((PV,NPV,BS), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import quickshift\n",
    "segments_quickshift = quickshift(img, kernel_size=11, convert2lab=True, max_dist=500, ratio=0.5)\n",
    "print(\"Quickshift number of segments: %d\" % len(np.unique(segments_quickshift)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplots(1,1, figsize=(20,20))\n",
    "# plt.imshow(segments_quickshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if importing from earlier work\n",
    "# segments_quickshift = xr.open_rasterio(results + \"/quickshift_test/\" + AOI + \"_\" + year + \"quickshift_segs.tif\")\n",
    "# segments_quickshift = segments_quickshift.drop('band').squeeze()\n",
    "# segments_quickshift = segments_quickshift.astype(np.uint64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export Gtiff for use in Image segmentation\n",
    "transform, projection = transform_tuple(fc_perc, (fc_perc.x, fc_perc.y), epsg=3577)\n",
    "\n",
    "SpatialTools.array_to_geotiff(results + \"/quickshift_test/\" + AOI + \"_\" + year + \"quickshift_segs_FCMedian.tif\",\n",
    "              segments_quickshift, geo_transform = transform, \n",
    "              projection = projection, nodata_val=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SegmentedTiffFile = results + \"/quickshift_test/\" + AOI + \"_\" + year + \"quickshift_segs_FCMedian.tif\"\n",
    "SegmentedPolygons = results + \"/quickshift_test/\" + AOI + \"_\" + year + \"quickshift_segs_FCMedian.shp\"\n",
    "os.system('gdal_polygonize.py ' + SegmentedTiffFile + ' -f' + ' ' + '\"ESRI Shapefile\"' + ' ' + SegmentedPolygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(SegmentedPolygons)\n",
    "#calculate area of polygons\n",
    "gdf['area'] = gdf['geometry'].area \n",
    "#filter by area and mean NDVI\n",
    "smallArea = gdf['area'] >= 50000 # area greater than 5 hectares\n",
    "gdf = gdf[smallArea]\n",
    "# export shapefile\n",
    "# gdf.to_file(results + \"/quickshift_test/\" + AOI + \"_\" + year + \"quickshift_segs_FCMedian_filtered5Ha.shp\")\n",
    "\n",
    "gdf.plot(figsize=(20,20), linewidth=0.5, alpha=0.7, edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate band indices and stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#band indices calculation\n",
    "def ndvi_func(nir, red):\n",
    "    return ((nir - red)/(nir + red))\n",
    "\n",
    "def ndvi_ufunc(ds):\n",
    "    return xr.apply_ufunc(\n",
    "        ndvi_func, ds.nir, ds.red,\n",
    "        dask='parallelized',\n",
    "        output_dtypes=[float])\n",
    "\n",
    "NDVI_landsat = ndvi_ufunc(landsat).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate per pixel summary stats\n",
    "NDVI_max = NDVI_landsat.max('time').rename('NDVI_max').compute()\n",
    "NDVI_95 = NDVI_landsat.quantile(dim='time', q=[0.95], keep_attrs=True).rename('95%_ndvi')\n",
    "NDVI_95 = NDVI_95.squeeze()\n",
    "NDVI_95 = NDVI_95.drop('quantile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image segmentation if using RSGISlib on MaxNDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import quickshift\n",
    "segments_quickshift = quickshift(NDVI_max, kernel_size=11, convert2lab=True, max_dist=500, ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export Gtiff for use in Image segmentation\n",
    "transform, projection = transform_tuple(NDVI_max, (NDVI_max.x, NDVI_max.y), epsg=3577)\n",
    "\n",
    "SpatialTools.array_to_geotiff(results + AOI + \"_\" + year + \"ndvi_max.tif\",\n",
    "              NDVI_max.values, geo_transform = transform, \n",
    "              projection = projection, nodata_val=np.nan)\n",
    "\n",
    "SpatialTools.array_to_geotiff(results + AOI + \"_\" + year + \"ndvi_95.tif\",\n",
    "              NDVI_95.values, geo_transform = transform, \n",
    "              projection = projection, nodata_val=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup input filenames\n",
    "InputNDVIStats = results + AOI + \"_\" + year + \"ndvi_95.tif\"\n",
    "KEAFile = results + AOI + '_' + year + '.kea'\n",
    "SegmentedKEAFile = results + AOI + '_' + year + '_sheperdSEG.kea'\n",
    "SegmentedTiffFile = results + AOI + '_' + year + '_sheperdSEG.tif'\n",
    "SegmentedPolygons = results + AOI + '_' + year + '_SEGpolygons.shp'\n",
    "imageSeg(InputNDVIStats, KEAFile, SegmentedKEAFile, SegmentedTiffFile, SegmentedPolygons, minPxls = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use RF classified map to mask the imag seg file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab the map\n",
    "classified_map = xr.open_rasterio(\"/g/data1a/r78/cb3058/dea-notebooks/ICE_project/results/Murrum_randomForest_Winter2013/Murrum_randomForest_Winter2013classpredict_handtrain.tif\")\n",
    "classified_map = classified_map.drop('band').squeeze()\n",
    "\n",
    "#get the areas that are just cultivated\n",
    "cultivated = classified_map.values\n",
    "cultivated = np.where((cultivated == 330) | (cultivated == 430), 1, 0) #using numpy where because it alters the values\n",
    "cultivated = xr.DataArray(cultivated, coords = [classified_map.y, classified_map.x], dims = ['y', 'x'], name='cultivated areas')\n",
    "cultivated = cultivated.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clip the cultivated areas map to the aoi\n",
    "transform, projection = transform_tuple(cultivated, (cultivated.x, cultivated.y), epsg=3577)\n",
    "width,height = cultivated.shape\n",
    "\n",
    "new_shp = 'data/spatial/wagga_paddockDrill_AOI_epsg3577.shp'\n",
    "aoi_raster = SpatialTools.rasterize_vector(new_shp, height, width, transform, projection, raster_path=None)\n",
    "aoi_raster = aoi_raster.astype(bool)\n",
    "aoi_raster = xr.DataArray(aoi_raster, coords = [cultivated.y, cultivated.x], dims = ['y', 'x'], name='aoi_raster')\n",
    "\n",
    "cultivated = cultivated.where(aoi_raster, drop=True)\n",
    "cultivated = cultivated.fillna(0).astype(bool)\n",
    "cultivated.attrs = classified_map.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSeg_raster = xr.open_rasterio(results + \"/quickshift_test/\" + AOI + \"_\" + year + \"quickshift_segs.tif\")\n",
    "imageSeg_raster = imageSeg_raster.drop('band').squeeze()\n",
    "imageSeg_raster = imageSeg_raster.astype(np.uint64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fixing extent of cultivated area...weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing out cultivated field\n",
    "transform, projection = transform_tuple(cultivated, (cultivated.x, cultivated.y), epsg=3577)\n",
    "SpatialTools.array_to_geotiff(results + AOI + \"_\" + year + \"cultivated.tif\",\n",
    "              cultivated.values, geo_transform = transform, \n",
    "              projection = projection, nodata_val=np.nan)\n",
    "reproject_image_to_master('results/WaggaWagga_2018/ndvi95_imageSeg/WaggaWagga_2018_sheperdSEG.tif', 'results/WaggaWagga_2018/WaggaWagga_2018cultivated.tif', res=None)\n",
    "cultivated = xr.open_rasterio('results/WaggaWagga_2018/WaggaWagga_2018cultivated_crop.tif')\n",
    "cultivated = cultivated.drop('band').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSeg_cultivated = imageSeg_raster.where(cultivated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polygonize imageSeg culitvated tif\n",
    "\n",
    "Then we'll add a unique ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, projection = transform_tuple(imageSeg_cultivated, (imageSeg_cultivated.x, imageSeg_cultivated.y), epsg=3577)\n",
    "SpatialTools.array_to_geotiff(results + AOI + \"_\" + year + \"imageSeg_cultivated.tif\",\n",
    "              imageSeg_cultivated.values, geo_transform = transform, \n",
    "              projection = projection, nodata_val=np.nan)\n",
    "\n",
    "imageSeg_cultivated_tif = results + AOI + \"_\" + year + \"imageSeg_cultivated.tif\"\n",
    "imagSeg_cultivated_polygons = results + AOI + '_' + year + '_imageSeg_cultivated_polygons.shp'\n",
    "os.system('gdal_polygonize.py ' + imageSeg_cultivated_tif + ' -f' + ' ' + '\"ESRI Shapefile\"' + ' ' + imagSeg_cultivated_polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = gpd.read_file(imagSeg_cultivated_polygons)\n",
    "# #calculate area of polygons\n",
    "# gdf['area'] = gdf['geometry'].area \n",
    "# #filter by area and mean NDVI\n",
    "# smallArea = gdf['area'] >= 50000 # area greater than 5 hectares\n",
    "# gdf = gdf[smallArea]\n",
    "# export shapefile\n",
    "# gdf.to_file(results + AOI + \"_\" + year + \"quickshift_segs_filtered5Ha.shp\")\n",
    "gdf.plot(linewidth=0.5, alpha=0.7, edgecolor='black',  figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_poly = gpd.read_file('results/WaggaWagga_2018/WaggaWagga_2018_imageSeg_cultivated_polygons.shp')\n",
    "seg_poly['id'] = list(range(1,(len(seg_poly.DN)+1))) #give each segment a unique ID\n",
    "seg_poly.to_file(results + 'WaggaWagga_2018_imageSeg_cultivated_polygons_withID.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paddock Drill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some user inputs\n",
    "results = \"results/\"\n",
    "AOI = 'WaggaWagga'\n",
    "year= '2018'\n",
    "\n",
    "results = results + AOI + \"_\" + year + \"/\"\n",
    "\n",
    "time_period = ('1990-01-01', '2019-01-01')\n",
    "\n",
    "shp_path = results + 'WaggaWagga_2018_imageSeg_cultivated_polygons_withID.shp'\n",
    "\n",
    "dc = datacube.Datacube(app='fc_fun')\n",
    "\n",
    "with fiona.open(shp_path) as input:\n",
    "    crs = geometry.CRS(input.crs_wkt)\n",
    "    \n",
    "def paddockDrill(feat, crs):\n",
    "    first_geom = feat['geometry']\n",
    "    poly_id = feat['properties']['id']\n",
    "    progress = round((poly_id/8412) * 100, 4)\n",
    "    print(\"\\r\", \"working on polygon: \" + str(poly_id) + \", \" + str(progress) + \"%\" + \" complete. \", end = '')\n",
    "    geom = geometry.Geometry(first_geom, crs=crs)\n",
    "\n",
    "    query = {'geopolygon': geom,\n",
    "             'time': time_period}\n",
    "\n",
    "    data = DEADataHandling.load_clearlandsat(dc, query,product='fc', ls7_slc_off =True, masked_prop=0.90)\n",
    "\n",
    "    mask = rasterio.features.geometry_mask([geom.to_crs(data.geobox.crs)for geoms in [geom]],\n",
    "                                       out_shape=data.geobox.shape,\n",
    "                                       transform=data.geobox.affine,\n",
    "                                       all_touched=False,\n",
    "                                       invert=False)\n",
    "\n",
    "    mask_xr = xr.DataArray(mask, dims = ('y','x'))\n",
    "    fc = data.where(mask_xr==False)\n",
    "\n",
    "    PV_mean = fc.PV.mean(dim=['x', 'y']).values\n",
    "    PV_std = fc.PV.std(dim=['x', 'y']).values\n",
    "    NPV_mean = fc.NPV.mean(dim=['x', 'y']).values\n",
    "    BS_mean = fc.BS.mean(dim=['x', 'y']).values        \n",
    "    time = fc.time.values\n",
    "\n",
    "    #export csv\n",
    "    statistics_df = pd.DataFrame({'dateTime': time, \n",
    "                                  'Mean PV (%)': PV_mean, \n",
    "                                  'Std. Dev. PV (%)':PV_std,\n",
    "                                  'Mean NPV (%)': NPV_mean,\n",
    "                                  'Mean BS (%)': BS_mean\n",
    "                                 })\n",
    "    statistics_df.to_csv(results + \"paddock_zonal/\" + str(poly_id) + \".csv\")\n",
    "\n",
    "p = multiprocessing.Pool()\n",
    "for feat in fiona.open(shp_path):\n",
    "    p.apply_async(paddock_drill, [feat, crs])  \n",
    "        \n",
    "print(\"finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
