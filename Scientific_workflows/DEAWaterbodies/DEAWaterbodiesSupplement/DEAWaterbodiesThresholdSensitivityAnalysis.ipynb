{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEA Waterbodies threshold sensitivity analysis <img align=\"right\" src=\"../../../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatability:** Notebook currently compatible with the `NCI`environment only.\n",
    "* **Products used:** \n",
    "None\n",
    "* **Special requirements:** \n",
    "    * NetCDF files with WOfS outputs that will be used to define the persistent water body polygons\n",
    "        * Variable name: `TileFolder`\n",
    "        * This folder can be either a custom extraction of datacube-stats (as was done here), or you can choose to use the WOfS summary tiles for all of Australia.\n",
    "    * Urban high rise polygon dataset\n",
    "        * Variable name: `UrbanMaskFile`.\n",
    "        * WOfS has a known limitation, where deep shadows thrown by tall CBD buildings are misclassified as water. This results in 'waterbodies' around these misclassified shadows in capital cities.\n",
    "* **Prerequisites:** This notebook explores the sensitivity of WOfS analysis time range and wetness thresholds during the DEA Waterbodies analysis ([see this notebook for the implementation of these thresholds](../TurnWaterObservationsIntoWaterbodyPolygons.ipynb)). It has been designed with that very specific purpose in mind, and is not intended as a general analysis notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "This notebook is an ammended copy of an old version of [`TurnWaterObservationsIntoWaterbodyPolygons.ipynb`](../TurnWaterObservationsIntoWaterbodyPolygons.ipynb). Note that the functions and workflow represent an earlier version of the final workflow used to produce DEA Waterbodies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook tests the impact of using different time range and wetness thresholds on the number, size, and spatial distribution of identified waterbodies. This notebook assists in the selection of appropriate thresholds by exploring the impact of different values on the overall results. \n",
    "\n",
    "There are two parameters that are explored here:\n",
    "- Time range\n",
    "- Wetness threshold\n",
    "\n",
    "**Time range** \n",
    "The time range refers to the length of time over which the water classified summary statistics are calculated. The water classifier used here is the [Water Observations from Space (WOfS)](https://www.sciencedirect.com/science/article/pii/S0034425715301929) decision tree algorithm. \n",
    "\n",
    "The summary statistics were generated using the [datacube-stats](https://github.com/opendatacube/datacube-stats) package, which is a tool for generating large-scale temporal statistics on data within Digital Earth Australia. This package was used to calculate frequency counts and statistics for: \n",
    "\n",
    "Time ranges tested:\n",
    "- Jan 1990 to Dec 2018\n",
    "- Jan 1995 to Dec 2018\n",
    "- Jan 2000 to Dec 2018\n",
    "- Jan 2005 to Dec 2018\n",
    "- Jan 2010 to Dec 2018\n",
    "- Jan 2015 to Dec 2018\n",
    "\n",
    "These summary statistics were pre-calculated, and then imported using the `CustomData` parameter below.\n",
    "\n",
    "**Wetness threshold**\n",
    "The second important parameter using in the generation of the waterbody polygons is the wetness threshold. The wetness threshold indicates how frequently a pixel needed to be observed as wet in order to be included. A wetness threshold of 0.1 means that at least 10% of the total, valid observations needed to be classified as 'wet'. This threshold needs to be sensitive enough to capture the locations of persistent waterbodies, but not so sensitive as to pick up false positives like flood irrigation, flood events or soggy areas in the landscape. \n",
    "\n",
    "Wetness thresholds tested:\n",
    "- 0.2\n",
    "- 0.1\n",
    "- 0.05\n",
    "- 0.02\n",
    "- 0.01 - this test was not completed for 2015-2018 as the number of polygons was too high. This threshold is far too sensitive.\n",
    "\n",
    "The suitability of each time range/wetness threshold was tested in three separate locations across NSW, representing three different landcover types; desert floodplain, irrigated cropping, combination of natural water and irrigated cropping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import rasterio.features\n",
    "from shapely.geometry import Polygon, shape, mapping\n",
    "from shapely.ops import unary_union\n",
    "import geopandas as gp\n",
    "import fiona\n",
    "from fiona.crs import from_epsg\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os.path\n",
    "import math\n",
    "import seaborn\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the functions for this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_list_of_albers_tiles(TileFolder='TileFolder', CustomData=True):\n",
    "    '''\n",
    "    Generate a list of Albers tiles to loop through for the water body analysis. This \n",
    "    function assumes that the list of tiles will be generated from a custom \n",
    "    datacube-stats run, and the file names will have the format\n",
    "    \n",
    "    */wofs_summary_8_-37_{date}.nc\n",
    "    \n",
    "    The tile number is expected in the 2nd and 3rd last positions when the string has been\n",
    "    broken using `_`. If this is not the case, then this code will not work, and will throw an error. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    TileFolder : str\n",
    "        This is the path to the folder of netCDF files for analysis. If this is not provided, or an\n",
    "        incorrect path name is provided, the code will exit with an error.\n",
    "    CustomData : boolean\n",
    "        This is passed in from elsewhere in the notebook. If this is not entered, the default parameter is True.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    CustomRegionAlbersTiles: list\n",
    "        List of Albers tiles across the analysis region. \n",
    "        E.g. ['8_-32', '9_-32', '10_-32', '8_-33', '9_-33']\n",
    "    \n",
    "    '''\n",
    "    if os.path.exists(TileFolder) == False:\n",
    "        print(\n",
    "            '** ERROR ** \\n'\n",
    "            'You need to specify a folder of files for running a custom region')\n",
    "        return\n",
    "\n",
    "    # Grab a list of all of the netCDF files in the tile folder\n",
    "    TileFiles = glob.glob(f'{TileFolder}*.nc')\n",
    "\n",
    "    CustomRegionAlbersTiles = set()\n",
    "    for filePath in TileFiles:\n",
    "        AlbersTiles = re.split('[_\\.]', filePath)\n",
    "        if CustomData:\n",
    "            # Test that the albers tile numbers are actually where we expect them to be in the file name\n",
    "            try:\n",
    "                int(AlbersTiles[-4])\n",
    "                int(AlbersTiles[-3])\n",
    "            except ValueError:\n",
    "                print(\n",
    "                    '** ERROR ** \\n'\n",
    "                    'The netCDF files are expected to have the file format \"*/wofs_summary_8_-37_{date}.nc\",\\n'\n",
    "                    'with the Albers tile numbers in the 2nd and 3rd last positions when separated on `_`. \\n'\n",
    "                    'Please fix the file names, or alter the `Generate_list_of_albers_tiles` function.'\n",
    "                )\n",
    "                return\n",
    "\n",
    "            # Now that we're happy that the file is reading the correct Albers tiles\n",
    "            ThisTile = f'{AlbersTiles[-3]}_{AlbersTiles[-2]}'\n",
    "        else:\n",
    "            # Test that the albers tile numbers are actually where we expect them to be in the file name\n",
    "            try:\n",
    "                int(AlbersTiles[-3])\n",
    "                int(AlbersTiles[-2])\n",
    "            except ValueError:\n",
    "                print(\n",
    "                    '** ERROR ** \\n'\n",
    "                    'The netCDF files are expected to have the file format \"*/wofs_filtered_summary_8_-37.nc\",\\n'\n",
    "                    'with the Albers tile numbers in the 2nd and 3rd last positions when separated on `_` and `.`. \\n'\n",
    "                    'Please fix the file names, or alter the `Generate_list_of_albers_tiles` function.'\n",
    "                )\n",
    "                return\n",
    "\n",
    "            # Now that we're happy that the file is reading the correct Albers tiles\n",
    "            ThisTile = f'{AlbersTiles[-3]}_{AlbersTiles[-2]}'\n",
    "        CustomRegionAlbersTiles.add(ThisTile)\n",
    "    CustomRegionAlbersTiles = list(CustomRegionAlbersTiles)\n",
    "    return CustomRegionAlbersTiles\n",
    "\n",
    "\n",
    "def Generate_list_of_tile_datasets(ListofAlbersTiles,\n",
    "                                   Year,\n",
    "                                   TileFolder='TileFolder',\n",
    "                                   CustomData=True):\n",
    "    '''\n",
    "    Generate a list of Albers tiles datasets to loop through for the water body analysis. Here, the \n",
    "    ListofAlbersTiles is used to generate a list of NetCDF files where the Albers coordinates have \n",
    "    been substituted into the naming file format.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    CustomRegionAlbersTiles: list\n",
    "        List of albers tiles to loop through\n",
    "        E.g. ['8_-32', '9_-32', '10_-32', '8_-33', '9_-33']\n",
    "    Year: int\n",
    "        Year for the analysis. This will correspond to the netCDF files for analysis.\n",
    "    TileFolder : str\n",
    "        This is the path to the folder of netCDF files for analysis. If this is not provided, or an\n",
    "        incorrect path name is provided, the code will exit with an error.\n",
    "    CustomData : boolean\n",
    "        This is passed from elsewhere in the notebook. If this parameter is not entered, the default value\n",
    "        is True.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Alltilespaths: list\n",
    "        List of file paths to files to be analysed.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    if os.path.exists(TileFolder) == False:\n",
    "        print(\n",
    "            '** ERROR ** \\n'\n",
    "            'You need to specify a folder of files for running a custom region')\n",
    "        raise\n",
    "\n",
    "    Alltilespaths = []\n",
    "\n",
    "    if CustomData:\n",
    "        for tile in ListofAlbersTiles:\n",
    "            Tiles = glob.glob(f'{TileFolder}*_{tile}_{Year}0101.nc')\n",
    "            Alltilespaths.append(\n",
    "                Tiles[0])  # Assumes only one file will be returned\n",
    "    else:\n",
    "        for tile in ListofAlbersTiles:\n",
    "            # Use glob to check that the file actually exists in the format we expect\n",
    "            Tiles = glob.glob(f'{TileFolder}wofs_filtered_summary_{tile}.nc')\n",
    "            # Check that assumption by seeing if the returned list is empty\n",
    "            if not Tiles:\n",
    "                Tiles = glob.glob(f'{TileFolder}WOFS_3577_{tile}_summary.nc')\n",
    "            # Check that we actually have something now\n",
    "            if not Tiles:\n",
    "                print(\n",
    "                    '** ERROR ** \\n'\n",
    "                    'An assumption in the file naming conventions has gone wrong somewhere.\\n'\n",
    "                    'We assume two file naming formats here: {TileFolder}wofs_filtered_summary_{tile}.nc, \\n'\n",
    "                    'and {TileFolder}WOFS_3577_{tile}_summary.nc. The files you have directed to don\\'t meet \\n'\n",
    "                    'either assumption. Please fix the file names, or alter the `Generate_list_of_albers_tiles` function.'\n",
    "                )\n",
    "            Alltilespaths.append(\n",
    "                Tiles[0])  # Assumes only one file will be returned\n",
    "\n",
    "    return Alltilespaths\n",
    "\n",
    "\n",
    "def Filter_shapefile_by_intersection(gpdData,\n",
    "                                     gpdFilter,\n",
    "                                     filtertype='intersects',\n",
    "                                     invertMask=True,\n",
    "                                     returnInverse=False):\n",
    "    '''\n",
    "    Filter out polygons that intersect with another polygon shapefile. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    gpdData: geopandas dataframe\n",
    "        Polygon data that you wish to filter\n",
    "    gpdFilter: geopandas dataframe\n",
    "        Dataset you are using as a filter\n",
    "    \n",
    "    Optional\n",
    "    --------\n",
    "    filtertype: default = 'intersects'\n",
    "        Options = ['intersects', 'contains', 'within']\n",
    "    invertMask: boolean\n",
    "        Default = 'True'. This determines whether you want areas that DO ( = 'False') or DON'T ( = 'True')\n",
    "        intersect with the filter shapefile.\n",
    "    returnInnverse: boolean\n",
    "        Default = 'False'. If true, then return both parts of the intersection - those that intersect AND \n",
    "        those that don't as two dataframes.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    gpdDataFiltered: geopandas dataframe\n",
    "        Filtered polygon set, with polygons that intersect with gpdFilter removed.\n",
    "    IntersectIndex: list of indices of gpdData that intersect with gpdFilter\n",
    "    \n",
    "    Optional\n",
    "    --------\n",
    "    if 'returnInverse = True'\n",
    "    gpdDataFiltered, gpdDataInverse: two geopandas dataframes\n",
    "        Filtered polygon set, with polygons that DON'T intersect with gpdFilter removed.\n",
    "    '''\n",
    "\n",
    "    # Check that the coordinate reference systems of both dataframes are the same\n",
    "\n",
    "    #assert gpdData.crs == gpdFilter.crs, 'Make sure the the coordinate reference systems of the two provided dataframes are the same'\n",
    "\n",
    "    Intersections = gp.sjoin(gpdFilter, gpdData, how=\"inner\", op=filtertype)\n",
    "\n",
    "    # Find the index of all the polygons that intersect with the filter\n",
    "    IntersectIndex = sorted(set(Intersections['index_right']))\n",
    "\n",
    "    # Grab only the polygons NOT in the IntersectIndex\n",
    "    # i.e. that don't intersect with a river\n",
    "    if invertMask:\n",
    "        gpdDataFiltered = gpdData.loc[~gpdData.index.isin(IntersectIndex)]\n",
    "    else:\n",
    "        gpdDataFiltered = gpdData.loc[gpdData.index.isin(IntersectIndex)]\n",
    "\n",
    "    if returnInverse:\n",
    "        # We need to use the indices from IntersectIndex to find the inverse dataset, so we\n",
    "        # will just swap the '~'.\n",
    "\n",
    "        if invertMask:\n",
    "            gpdDataInverse = gpdData.loc[gpdData.index.isin(IntersectIndex)]\n",
    "        else:\n",
    "            gpdDataInverse = gpdData.loc[~gpdData.index.isin(IntersectIndex)]\n",
    "\n",
    "        return gpdDataFiltered, IntersectIndex, gpdDataInverse\n",
    "    else:\n",
    "\n",
    "        return gpdDataFiltered, IntersectIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters\n",
    "\n",
    "See [this notebook](../TurnWaterObservationsIntoWaterbodyPolygons.ipynb) for an extensive discussion on each of these parameters.\n",
    "\n",
    "* `MinimumValidObs`: How many valid observations must there be for a pixel for it to be included in the analysis\n",
    "* `MinSize`: What is the minimum waterbody size in m2\n",
    "* `MaxSize`: What is the maximum waterbody size in m2\n",
    "* `UrbanMaskFile`: file directory to a shapefile containing an urban mask to filter out incorrect polygons caused by deep urban shadows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinimumValidObs = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinSize = 3120  # 5 pixels\n",
    "MaxSize = math.inf  # No upper limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "UrbanMaskFile = '/g/data/r78/cek156/ShapeFiles/ABS_1270055001_sa3_2016_aust_shape/HighRiseCBD_ABS_sa3.shp'\n",
    "\n",
    "CBDs = gp.read_file(UrbanMaskFile)\n",
    "CBDs = CBDs.to_crs({'init': 'epsg:3577'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental variables\n",
    "### Time range\n",
    "\n",
    "Precomputer WOfS summary statistics were calculated using the [datacube-stats](https://github.com/opendatacube/datacube-stats) package. \n",
    "These different time range statistic calculations were manually cycled through using the `CustomData` parameter here.\n",
    "* `CustomData`: if `True`, you will need to specify the location of the data you would like to use for this analysis, setting `TileFolder` below. If `False`, the code will automatically look at the published WOfS all time summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomData = False\n",
    "AutoGenerateTileList = False\n",
    "\n",
    "if CustomData:\n",
    "    TileFolder = '/g/data/r78/cek156/datacube_stats/WOFSDamsAllTimeNSWMDB/'\n",
    "else:\n",
    "    TileFolder = '/g/data/fk4/datacube/002/WOfS/WOfS_Stats_25_2_1/netcdf/'\n",
    "\n",
    "# We only want to generate the tile list if we are not doing all of Australia.\n",
    "if not AllOfAustraliaAllTime:\n",
    "    if AutoGenerateTileList:\n",
    "        ListofAlbersTiles = Generate_list_of_albers_tiles(\n",
    "            TileFolder, CustomData)\n",
    "    else:\n",
    "        ListofAlbersTiles = ['7_-34', '10_-40', '16_-34']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wetness threshold\n",
    "This variable is manually varied to test the sensitivity of this parameter on the overall results:\n",
    "- 0.2\n",
    "- 0.1\n",
    "- 0.05\n",
    "- 0.02\n",
    "- 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "AtLeastThisWet = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of experiments\n",
    "\n",
    "The time range and wetness thresholds were both varied, producing a total of 29 experiments.The final experiment of `2015-18` and `0.01` produced *way too many* polygons and so took a long time to complete. After a day I just stopped it running.\n",
    "\n",
    "|     Time Range\\Wetness Threshold       |0.02  |0.1 |0.05 |0.02 |0.01 |\n",
    "|-----------| ------------------|----------|----------|----------|----------|\n",
    "|Jan 1990 to Dec 2018 | &#9745; | &#9745;  |  &#9745; | &#9745;  |  &#9745; |\n",
    "|Jan 1995 to Dec 2018  | &#9745; | &#9745;  |  &#9745; | &#9745;  |  &#9745; |\n",
    "|Jan 2000 to Dec 2018  | &#9745; | &#9745;  |  &#9745; | &#9745;  |  &#9745; |\n",
    "|Jan 2005 to Dec 2018 | &#9745; | &#9745;  |  &#9745; | &#9745;  |  &#9745; |\n",
    "|Jan 2010 to Dec 2018  | &#9745; | &#9745;  |  &#9745; | &#9745;  |  &#9745; |\n",
    "|Jan 2015 to Dec 2018  | &#9745; | &#9745;  |  &#9745; | &#9745;  |  &#9744; |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through each tile and polygonise the WOfS statistics data\n",
    "\n",
    "Note that this is an older version of the code that was used to produce the final DEA Waterbodies polygons. See [`TurnWaterObservationsIntoWaterbodyPolygons.ipynb`](../TurnWaterObservationsIntoWaterbodyPolygons.ipynb) for the most recent workflow.\n",
    "\n",
    "### Analysis parameters\n",
    "* `year`: here is how you manually loop through the different time ranges. Set this to be the first year of the time range period you are analysing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This code does the analysis a year at a time. If there is a single year only, set the year range to be\n",
    "# `range(year, year + 1)`\n",
    "\n",
    "year = '1987'\n",
    "\n",
    "### Set up some file names for the inputs and outputs\n",
    "\n",
    "# The name and filepath of the intermediate output polygon set\n",
    "WaterBodiesShp = f'/g/data/r78/cek156/dea-notebooks/Scientific_workflows/DEAWaterbodies/DEAWaterbodiesThresholdAnalysis/WaterBodies{year}_{AtLeastThisWet}.shp'\n",
    "\n",
    "### Get the list of netcdf file names to loop through\n",
    "if AllOfAustraliaAllTime:\n",
    "    # Grab everything from the published WOfS all time summaries\n",
    "    Alltiles = glob.glob(f'{TileFolder}*.nc')\n",
    "else:\n",
    "    Alltiles = Generate_list_of_tile_datasets(ListofAlbersTiles, year,\n",
    "                                              TileFolder, CustomData)\n",
    "\n",
    "for WOFSfile in Alltiles:\n",
    "    # Read in the data\n",
    "    # Note that the netCDF files we are using here contain a variable called 'frequency',\n",
    "    # which is what we are using to define our water polygons.\n",
    "    # If you use a different netCDF input source, you may need to change this variable name here\n",
    "    WOFSnetCDFData = xr.open_rasterio(f'NETCDF:{WOFSfile}:frequency')\n",
    "    # Remove the superfluous time dimension\n",
    "    WOFSnetCDFData = WOFSnetCDFData.squeeze()\n",
    "\n",
    "    # Open the clear count variable to generate the minimum observation mask\n",
    "    WOFSvalidcount = xr.open_rasterio(f'NETCDF:{WOFSfile}:count_clear')\n",
    "    WOFSvalidcount = WOFSvalidcount.squeeze()\n",
    "\n",
    "    # Filter our WOfS classified data layer to remove noise\n",
    "    # Remove any pixels not abserved at least MinimumValidObs times\n",
    "    WOFSValidFiltered = WOFSvalidcount >= MinimumValidObs\n",
    "\n",
    "    # Remove any pixels that are wet < AtLeastThisWet% of the time\n",
    "    WOFSfiltered = WOFSnetCDFData > AtLeastThisWet\n",
    "\n",
    "    # Now find pixels that meet both the MinimumValidObs and AtLeastThisWet criteria\n",
    "    # Change all zeros to NaN to create a nan/1 mask layer\n",
    "    # Pixels == 1 now represent our water bodies\n",
    "    WOFSfiltered = WOFSfiltered.where((WOFSfiltered != 0) &\n",
    "                                      (WOFSValidFiltered != 0))\n",
    "\n",
    "    # Convert the raster to polygons\n",
    "    # We use a mask of '1' to only generate polygons around values of '1' (not NaNs)\n",
    "    WOFSpolygons = rasterio.features.shapes(\n",
    "        WOFSfiltered.data.astype('float32'),\n",
    "        mask=WOFSfiltered.data.astype('float32') == 1,\n",
    "        transform=WOFSnetCDFData.transform)\n",
    "    # The rasterio.features.shapes returns a tuple. We only want to keep the geometry portion,\n",
    "    # not the value of each polygon (which here is just 1 for everything)\n",
    "    WOFSbreaktuple = (a for a, b in WOFSpolygons)\n",
    "\n",
    "    # Put our polygons into a geopandas geodataframe\n",
    "    PolygonGP = gp.GeoDataFrame(list(WOFSbreaktuple))\n",
    "\n",
    "    # Grab the geometries and convert into a shapely geometry\n",
    "    # so we can quickly calcuate the area of each polygon\n",
    "    PolygonGP['geometry'] = None\n",
    "    for ix, poly in PolygonGP.iterrows():\n",
    "        poly['geometry'] = shape(poly)\n",
    "\n",
    "    # Set the geometry of the dataframe to be the shapely geometry we just created\n",
    "    PolygonGP = PolygonGP.set_geometry('geometry')\n",
    "    # We need to add the crs back onto the dataframe\n",
    "    PolygonGP.crs = {'init': 'epsg:3577'}\n",
    "\n",
    "    # Combine any overlapping polygons\n",
    "    MergedPolygonsGeoms = unary_union(PolygonGP['geometry'])\n",
    "\n",
    "    # Turn the combined multipolygon back into a geodataframe\n",
    "    MergedPolygonsGPD = gp.GeoDataFrame([poly for poly in MergedPolygonsGeoms])\n",
    "    # Rename the geometry column\n",
    "    MergedPolygonsGPD.columns = ['geometry']\n",
    "    # We need to add the crs back onto the dataframe\n",
    "    MergedPolygonsGPD.crs = {'init': 'epsg:3577'}\n",
    "\n",
    "    # Calculate the area of each polygon again now that overlapping polygons\n",
    "    # have been merged\n",
    "    MergedPolygonsGPD['area'] = MergedPolygonsGPD['geometry'].area\n",
    "\n",
    "    # Filter out any polygons smaller than MinSize, and greater than MaxSize\n",
    "    WaterBodiesBig = MergedPolygonsGPD.loc[(\n",
    "        (MergedPolygonsGPD['area'] > MinSize) &\n",
    "        (MergedPolygonsGPD['area'] <= MaxSize))]\n",
    "\n",
    "    # WOfS has a known bug where deep shadows from high-rise CBD buildings are misclassified\n",
    "    # as water. We will use the ABS sa3 dataset to filter out Brisbane, Gold Coast, Sydney,\n",
    "    # Melbourne, Adelaide and Perth CBDs.\n",
    "    NotCities = Filter_shapefile_by_intersection(WaterBodiesBig, CBDs)\n",
    "\n",
    "    # Save the polygons to a shapefile\n",
    "    schema = {'geometry': 'Polygon', 'properties': {'area': 'str'}}\n",
    "\n",
    "    if os.path.isfile(WaterBodiesShp):\n",
    "        with fiona.open(WaterBodiesShp,\n",
    "                        \"a\",\n",
    "                        crs=from_epsg(3577),\n",
    "                        driver='ESRI Shapefile',\n",
    "                        schema=schema) as output:\n",
    "            for ix, poly in NotCities[0].iterrows():\n",
    "                output.write(({\n",
    "                    'properties': {\n",
    "                        'area': poly['area']\n",
    "                    },\n",
    "                    'geometry': mapping(shape(poly['geometry']))\n",
    "                }))\n",
    "    else:\n",
    "        with fiona.open(WaterBodiesShp,\n",
    "                        \"w\",\n",
    "                        crs=from_epsg(3577),\n",
    "                        driver='ESRI Shapefile',\n",
    "                        schema=schema) as output:\n",
    "            for ix, poly in NotCities[0].iterrows():\n",
    "                output.write(({\n",
    "                    'properties': {\n",
    "                        'area': poly['area']\n",
    "                    },\n",
    "                    'geometry': mapping(shape(poly['geometry']))\n",
    "                }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the threshold results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all of the sensitivity test shapefiles\n",
    "AllSensitivityResults = glob.glob(\n",
    "    f'/g/data/r78/cek156/dea-notebooks/Scientific_workflows/DEAWaterbodies/DEAWaterbodiesThresholdAnalysis/WaterBodies*.shp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the effect of time range on results\n",
    "\n",
    "Here we use the total area inside all identified polygons as a means to assess the relative impact of time range and threshold on the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60557caa16304306871815d8b851a6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f0f4c1e04a8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AreaData = []\n",
    "\n",
    "for File in AllSensitivityResults:\n",
    "    PolygonShapes = gp.read_file(File)\n",
    "    AllPolygonArea = PolygonShapes.area.sum()\n",
    "    # Break up the file name to get the start year, and threshold\n",
    "    GDataBit, ExtraBit, ThresholdBit = File.split('_')\n",
    "    StartYear = ExtraBit[-4:]\n",
    "    Threshold = ThresholdBit[:-4]\n",
    "    AreaData.append([AllPolygonArea, StartYear, Threshold])\n",
    "\n",
    "AreaDataFrame = pd.DataFrame(AreaData, columns=['AreaSum', 'StartYear', 'Threshold'])\n",
    "AreaDataFrame['StartYear'] = pd.to_numeric(AreaDataFrame['StartYear'])\n",
    "\n",
    "seaborn.lmplot(x='StartYear', y='AreaSum', data = AreaDataFrame, fit_reg = False, hue = 'Threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the figure above we can conclude that the number of years over which the results are integrated doesn't have a large affect on the overall results, with the exception of the 2015-2018 analysis.** \n",
    "\n",
    "We can see that the sensitivity of the results from the 2015-2018 analysis is far too low, and many of the polygon pixels picked up in the other analyses are missed over this short integration period. \n",
    "\n",
    "The combination of the 0.01 wetness threshold and the all time analysis (1987-2018) sees a large spike in the overall area of identified waterbodies. This result appears to be an outlier and suggests that the 0.01 threshold is too sensitive over this long time period. \n",
    "\n",
    "The remaining experiments all produce very similar results, suggesting that **the time period over which the analysis is performed does not have a strong overall impact on the waterbodies generated.**\n",
    "\n",
    "We therefore choose to use all available observations, to limit the use of custom analysis periods, and to be consistent with the [WOfS all time summary product](https://cmi.ga.gov.au/wo-filt-stats_25_2.1.5). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the effect of different wetness thresholds on the overall results\n",
    "\n",
    "Here we explore the effect of difference wetness thresholds on the total area inside all identified polygons for each sensitivity test combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba83de89d6c4ecc8055c3de1335b1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/dea-env/20191127/lib/python3.6/site-packages/seaborn/regression.py:279: RuntimeWarning: invalid value encountered in log\n",
      "  grid = np.c_[np.ones(len(grid)), np.log(grid)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f0f4bea0be0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AreaDataFrame['Threshold'] = pd.to_numeric(AreaDataFrame['Threshold'])\n",
    "seaborn.lmplot(x='Threshold', y='AreaSum', data = AreaDataFrame, logx = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overall, we can see that the total area of identified polygons increases as the threshold applied reduces.**\n",
    "\n",
    "The outliers seen on this plot represent the data for the 2015-2018 period, where the total polygon area is underestimated.\n",
    "\n",
    "It is unclear from this plot whether the increase in total polygon area is related to the identification of more polygons, or simply increases in the relative size of individual polygons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of wetness threshold on polygon number and size\n",
    "\n",
    "Here we explore both the number and size of polygons identified using each of the tested thresholds. We perform this analysis only for the 1987-2018 results, as these have been identified as the preferred time range in the analysis above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48623dc3870543e8a627a52129514cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Histogram count')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for File in AllSensitivityResults:\n",
    "    GDataBit, ExtraBit, ThresholdBit = File.split('_')\n",
    "    StartYear = ExtraBit[-4:]\n",
    "    Threshold = ThresholdBit[:-4]\n",
    "    \n",
    "    # Only perform the analysis on results for 2000-2018\n",
    "    if StartYear == '1987':\n",
    "        PolygonShapes = gp.read_file(File)\n",
    "        PolygonShapes['area'] = pd.to_numeric(PolygonShapes['area'])\n",
    "\n",
    "        plt.hist(PolygonShapes['area'], bins = list(range(0, 110000, 10000)), \n",
    "                 label=Threshold, histtype = 'step')\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "handles, labels = zip(*[ (handles[i], labels[i]) \n",
    "                        for i in sorted(range(len(handles)), \n",
    "                                        key=lambda k: list(map(float,labels))[k])] )\n",
    "        \n",
    "plt.legend(handles, labels)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Individual polygon area (m2)')\n",
    "plt.ylabel('Histogram count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot, we can draw the following conclusions:\n",
    "* Generally, a lower threshold means more *total* waterbody polygons are identified.\n",
    "* Generally, a lower threshold means more *larger sized* waterbody polygons are identified.\n",
    "* It's not clear from our analysis of the threshold results so far which wetness threshold is most suitable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are more (and larger) polygons better?\n",
    "\n",
    "An assessment as to the most appropriate final threshold to use will need to be somewhat subjective. While we can quantify the different affects caused by varying the time period and wetness threshold, a judgement call as to an acceptable signal:noise ratio will need to be made. \n",
    "\n",
    "Here we provide the evidence used to come to the final decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![All thresholds](../DocumentationFigures/AllThresholds.JPG \"All thresholds shown, with darker blues = higher thresholds, and lighter blues for lower thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above image, all of the wetness thresholds, all run over the same time range, have been plotted together. The darkest blue represents the 0.01 threshold, with the lightest blue being 0.2.\n",
    "\n",
    "The lowest threshold of 0.01, shown in the darkest blue, returns a much larger number of polygons than the other thresholds, but most of these seem to be noise. There is some clear striping from Landsat 7's scan line corrector failure (lower right corner), as well as a lot of small polygons that do not clearly line up with waterbody features. \n",
    "\n",
    "This same conclusion was drawn from examination of the 0.01 wetness threshold in other locations.\n",
    "\n",
    "**We therefore discount 0.01 (i.e. 1%) as a useful wetness threshold.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Remove 0.01](../DocumentationFigures/No0.01.JPG \"All thresholds shown, with darker blues = higher thresholds, and lighter blues for lower thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the 0.01 threshold removed, it is clear that most of the noisy polygons have also been removed. There still remains a reasonable number of small, noisy pixels that appear to be associated with intermittently wet features (like soggy bits in paddocks), rather than water bodies. \n",
    "\n",
    "This was also found at other testing locations.\n",
    "\n",
    "**We therefore discount 0.02 (i.e. 2%) as an acceptable wetness threshold**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Remove 0.02](../DocumentationFigures/No0.02.JPG \"All thresholds shown, with darker blues = higher thresholds, and lighter blues for lower thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the left hand side of the image above (and in other areas not shown), we can see that the threshold of 0.2 misses parts of water bodies (as seen by the smaller polygons sitting inside of the larger ones), resulting in only portions of waterbodies being mapped. It also misses entire waterbodies, which are observed as wet less frequently.\n",
    "\n",
    "**The sensitivity of the 0.2 (20%) wetness threshold is too conservative, so we therefore discount it as an acceptable wetness threshold.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the most suitable threshold between the two remaining thresholds (0.1 and 0.05) is difficult. We can see from above, there is little difference between both the total number of water bodies, and the relative size of individual polygons, however spatially, the two threshold can be seen to have quite different results. \n",
    "\n",
    "To make the differences between the two thresholds easier to visualise, we have recoloured the polygons:\n",
    "- 0.1 = purple\n",
    "- 0.05 = yellow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Agricultural Comparison](../DocumentationFigures/AgricultureArea.JPG \"0.1 Threshold = purple, 0.05 threshold = yellow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the area above, (northern NSW), we can see that the lower threshold of 0.05 (shown in yellow) appears to do a better job of characterising waterbodies. The Purple polygons frequently pick up only parts of waterbodies, whereas the yellow polygons pick up the whole waterbody area, as well as some additional smaller waterbodies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Lake Frome Comparison](../DocumentationFigures/LakeFrome.JPG \"0.1 Threshold = purple, 0.05 threshold = yellow. The red line denotes the boundary of the test area\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example, the lower threshold of 0.05 does a much better job of characterising the extent of Lake Frome in central Australia. Lake Frome is a large floodplain, and so inundates relatively infrequently, making it very sensitive to the threshold used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Flood Irrigation Comparison](../DocumentationFigures/Cotton.JPG \"0.1 Threshold = purple, 0.05 threshold = yellow. The red line denotes the boundary of the test area\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above region in south central NSW, the issues with the 0.05 threshold become apparent. In this region, flood irrigation is commonly used, resulting in waterbodies being identified within flood irrigated paddocks. The more conservative threshold of 0.1 does a much better job in this region of distinguishing between flood irrigation, and waterbodies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a wetness threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the 0.05 and 0.1 thresholds showed both errors of omission and commission, depending on the location in which they were applied. In a location with large areas of flood irrigation, the 0.05 threshold identified a number of paddocks as waterbodies, indicating this threshold is too sensitive in these conditions. In more arid areas, where waterbodies rarely reach their maximum extent, the 0.1 threshold was shown to underrepresent the maximum waterbody extent, picking out only partial polygons within individual waterbodies. \n",
    "\n",
    "Given the limitations of both wetness thresholds, a **hybrid threshold was chosen, whereby the locations of waterbodies was identified using the 0.1 threshold, but the spatial extent of these waterbodies was characterized using the 0.05 threshold**. This minimizes errors caused by flood irrigation, which are not readily captured by the 0.1 wetness threshold, but also captures the larger spatial extent of individual waterbodies afforded by the 0.05 threshold. \n",
    "\n",
    "While we have chosen a 0.1/0.05 threshold for our purposes, the [DEA Waterbodies code](../TurnWaterObservationsIntoWaterbodyPolygons.ipynb) has been written to allow the user to define their own single, or hybrid threshold, making it customizable to different environmental conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below, showing Lake George near the NSW/ACT border, the 10% threshold shown in blue, captures a smaller spatial footprint of Lake George than the 5% threshold in red. Here we can see that the 5% threshold does a better job of capturing the full spatial footprint of Lake George, i.e. the footprint is closer to how we would manually define the outline of Lake George. This creates a nice compromise between better spatial characterisation of footprints, and the addition of false positives from the lower 5% threshold. \n",
    "\n",
    "![Hybrid Threshold effect on Lake George, NSW](../DocumentationFigures/HybridThreshold.JPG \"In this example showing Lake George near the NSW/ACT border, the 10% threshold shown in blue, captures a smaller spatial footprint of Lake George than the 5% threshold in red. Here we can see that the 5% threshold does a better job of capturing the full spatial footprint of Lake George\")\n",
    "\n",
    "The area below in south central NSW is an area where flood irrigation is common. The yellow polygons identified below, are those generated from the 5% threshold. The clear presence of 'waterbody' polygons in flood irrigated fields is a good example of the high sensitivity of the 5% threshold, when applied blindly. The hybrid approach (shown in red) shows where the polygons from the 5% threshold have been intentionally selected for inclusion in the final waterbody polygon set. These included polygons intersect with a polygon identified within the 10% threshold, thereby allowing the 10% threshold to identify the location of polygons, but the 5% threshold to characterise their spatial footprint. \n",
    "\n",
    "![Threshold sensitivity comparison, south central NSW](../DocumentationFigures/ThresholdCompare.JPG \"This example in south central NSW is an area where flood irrigation is common. The yellow polygons are those generated from the 5% threshold. The clear presence of 'waterbody' polygons in flood irrigated fields is a good example of the high sensitivity of the 5% threshold, when applied blindly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** January 2020\n",
    "\n",
    "**Compatible datacube version:** N/A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**Tags**: :index:`DEA Waterbodies`"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
