{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download scraper module `dea_bom`:\n",
    "\n",
    "```\n",
    "!wget https://raw.githubusercontent.com/GeoscienceAustralia/dea-notebooks/kirill-bom-water/Scripts/dea_bom.py\n",
    "```\n",
    "\n",
    "Needs to be done once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import ipywidgets as W\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../Scripts')\n",
    "import os\n",
    "import dea_bom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import datacube\n",
    "from datacube.utils import geometry \n",
    "from datacube.utils.geometry import CRS\n",
    "from datacube.storage import masking\n",
    "from datacube.helpers import ga_pq_fuser, write_geotiff\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='datacube')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of All Available Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 93.1 ms, sys: 20.2 ms, total: 113 ms\n",
      "Wall time: 4.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6027,\n",
       " [namespace(name='15 MILE @ GRETA STH', pos=(-36.61945775, 146.24407214), url='http://bom.gov.au/waterdata/services/stations/403213'),\n",
       "  namespace(name='15 MILE @ WANGARATTA', pos=(-36.36666667, 146.2833333), url='http://bom.gov.au/waterdata/services/stations/403239'),\n",
       "  namespace(name='15 MILE CK GLENROWAN', pos=(-36.47080718, 146.246199), url='http://bom.gov.au/waterdata/services/stations/403251'),\n",
       "  namespace(name='16 Mile Waterhole', pos=(-18.876921, 139.360487), url='http://bom.gov.au/waterdata/services/stations/913010A'),\n",
       "  namespace(name='163 Clifton Rd', pos=(-32.97808, 115.90111), url='http://bom.gov.au/waterdata/services/stations/6131318')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "stations = dea_bom.get_stations()\n",
    "len(stations), stations[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667b6f9a882841b2b59c831f573a0cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Map(basemap={'url': 'https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', 'max_zâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbg = W.Output()\n",
    "fig_display = W.Output()\n",
    "stt = [] # call stt to see all selected stations in the Kernel\n",
    "collected_data = [] #call collected_data to see what data you are working with\n",
    "legends = []\n",
    "\n",
    "with fig_display:\n",
    "    plt.ioff()\n",
    "    fig, ax = plt.subplots(1, figsize=(14,4))\n",
    "    \n",
    "def on_clear():\n",
    "    dbg.clear_output(wait=True)\n",
    "    with dbg:\n",
    "        print('Clear')\n",
    "\n",
    "    ax.clear()\n",
    "    legends.clear()\n",
    "    collected_data.clear()\n",
    "    stt.clear()\n",
    "    fig_display.clear_output()\n",
    "    \n",
    "\n",
    "def on_select(st):\n",
    "    with dbg:\n",
    "        print(f'Fetching data for: {st.name}')\n",
    "    stt.append(st)\n",
    "    try:\n",
    "        xx = dea_bom.get_station_data(st).dropna()\n",
    "    except Exception:\n",
    "        with dbg:\n",
    "            print('Failed to read data')\n",
    "            return\n",
    "\n",
    "    with dbg:\n",
    "        print(f'Got {xx.shape[0]} observations')\n",
    "    \n",
    "    if xx.shape[0] == 0:\n",
    "        return\n",
    "    collected_data.append(xx)\n",
    "    \n",
    "    xx.plot(ax=ax)\n",
    "    legends.append(st.name)\n",
    "    ax.legend(legends)\n",
    "    \n",
    "    fig_display.clear_output(wait=True)\n",
    "    with fig_display:\n",
    "        display(fig)\n",
    "        \n",
    "m, cluster = dea_bom.mk_station_selector(on_select,\n",
    "                                         stations,\n",
    "                                         center=(-24, 138),\n",
    "                                         zoom=3)\n",
    "\n",
    "btn = W.Button(description=\"Clear\")\n",
    "btn.on_click(lambda b: on_clear())\n",
    "\n",
    "ui = W.VBox(\n",
    "    [W.HBox([m, W.VBox([btn, dbg], layout=W.Layout(width=\"30%\"))]), fig_display]\n",
    ")\n",
    "\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a guage from the map\n",
    "Make sure it has data in it as some gauges are empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please select the lat and lon of the area you want to make a picture of\n",
    "lat = -35.0442\n",
    "lon = 144.4464\n",
    "buffer = 10000\n",
    "\n",
    "print(\"Here is the lat and lon of the gauge: {}\".format(stt))\n",
    "print(\"make sure your selected lat and lon matches the gauge lat and lon:\\n\")\n",
    "print(\"You have selected: lat = {}\".format(lat))\n",
    "print(\"You have selected: lon = {}\".format(lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rearranging data into a flow duration curve\n",
    "gauge_data = collected_data[0]\n",
    "gauge_data = gauge_data.dropna()\n",
    "gauge_data = gauge_data.sort_values('Value')\n",
    "gauge_data['rownumber'] = np.arange(len(gauge_data))\n",
    "gauge_data['Exceedence'] = (1-(gauge_data.rownumber/len(gauge_data)))*100\n",
    "\n",
    "\n",
    "\n",
    "gauge_data.plot(x='Exceedence', y='Value', figsize=(11,7))\n",
    "plt.ylabel('cubic meters per second')\n",
    "plt.grid(True)\n",
    "plt.title('FDC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What part of the Flow Duration Curve do you want to look at?\n",
    "yaxis_lower_parameter = 30\n",
    "yaxis_higher_parameter = 80\n",
    "\n",
    "#Let's look at it on a log scale\n",
    "ax2 = gauge_data.plot(x='Exceedence', y='Value', figsize=(11,7)) \n",
    "ax2 = plt.axhspan(yaxis_lower_parameter, yaxis_higher_parameter, color='red', alpha=0.2)\n",
    "ax2 = plt.title('This is the range you selected displayed as a log')\n",
    "ax2 = plt.ylabel('cubic meters per second (log)')\n",
    "ax2 = plt.xlabel('Exceedence')\n",
    "ax2 = pyplot.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_data_xr = gauge_data.to_xarray()\n",
    "\n",
    "#Dask loading wofs_albers data (loading parameters only, not loading the actual satellite data since 1988)\n",
    "x, y = geometry.point(lon, lat, CRS('WGS84')).to_crs(CRS('EPSG:3577')).points[0]\n",
    "query = {'x': (x - buffer, x + buffer),\n",
    "         'y': (y - buffer, y + buffer),    \n",
    "         'time': ('1988-01-01', '2019-08-22'), # You might want to change the date to todays date\n",
    "         'crs': 'EPSG:3577'} \n",
    "dc = datacube.Datacube(app='dc-WOfS')\n",
    "wofs_albers= dc.load(product = 'wofs_albers', dask_chunks = {}, group_by='solar_day', **query)\n",
    "\n",
    "# Merging satellite data with gauge data by timestamp\n",
    "merged_data = gauge_data_xr.interp(Timestamp=wofs_albers.time)\n",
    "\n",
    "# Here is where it takes into account user input for the FDC\n",
    "specified_level = merged_data.where((merged_data.Value > yaxis_lower_parameter) & \n",
    "                                    (merged_data.Value < yaxis_higher_parameter), drop=True)\n",
    "date_list = specified_level.time.values\n",
    "\n",
    "print(\"WARNING: You are about to load satellite pass data from the Geoscience datacube.\\n\" \n",
    "      \"If you load more than 300 passes it will take a long time to load.\\n\"\n",
    "     \"To change the amount of passes, change the yaxis parameters.\\n\"\n",
    "      \"If you got 0 passes unexpectedly, check that you got the lower and higher yaxis parameters around the right way.\\n\"\n",
    "     \"You are about to load this many passes (check that it's under 300):\\n {}\".format(specified_level.time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = geometry.point(lon, lat, CRS('WGS84')).to_crs(CRS('EPSG:3577')).points[0]\n",
    "query = {'x': (x - buffer, x + buffer),\n",
    "         'y': (y - buffer, y + buffer), \n",
    "         'crs': 'EPSG:3577'} \n",
    "\n",
    "#loop selecting data based on FDC parameters\n",
    "xr_list = []\n",
    "for date in date_list:\n",
    "    date = str(date)  \n",
    "    wofs_albers= dc.load(product = 'wofs_albers', time=date,  **query)\n",
    "    xr_list.append(wofs_albers)\n",
    "specified_passes = xr.concat(xr_list, dim='time')\n",
    "\n",
    "#Cloud Mask\n",
    "ClearTimesteps = []\n",
    "for ix, timestep in enumerate(specified_passes.time):\n",
    "    SingleTime = specified_passes.water.isel(time=ix)\n",
    "    IsItCloudy = masking.make_mask(SingleTime, cloud=True)\n",
    "    CountClouds = IsItCloudy.sum()   \n",
    "    PercentCloudy = CountClouds.values.item()/(len(specified_passes.x)*len(specified_passes*y))*100\n",
    "    IsItClearEnough = PercentCloudy <= 50  \n",
    "    if IsItClearEnough:\n",
    "        ClearTimesteps.append(ix)     \n",
    "clear_specified_passes = specified_passes.water.isel(time = ClearTimesteps)\n",
    "\n",
    "wet = (clear_specified_passes == 128).sum(dim='time')\n",
    "dry = (clear_specified_passes == 0).sum(dim='time')\n",
    "clear = wet + dry\n",
    "frequency = wet / clear\n",
    "frequency= frequency.fillna(0) #this is to get rid of the NAs that occur due to mountain shadows\n",
    "frequency = frequency.where(frequency!=0) #This is to tell it to make areas that were dry 100% of the time white\n",
    "\n",
    "#Plotting the image\n",
    "frequency.plot(figsize = (16, 12))\n",
    "plt.axis('off')\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(16, 6))\n",
    "\n",
    "ax1 = frequency.plot(ax=ax[0])\n",
    "\n",
    "ax2 = gauge_data.plot(x='Exceedence', y='Value', ax=ax[1]) \n",
    "ax2 = plt.axhspan(yaxis_lower_parameter, yaxis_higher_parameter, color='red', alpha=0.2)\n",
    "ax2 = plt.title('This was the specified range for which the image was generated (FDC log)')\n",
    "ax2 = plt.ylabel('cubic meters per second (log)')\n",
    "ax2 = plt.xlabel('Exceedence')\n",
    "ax2 = pyplot.yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"This image was made by layering this many images: {}\".format(clear_specified_passes.time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
