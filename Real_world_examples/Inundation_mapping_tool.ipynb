{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these imports access modules from the Geoscience datacube and modules that have been written specifically for this notebook, which are contained in the Scripts folder. Run these imports and subsequent cells by pressing 'Shift' + 'Enter'. There is a tab called Kernel in the top left of the Sandbox. If you want to clear all the outputs and re-set the notebook, select 'Restart Kernal and Clear All Outputs'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../Scripts')\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from datacube.helpers import write_geotiff\n",
    "\n",
    "from pathlib import Path\n",
    "import dea_bom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import datacube\n",
    "from datacube.utils import geometry \n",
    "from datacube.utils.geometry import CRS\n",
    "from datacube.storage import masking\n",
    "from datacube.helpers import ga_pq_fuser, write_geotiff\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='datacube')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of All Available Stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the code accesses the dea_bom.py module which contains an XML webscraping code. It retrieves the stream gauges from BOM's Water Data Online website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "stations_pkl = Path('stations.pkl')\n",
    "\n",
    "# if cache exists, get it from cache\n",
    "if stations_pkl.exists():\n",
    "    print('Loading from cache')\n",
    "    stations = pickle.load(open(str(stations_pkl), 'rb'))\n",
    "else:\n",
    "    print('Fetching from BoM')\n",
    "    stations = dea_bom.get_stations()\n",
    "    pickle.dump(stations, open(str(stations_pkl), 'wb'))\n",
    "    \n",
    "len(stations), stations[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a map of stations and select a gauge that contains data\n",
    "\n",
    "Running this cell will generate a map displaying the locations of stream gauges in Australia. It will take about 20 seconds to load. Choose a gauge on the map by clicking on it. Note that after you click on a gauge it can take a second or two to respond. Also note that a few gauges have no data available and will retrieve zero observations, so you will have to click around until you find a gauge with good data. When you have the station you want, you must click the Done button before moving onto the next box. If you want to choose a different gauge after having pressed the Done button, you must re-run this box to regenerate the map then choose another gauge and press Done again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_data, station = dea_bom.ui_select_station(stations);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a flow duration curve from the data selected above\n",
    "The code in the box below will automatically select the latitude and longitude of the selected gauge, but you can enter a different lat and lon if you want by following the hashtag lines in the code below. The output will tell you what lat and lon has been selected. The buffer, which is the radius around the location point, is set to 8000 meters but you can change it if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = station.pos\n",
    "\n",
    "#The lat and lon takes the location of the gauge (pos). You can change the lat and lon to a different location if necessary, \n",
    "#just hashtag out this lat, lon = pos line below and define your own.\n",
    "lat, lon = pos\n",
    "\n",
    "#lat =\n",
    "#lon = \n",
    "\n",
    "#The buffer is how many meters radius around the location you want to display.\n",
    "buffer = 8000 \n",
    "\n",
    "#Rearranging data into a flow duration curve\n",
    "gauge_data = gauge_data.dropna()\n",
    "gauge_data = gauge_data.sort_values('Value')\n",
    "gauge_data['rownumber'] = np.arange(len(gauge_data))\n",
    "gauge_data['Exceedence'] = (1-(gauge_data.rownumber/len(gauge_data)))*100\n",
    "\n",
    "#Plotting the flow duration curve\n",
    "gauge_data.plot(x='Exceedence', y='Value', figsize=(11,7))\n",
    "plt.ylabel('cubic meters per second')\n",
    "plt.grid(True)\n",
    "plt.title('FDC')\n",
    "\n",
    "print(\"You have selected: lat = {}\".format(lat))\n",
    "print(\"You have selected: lon = {}\".format(lon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter the y-axis parameters in cubic meters per second then run the cell with 'Shift' + 'Enter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What part of the Flow Duration Curve do you want to look at?\n",
    "yaxis_lower_parameter = 300\n",
    "yaxis_higher_parameter = 1750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next box plots your selection on a log of the FDC so you can see what part of the FDC you selected on a log scale. This is also the section which calls the satellite data from the Geoscience datacube. You will note that the query contains time, which you can change to any time frame you like using the format \"yyyy-mm-dd\" on the line that says # You can change this date accordingly. The output will also tell you how many passes were called from the datacube that will then be loaded in the next section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's look at it on a log scale\n",
    "ax2 = gauge_data.plot(x='Exceedence', y='Value', figsize=(11,7)) \n",
    "ax2 = plt.axhspan(yaxis_lower_parameter, yaxis_higher_parameter, color='red', alpha=0.2)\n",
    "ax2 = plt.title('This is the range you selected displayed as a log')\n",
    "ax2 = plt.ylabel('cubic meters per second (log)')\n",
    "ax2 = plt.xlabel('Exceedence')\n",
    "ax2 = plt.yscale('log')\n",
    "\n",
    "gauge_data_xr = gauge_data.to_xarray()\n",
    "\n",
    "#Dask loading wofs_albers data (loading parameters only, not loading the actual satellite data since 1988)\n",
    "x, y = geometry.point(lon, lat, CRS('WGS84')).to_crs(CRS('EPSG:3577')).points[0]\n",
    "query = {'x': (x - buffer, x + buffer),\n",
    "         'y': (y - buffer, y + buffer),    \n",
    "         'time': ('1988-01-01', '2019-10-01'), # You can change this date accordingly\n",
    "         'crs': 'EPSG:3577'} \n",
    "dc = datacube.Datacube(app='dc-WOfS')\n",
    "wofs_albers= dc.load(product = 'wofs_albers', dask_chunks = {}, group_by='solar_day', **query)\n",
    "\n",
    "# Merging satellite data with gauge data by timestamp\n",
    "merged_data = gauge_data_xr.interp(Timestamp=wofs_albers.time)\n",
    "\n",
    "# Here is where it takes into account user input for the FDC\n",
    "specified_level = merged_data.where((merged_data.Value > yaxis_lower_parameter) & \n",
    "                                    (merged_data.Value < yaxis_higher_parameter), drop=True)\n",
    "date_list = specified_level.time.values\n",
    "\n",
    "print(\"You are about to load this many satellite passes: {}\".format(specified_level.time.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The box below will cloud mask the images, meaning it will take out images that had too much cloud to see anything. It will then generate a summary image made by layering the clear images on top of each other to show the frequency of water observed while the gauge was reading the specified flow values. Yellow means water was present in every pass during the specified flows and purple means it was there 20% of the time or less. The output will also tell you how many clear passes were used to generate the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the passes that happened during the specified flow parameters\n",
    "specified_passes = wofs_albers.sel(time=date_list).compute()\n",
    "\n",
    "# prune out \"too cloudy\" passes\n",
    "cc = masking.make_mask(specified_passes.water, cloud=True)\n",
    "\n",
    "npixels_per_slice = specified_passes.water.shape[1]*specified_passes.water.shape[2]\n",
    "npixels_per_slice\n",
    "\n",
    "ncloud_pixels = cc.sum(dim='x').sum(dim='y')\n",
    "cloud_pixels_fraction = (ncloud_pixels/npixels_per_slice)\n",
    "\n",
    "clear_specified_passes = specified_passes.water.isel(time=cloud_pixels_fraction<0.5)\n",
    "clear_specified_passes.shape\n",
    "\n",
    "#Create parameters for the image\n",
    "wet = (clear_specified_passes == 128).sum(dim='time')\n",
    "dry = (clear_specified_passes == 0).sum(dim='time')\n",
    "clear = wet + dry\n",
    "frequency = wet / clear\n",
    "frequency= frequency.fillna(0) #this is to get rid of the NAs that occur due to mountain shadows\n",
    "frequency = frequency.where(frequency!=0) #This is to tell it to make areas that were dry 100% of the time white\n",
    "\n",
    "#Plotting the image\n",
    "frequency.plot(figsize = (16, 12))\n",
    "plt.axis('off')\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(16, 6))\n",
    "\n",
    "ax1 = frequency.plot(ax=ax[0])\n",
    "\n",
    "ax2 = gauge_data.plot(x='Exceedence', y='Value', ax=ax[1]) \n",
    "ax2 = plt.axhspan(yaxis_lower_parameter, yaxis_higher_parameter, color='red', alpha=0.2)\n",
    "ax2 = plt.title('This was the specified range for which the image was generated (FDC log)')\n",
    "ax2 = plt.ylabel('cubic meters per second (log)')\n",
    "ax2 = plt.xlabel('Exceedence')\n",
    "ax2 = plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"This image was made by layering this many images: {}\".format(clear_specified_passes.time.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, this is an image of the gauge location according to the flow values you selected. You can now go back and change the flow parameters or you can re-run the map box and choose a different gauge all together. Would you like to see a list of dates that were used to make this summary image? If yes, run the box below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_specified_passes.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the file as a geotiff\n",
    "You might want to use this image in another workflow, so here is some code that will save it as a .tif file for you. Enter a name for the .tif file below. The ../ part of the name means it will save this file one directory up from where this notebook is saved, ie in your dea-notebooks folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '../file_name_here.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_dataset = frequency.to_dataset()\n",
    "frequency_dataset.attrs=wofs_albers.attrs\n",
    "# Write geotiff to a location\n",
    "write_geotiff(file_name, frequency_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
