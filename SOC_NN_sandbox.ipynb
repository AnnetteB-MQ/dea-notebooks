{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making tools to use covariate xarrays with a Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading covariates and targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These should already exist in a bunch of pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('site_and_points.pkl','rb') as f:\n",
    "    final_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"quantile_img.pkl\",\"rb\") as f:\n",
    "    quant_raster = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "tpi = xr.open_rasterio('SOC_geotiff/TPI_ablers.tif')\n",
    "saga = xr.open_rasterio('SOC_geotiff/sagawetness_albers.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SampleID</th>\n",
       "      <th>Easting</th>\n",
       "      <th>Northing</th>\n",
       "      <th>TC</th>\n",
       "      <th>Method</th>\n",
       "      <th>Year</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001_A1.2</td>\n",
       "      <td>338014.132</td>\n",
       "      <td>6370645.57</td>\n",
       "      <td>0.981252</td>\n",
       "      <td>CNS</td>\n",
       "      <td>2001</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1MIR</td>\n",
       "      <td>338014.132</td>\n",
       "      <td>6370645.57</td>\n",
       "      <td>0.600364</td>\n",
       "      <td>MIR</td>\n",
       "      <td>2001</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001_A6.2</td>\n",
       "      <td>338068.776</td>\n",
       "      <td>6370868.38</td>\n",
       "      <td>0.866419</td>\n",
       "      <td>CNS</td>\n",
       "      <td>2001</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A6MIR</td>\n",
       "      <td>338068.776</td>\n",
       "      <td>6370868.38</td>\n",
       "      <td>1.187051</td>\n",
       "      <td>MIR</td>\n",
       "      <td>2001</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001_A11.2</td>\n",
       "      <td>338182.533</td>\n",
       "      <td>6370550.16</td>\n",
       "      <td>0.772519</td>\n",
       "      <td>CNS</td>\n",
       "      <td>2001</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SampleID     Easting    Northing        TC Method  Year  \\\n",
       "0   2001_A1.2  338014.132  6370645.57  0.981252    CNS  2001   \n",
       "1       A1MIR  338014.132  6370645.57  0.600364    MIR  2001   \n",
       "2   2001_A6.2  338068.776  6370868.38  0.866419    CNS  2001   \n",
       "3       A6MIR  338068.776  6370868.38  1.187051    MIR  2001   \n",
       "4  2001_A11.2  338182.533  6370550.16  0.772519    CNS  2001   \n",
       "\n",
       "                                              points  \n",
       "0  Geometry({'type': 'Point', 'coordinates': (178...  \n",
       "1  Geometry({'type': 'Point', 'coordinates': (178...  \n",
       "2  Geometry({'type': 'Point', 'coordinates': (178...  \n",
       "3  Geometry({'type': 'Point', 'coordinates': (178...  \n",
       "4  Geometry({'type': 'Point', 'coordinates': (178...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a DataFrame with all the position and target information about the site measurements, and raster maps of the TPI and SAGA wetness, along with quantiles of photosynthetic vegetation cover observed by Landsat. We should combine these separate rasters into one huge multi-channel raster, then write a function to select from this raster and produce a 'window' around a site measurement for input into the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "topographic = xr.concat((saga,tpi),dim='band').rename({'band':'channel'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 886, 659)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topographic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_raster = quant_raster.rename({'quantile':'channel'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "covars = xr.concat((topographic,quant_raster),dim='channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove incompatible metadata in the dimension that was concatenated\n",
    "import numpy as np; covars['channel'] = np.arange(len(covars['channel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'channel' (channel: 9)>\n",
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
       "Coordinates:\n",
       "  * channel  (channel) int64 0 1 2 3 4 5 6 7 8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covars.channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create training/validation samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a point (x,y) and a specified buffer around it (in pixels), then returns a trimmed raster of the covariates around the point. It should deal with cases where the buffer zone intersects the edge of the covariate raster map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine resolution of rasters by differencing the spatial dimensions.\n",
    "#ensure that if the raster contains covariates from different sources that they are coregistered\n",
    "#to the same spatial coordinate sets otherwise this won't work and you'll end up with a bunch of\n",
    "#NaNs in your underlying numpy arrays.\n",
    "xres = covars.x[1]-covars.x[0]\n",
    "yres = covars.y[1]-covars.y[0]\n",
    "\n",
    "def sample_raster(row,bufferx=5,buffery=5):\n",
    "    LL = row['points']\n",
    "    sitex = LL.coords[0][0]\n",
    "    sitey = LL.coords[0][1]\n",
    "    \n",
    "    x = np.arange(sitex-bufferx*xres,sitex+(bufferx+1)*xres,xres)\n",
    "    y = np.arange(sitey-buffery*yres,sitey+(buffery+1)*yres,yres)\n",
    "    \n",
    "    sample_array = covars.reindex(x=x,method='nearest',tolerance=abs(xres/2)).reindex(y=y,method='nearest',tolerance=abs(yres/2))\n",
    "    \n",
    "    return sample_array.data\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may help to standardise the inputs for training. We can do this simply using built-in features of xarray before generating training samples. We can then either impute missing values (NaNs) on-the-fly using Keras or do it using our sample generating function while creating the training/validation set. It is less costly to do the latter because once it's done it will not need to be done again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "covars = (covars - covars.mean(dim=['x','y']))/covars.std(dim=['x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the standardised covariate raster - this will come in handy later on\n",
    "with open(\"standardised_NN_covars.pkl\",\"wb\") as f:\n",
    "    pickle.dump(covars,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating labelled datasets for training and validation\n",
    "We can now iterate through the dataframe and save the input data associated with each sample site in a directory in the 'normal' way for use with a Keras generator. This avoids loading every sample into RAM to train the NN. The labels are the measured SOC values in the dataframe. We will need to associate each row of the dataframe with a unique file on disk which can be read by the generator which feeds samples to Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2183"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.981252\n",
       "1    0.600364\n",
       "2    0.866419\n",
       "3    1.187051\n",
       "4    0.772519\n",
       "5    1.398617\n",
       "6    0.593211\n",
       "7    1.126836\n",
       "8    1.315066\n",
       "9    1.881963\n",
       "Name: TC, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.iloc[0:10]['TC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-112-24ca3002f14a>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-112-24ca3002f14a>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    def on_epoch_end(self)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class CovarGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Feed trimmed covariate images for an NN\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,gen_df,batch_size = 32, shuffle = True):\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.length = len(gen_df)//batch_size\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        if self.shuffle:\n",
    "            self.gen_df = gen_df.sample(frac=1).reset_index(drop=True)\n",
    "        else:\n",
    "            self.gen_df = gen_df\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        slicedf = self.gen_df.iloc[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        y = np.array(slicedf['TC'])\n",
    "        X = np.stack(slicedf.apply(sample_raster,axis=1))\n",
    "        return (X,y)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.gen_df = gen_df.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "testgen = CovarGenerator(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = testgen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 9, 11, 11)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
