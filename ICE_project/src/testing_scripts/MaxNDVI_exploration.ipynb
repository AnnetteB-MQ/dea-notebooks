{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a complete but still being tested workflow for generating irrigated cropping extents\n",
    "\n",
    "Go to the user inputs section and input the required info, then run the rest of the cells.\n",
    "Results will be in your results folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import dask\n",
    "import datacube \n",
    "from matplotlib import pyplot as plt\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from datacube.storage import masking\n",
    "from datacube.utils import geometry\n",
    "\n",
    "import fiona\n",
    "import rasterio.features\n",
    "from osgeo import gdal, ogr\n",
    "import os\n",
    "from rsgislib.segmentation import segutils\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "#import custom functions\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "import DEAPlotting, SpatialTools, BandIndices, DEADataHandling\n",
    "from load_data import load_data\n",
    "from transform_tuple import transform_tuple\n",
    "from imageSeg import imageSeg\n",
    "from query_from_shp import query_from_shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where is your data and results folder?\n",
    "data = 'data/'\n",
    "results = 'results/'\n",
    "\n",
    "#do I need to load in new data from the datacube\n",
    "#or have you already saved it previously?\n",
    "load_fresh_data = True\n",
    "\n",
    "sensors = ['ls5','ls7','ls8']\n",
    "\n",
    "#are we using a polygon to mask the AOI?\n",
    "polygon_mask = False\n",
    "shp_fpath = 'data/spatial/murrumbidgee_catchment.shp'\n",
    "\n",
    "#If not using a polygon then enter your AOI coords\n",
    "#below:\n",
    "lat, lon = -34.294, 146.037\n",
    "latLon_adjust = 0.15\n",
    "\n",
    "#Input your area of interest's name, coords, and \n",
    "#the year you're interested in?\n",
    "AOI = 'training_winter'\n",
    "year = '2016'\n",
    "\n",
    "time_period = ('2013-05-01', '2013-09-30')\n",
    "\n",
    "#What thresholds should I use?\n",
    "threshold = 0.8\n",
    "wofs_theshold = 0.15\n",
    "#-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a folder to keep things neat\n",
    "directory = results + AOI + \"_\" + year\n",
    "if not os.path.exists(directory):\n",
    "    os.mkdir(directory)\n",
    "\n",
    "results = results + AOI + \"_\" + year + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load landsat data    \n",
    "if load_fresh_data == True:\n",
    "    if polygon_mask == True:\n",
    "        #set up query\n",
    "        query = query_from_shp(shp_fpath, time_period[0], time_period[1], dask_chunks = 0)\n",
    "        #landsat\n",
    "        landsat = load_data(dc_name = 'irrigated_areas', sensors=sensors,\n",
    "                  export_name = data + AOI + \"_\" + year + '.nc', query=query)\n",
    "        \n",
    "        #wofs\n",
    "        dc = datacube.Datacube(app='wofs')\n",
    "        del query['time'] \n",
    "        wofs_alltime = dc.load(product = 'wofs_summary', **query)\n",
    "        \n",
    "        #masking the returned array to the polygon area\n",
    "        with fiona.open(shp_fpath) as shapes:\n",
    "                crs = geometry.CRS(shapes.crs_wkt)\n",
    "                first_geometry = next(iter(shapes))['geometry']\n",
    "                geom = geometry.Geometry(first_geometry, crs=crs)\n",
    "\n",
    "        mask = rasterio.features.geometry_mask([geom.to_crs(landsat.geobox.crs) for geoms in [geom]],\n",
    "                                                   out_shape=landsat.geobox.shape,\n",
    "                                                   transform=landsat.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "        # Mask the xarrays\n",
    "        landsat = landsat.where(mask)\n",
    "        #wofs_alltime = wofs_alltime.where(mask)\n",
    "        #datacube.storage.storage.write_dataset_to_netcdf(landsat, results + AOI + \"_\" + year + '.nc')\n",
    "    else:\n",
    "        # Set up query\n",
    "        query = {'lon': (lon - latLon_adjust, lon + latLon_adjust),\n",
    "                 'lat': (lat - latLon_adjust, lat + latLon_adjust),\n",
    "                 'time': time_period}\n",
    "        #query['dask_chunks']= {'x': 500, 'y': 500}\n",
    "\n",
    "        #landsat\n",
    "        landsat = load_data(dc_name = 'irrigated_areas', sensors=sensors,\n",
    "                  export_name = data + AOI + \"_\" + year + '.nc', query=query)\n",
    "#         dc = datacube.Datacube(app='landsat')\n",
    "#         landsat = DEADataHandling.load_clearlandsat(dc=dc, query=query,sensors=['ls7'], \n",
    "#                 bands_of_interest=['red', 'nir'],\n",
    "#                 masked_prop=0.1, mask_pixel_quality=True)\n",
    "\n",
    "        \n",
    "        #wofs\n",
    "#         dc = datacube.Datacube(app='wofs')\n",
    "#         del query['time'] \n",
    "#         wofs_alltime = dc.load(product = 'wofs_summary', **query)\n",
    "        \n",
    "else:\n",
    "    #load in data from saved netcdf file\n",
    "    landsat = xr.open_dataset(\"data/wagga_Summer2017-18.nc\")\n",
    "    \n",
    "    #landsat = xr.open_dataset('data/' + AOI +  \"_\" + year + '.nc')\n",
    "    #load wofs for masking\n",
    "    query_wofs = {'lon': (lon - latLon_adjust, lon + latLon_adjust),\n",
    "                 'lat': (lat - latLon_adjust, lat + latLon_adjust)} \n",
    "    dc = datacube.Datacube(app='wofs')\n",
    "    wofs_alltime = dc.load(product = 'wofs_summary', **query_wofs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Band Indices and Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#band indices calculation\n",
    "def ndvi_func(nir, red):\n",
    "    return ((nir - red)/(nir + red))\n",
    "\n",
    "def ndvi_ufunc(ds):\n",
    "    return xr.apply_ufunc(\n",
    "        ndvi_func, ds.nir, ds.red,\n",
    "        dask='parallelized',\n",
    "        output_dtypes=[float])\n",
    "\n",
    "NDVI_landsat = ndvi_ufunc(landsat).compute()\n",
    "# NDMI_landsat = BandIndices.calculate_indices(landsat, index='NDMI-nir').compute()\n",
    "\n",
    "# x = NDVI_landsat.to_dataset(name='NDVI')\n",
    "# y = NDMI_landsat.to_dataset(name='NDMI')\n",
    "# a = xr.merge([x,y])\n",
    "# a.attrs=dict(crs=landsat.crs)\n",
    "# datacube.storage.storage.write_dataset_to_netcdf(a, results + AOI +\"_\" + \"winter\"+year + '.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate per pixel summary stats\n",
    "NDVI_landsat = NDVI_landsat.resample(time='M').mean('time')\n",
    "y = NDVI_max.coords['y']\n",
    "x = NDVI_max.coords['x']\n",
    "\n",
    "NDVI_max = NDVI_landsat.max('time').rename('NDVI_max').compute()\n",
    "NDVI_min = NDVI_landsat.min('time').rename('NDVI_min').compute()\n",
    "NDVI_range = NDVI_max - NDVI_min\n",
    "NDVI_std = NDVI_landsat.std('time').rename('NDVI_std').compute()\n",
    "NDVI_median = NDVI_landsat.median('time').rename('NDVI_median').compute()\n",
    "NDVI_mean = NDVI_landsat.mean('time').rename('NDVI_mean').compute()\n",
    "\n",
    "timeofmax = NDVI_landsat.values.argmax(axis=0)\n",
    "timeofmax = xr.DataArray(timeofmax, coords = [y, x], dims = ['y', 'x'], name='time_of_max')\n",
    "\n",
    "timeofmin = NDVI_landsat.values.argmin(axis=0)\n",
    "timeofmin = xr.DataArray(timeofmin, coords = [y, x], dims = ['y', 'x'], name='time_of_min')\n",
    "\n",
    "NDVI_percentiles = NDVI_landsat.quantile(dim='time', q=[0.95,0.90,0.5,0.1,0.05], keep_attrs=True).rename('ndvi_percentiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.segmentation import quickshift\n",
    "# segments_quickshift = quickshift(NDVI_max, kernel_size=11, convert2lab=False, max_dist=500, ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 0.3\n",
    "b = NDVI_min.where((timeofmin != 0) | (timeofmin != 1), 0) #minimum is not in May or June\n",
    "c = b.where(b >= thres,0) # Minimum NDVI value is above set threshold \n",
    "d = c.where(NDVI_std >= 0.1,0) #NDVI variance is higher than 0.1 to remove trees\n",
    "\n",
    "d.plot(figsize=(10,10), vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.count_nonzero((d.values))\n",
    "area = (ones*(25*25)) / 1000000\n",
    "print(\"Around \" + AOI + \" during \" + str(year) + \", \" + str(area) + \" km2 was under irrigated cultivation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export Gtiff for use in Image segmentation\n",
    "transform, projection = transform_tuple(NDVI_max, (NDVI_max.x, NDVI_max.y), epsg=3577)\n",
    "SpatialTools.array_to_geotiff(results + AOI + \"_\" + year + \".tif\",\n",
    "              NDVI_max.values, geo_transform = transform, \n",
    "              projection = projection, nodata_val=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup input filenames\n",
    "InputNDVIStats = results + AOI + \"_\" + year + \".tif\"\n",
    "KEAFile = results + AOI + '_' + year + '.kea'\n",
    "SegmentedKEAFile = results + AOI + '_' + year + '_sheperdSEG.kea'\n",
    "SegmentedTiffFile = results + AOI + '_' + year + '_sheperdSEG.tif'\n",
    "SegmentedPolygons = results + AOI + '_' + year + '_SEGpolygons.shp'\n",
    "imageSeg(InputNDVIStats, KEAFile, SegmentedKEAFile, SegmentedTiffFile, SegmentedPolygons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zonal Statistics & filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(results + AOI + '_' + year + '_SEGpolygons.shp')\n",
    "#calculate zonal mean of NDVI\n",
    "gdf['mean'] = pd.DataFrame(zonal_stats(vectors=gdf['geometry'], raster=InputNDVIStats, stats='mean'))['mean']\n",
    "#calculate area of polygons\n",
    "gdf['area'] = gdf['geometry'].area\n",
    "#filter by area and mean NDVI\n",
    "highNDVI = gdf['mean'] >= threshold\n",
    "smallArea = gdf['area'] <= 5500000\n",
    "gdf = gdf[highNDVI & smallArea]\n",
    "#export shapefile\n",
    "gdf.to_file(results + AOI + \"_\" + year + \"_Irrigated.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking using zonal stats polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the transform and projection of our gtiff\n",
    "transform, projection = transform_tuple(NDVI_max, (NDVI_max.x, NDVI_max.y), epsg=3577)\n",
    "#find the width and height of the xarray dataset we want to mask\n",
    "width,height = NDVI_max.shape\n",
    "# rasterize vector\n",
    "gdf_raster = SpatialTools.rasterize_vector(results + AOI + \"_\" + year + \"_Irrigated.shp\",\n",
    "                                           height, width, transform, projection, raster_path=None)\n",
    "# Mask the xarray\n",
    "NDVI_max_Irrigated = NDVI_max.where(gdf_raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reclassify & raster math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove areas below our threshold that are at the edges of the rasterized polygons\n",
    "NDVI_max_Irrigated = NDVI_max_Irrigated.where(NDVI_max_Irrigated >= threshold)\n",
    "#Use wofs to remove areas that have standing water for a significant amount of time\n",
    "NDVI_max_Irrigated = NDVI_max_Irrigated.where(wofs_alltime.frequency.drop('time').squeeze() <= wofs_theshold)\n",
    "\n",
    "#remove pixels that cross over the major rivers in the region\n",
    "rivers_raster = SpatialTools.rasterize_vector(\"data/spatial/major_rivers_aus.shp\", height, width, transform, projection, raster_path=None)\n",
    "rivers_raster = rivers_raster.astype(bool)\n",
    "rivers_raster = xr.DataArray(rivers_raster, coords = [NDVI_max.y, NDVI_max.x], dims = ['y', 'x'], name='rivers')\n",
    "NDVI_max_Irrigated = NDVI_max_Irrigated.where(rivers_raster == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the area of irrigation?\n",
    "# ones = np.count_nonzero(~np.isnan(NDVI_max_Irrigated.values))\n",
    "# area = (ones*(25*25)) / 1000000\n",
    "# print(\"Around \" + AOI + \" during \" + str(year) + \", \" + str(area) + \" km2 was under irrigated cultivation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter with MADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query_from_shp(shp_fpath, start_date = '2017-01-01', end_date = '2017-12-31')\n",
    "\n",
    "dc_mads = datacube.Datacube(config='/g/data1a/u46/users/cb3058/datacube.conf', env='NCI-test')\n",
    "mads = dc_mads.load(product = 'ls8_nbart_tmad_annual', **query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del query['dask_chunks'] \n",
    "dc_mads = datacube.Datacube(env=\"NCI-test\")\n",
    "del query['dask_chunks']\n",
    "mads = dc_mads.load(product = 'ls8_nbart_tmad_annual', **query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mads.edev.sel(time='2017-01-01')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.where(a <=0.05).plot(figsize=(5,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mads.edev[2]#.isel(time=3).where(mads.edev <= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = NDVI_max_Irrigated.where(x >=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon = -35.543784, 148.087523\n",
    "latLon_adjust = 0.1\n",
    "\n",
    "time_period = ('2015-10-15', '2016-3-31')\n",
    "\n",
    "query = {'lon': (lon - latLon_adjust, lon + latLon_adjust),\n",
    "         'lat': (lat - latLon_adjust, lat + latLon_adjust),\n",
    "         'time': time_period}\n",
    "dc_mads = datacube.Datacube(config='/g/data1a/u46/users/cb3058/datacube.conf', env='NCI-test')\n",
    "mads = dc_mads.load(product = 'ls8_nbart_tmad_annual', **query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra comment to make it different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export results as GTiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpatialTools.array_to_geotiff(results + AOI + \"_\" + year + \"_Irrigated_minusMADS.tif\",\n",
    "              y.values,\n",
    "              geo_transform = transform, \n",
    "              projection = projection, \n",
    "              nodata_val=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = xr.open_rasterio(\"/g/data1a/r78/cb3058/dea-notebooks/dcStats/results/Murrumbidgee/stats/winter_1990_2018/rate_20160501.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeofmax = rate[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the transform and projection of our gtiff\n",
    "transform, projection = transform_tuple(timeofmax, (timeofmax.x, timeofmax.y), epsg=3577)\n",
    "#find the width and height of the xarray dataset we want to mask\n",
    "width,height = timeofmax.shape\n",
    "\n",
    "# rasterize vector\n",
    "gdf_raster = SpatialTools.rasterize_vector(\"/g/data1a/r78/cb3058/dea-notebooks/ICE_project/data/spatial/OEH_irrigated_2013.shp\",\n",
    "                                           height, width, transform, projection, raster_path=None)\n",
    "# Mask the xarray\n",
    "timeofmax.where(gdf_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gdf_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tom_clipped = timeofmax.where(gdf_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpatialTools.array_to_geotiff(\"/g/data1a/r78/cb3058/dea-notebooks/ICE_project/results/timeofmax_clippedtoOEH2013.tif\",\n",
    "              tom_clipped.values,\n",
    "              geo_transform = transform, \n",
    "              projection = projection, \n",
    "              nodata_val=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
