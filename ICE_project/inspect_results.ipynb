{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processsing the results for the annual Summer Irrigated Cropping Area (SICA) project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T03:47:05.175970Z",
     "start_time": "2019-05-10T03:47:02.046178Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from osgeo import gdal, ogr\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "from multiprocessing import Pool\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entire catchment plot\n",
    "\n",
    "This code will produce a timeseries of annual irrigated area aggregated acrosss the entire Northern Murray Darling Basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T03:47:06.408560Z",
     "start_time": "2019-05-10T03:47:06.401314Z"
    }
   },
   "outputs": [],
   "source": [
    "directory = \"/g/data/r78/cb3058/dea-notebooks/ICE_project/results/nmdb/\"\n",
    "suffix = \"_Irrigated_OEHandLS_masked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T03:49:33.543082Z",
     "start_time": "2019-05-10T03:47:11.186019Z"
    }
   },
   "outputs": [],
   "source": [
    "#list of years to help for-loop iterate through folders\n",
    "x = range(1987,2019,1)\n",
    "years = []\n",
    "for i in x:\n",
    "    nextyear = str(i + 1)[2:]\n",
    "    y = str(i) + \"_\" + nextyear\n",
    "    years.append(str(y))\n",
    "# removing years that didn't work\n",
    "years =  [e for e in years if e not in ('2011_12', '2012_13')]\n",
    "years.sort()\n",
    "\n",
    "folders = os.listdir(directory)\n",
    "folders.sort()\n",
    "\n",
    "area_a = []\n",
    "def getIrrigatedArea(shp):\n",
    "    irr = gpd.read_file(shp)\n",
    "    area_a.append(irr.area.sum() / 10000)\n",
    "\n",
    "#grab sum of irrigated area for each each and add to dataframe\n",
    "for year, folder in zip(years, folders): \n",
    "    #progress indicator\n",
    "    print(\"\\r\", \"working on year: \" + year, end = '')\n",
    "    getIrrigatedArea(directory+folder+\"/\"+\"nmdb_Summer\"+ year + suffix+\".shp\")\n",
    "\n",
    "#convert years back into integers for plot\n",
    "years_dt = []\n",
    "for i in years:\n",
    "    x = int(i[:-3])\n",
    "    years_dt.append(x)\n",
    "#create pandas dataframe\n",
    "df = pd.DataFrame.from_dict({'year':years_dt, 'irrigated area':area_a})#, '0.75+0.8':area_b, '0.70+0.75+0.8':area_c})\n",
    "df = df.set_index('year')\n",
    "df.to_csv(\"results/nmdb_plots/csvs/NMDB_annual_area.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot annual irrigated area\n",
    "fontsize = 17\n",
    "df = pd.read_csv(\"results/nmdb_plots/csvs/NMDB_annual_area.csv\", index_col=0)\n",
    "ax = df.plot(colormap='jet', linestyle='--', marker='o', legend=False,figsize=(20,8))\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "ax.set_xlabel('Year (Summer Nov-Mar)', fontsize=fontsize)\n",
    "ax.set_ylabel('Area under Irrigation ($10^5$ Ha)', fontsize=fontsize)\n",
    "ax.set_ylim(bottom=-int((df['irrigated area'].max()*0.05)), top=(df['irrigated area'].max()+(df['irrigated area'].max()*0.1)))\n",
    "ax.ticklabel_format(axis='y', style='sci', scilimits=(0, 3), useMathText=True)\n",
    "plt.tick_params(labelsize=fontsize)\n",
    "ax.grid(True, linestyle='--', alpha=0.75, color=\"gray\")\n",
    "ax.axvspan(2010, 2013, alpha=0.4, color='grey')\n",
    "ax.set_facecolor('cornsilk')\n",
    "ax.set_title(\"Northern MDB Annual Summer Irrigated Area\", fontsize=fontsize)\n",
    "#     plt.tight_layout()\n",
    "plt.savefig(\"results/nmdb_plots/plots/NMDB_annual_irrigated_area.pdf\",\n",
    "           orientation='landscape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-catchment plots\n",
    "\n",
    "This script will produce a timeseries of irrigated area for each subcatchment in the directory.  This script is slow to run beacause the geopandas overlay functions are cumbersome (this is true of other libraries as well). R-tree spatial indexing is NOT used as it is imprecise with the clip boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/g/data/r78/cb3058/dea-notebooks/ICE_project/results/nmdb/\"\n",
    "individual_catchments_dir =\"/g/data/r78/cb3058/dea-notebooks/ICE_project/data/spatial/nmdb_individual_catchments/\"\n",
    "suffix = \"_Irrigated_OEHandLS_masked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate all the filenames we need for the loops\n",
    "catchments = []\n",
    "for file in os.listdir(individual_catchments_dir):\n",
    "    if file.endswith(\".shp\"):\n",
    "        catchments.append(os.path.join(individual_catchments_dir, file))\n",
    "\n",
    "x = range(1987,2019,1)\n",
    "years = []\n",
    "for i in x:\n",
    "    nextyear = str(i + 1)[2:]\n",
    "    y = str(i) + \"_\" + nextyear\n",
    "    years.append(str(y))\n",
    "# removing years that didn't work due to bad satellite coverage\n",
    "years =  [e for e in years if e not in ('2011_12', '2012_13')]\n",
    "years.sort()\n",
    "\n",
    "years_dt = []\n",
    "for i in years:\n",
    "    x = int(i[:-3])\n",
    "    years_dt.append(x)\n",
    "\n",
    "folders = os.listdir(directory)\n",
    "folders.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multithreaded version\n",
    "def subcatchmentarea(catchment):\n",
    "    print(\"working on \"+ catchment[85:-4])\n",
    "    area_a = []\n",
    "    for year, folder in zip(years, folders): \n",
    "        #progress indicator\n",
    "        print(\"\\r\", \"working on \"+ catchment[85:-4] + \": \" + year, end = '')\n",
    "        #get the irrigated area shapefile\n",
    "        irr = gpd.read_file(directory+folder+\"/\"+\"nmdb_Summer\"+ year + suffix+\".shp\")\n",
    "        catch = gpd.read_file(catchment)\n",
    "        irr_clip = gpd.overlay(irr, catch, how='intersection')\n",
    "        area_a.append(irr_clip.area.sum() / 10000) \n",
    "    #create pandas dataframe\n",
    "    df = pd.DataFrame.from_dict({'year':years_dt, 'irr_area':area_a})\n",
    "    df = df.set_index('year')\n",
    "    df.to_csv(\"results/nmdb_plots/csvs/annual_area/\" + catchment[85:-4] + \"_annual_area.csv\", header=True)\n",
    "    print(\"finished \"+ catchment[85:-4])\n",
    "\n",
    "#singlethreaded version\n",
    "# for i in catchments:\n",
    "#     subcatchmentarea(i)\n",
    "\n",
    "# multithreaded version\n",
    "pool = Pool(4)    \n",
    "pool.map(subcatchmentarea, catchments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create plot and save\n",
    "folder = \"/g/data/r78/cb3058/dea-notebooks/ICE_project/results/nmdb_plots/csvs/annual_area/\"\n",
    "\n",
    "fig, axs = plt.subplots(5,2, figsize=(25, 30), facecolor='w', edgecolor='k')\n",
    "files = os.listdir(folder)\n",
    "files.sort()\n",
    "\n",
    "for ax,file in zip(axs.ravel(), files):\n",
    "    fontsize = 23\n",
    "    df = pd.read_csv(folder+file, index_col=0)\n",
    "    df.plot(ax=ax,colormap='jet', linestyle='--', marker='o', legend = False)\n",
    "    col_name = 'irr_area'\n",
    "    if file[:-16] == 'PAROO RIVER':\n",
    "        t = [200]\n",
    "        bottom = -10\n",
    "        top = 225\n",
    "        ax.set_ylim(bottom=bottom, top=top)\n",
    "        ax.set_yticks(t)\n",
    "        ax.set_yticklabels([str(i)+\" ha\" for i in t])\n",
    "        ax.tick_params(axis='y', direction='in', pad=-95)\n",
    "    elif file[:-16] == 'MOONIE RIVER':\n",
    "        t = [round(int(df[col_name].max()), -2)]\n",
    "        bottom = -100\n",
    "        top = df[col_name].max()+(df[col_name].max()*0.05)\n",
    "        ax.set_ylim(bottom=bottom, top=top)\n",
    "        ax.set_yticks(t)\n",
    "        ax.set_yticklabels([format(i,\",\")+\" ha\" for i in t])\n",
    "        ax.tick_params(axis='y', direction='in', pad=-110)\n",
    "    elif file[:-16] == 'CASTLEREAGH RIVER':\n",
    "        t = [round(int(df[col_name].max()), -2)]\n",
    "        bottom = -250\n",
    "        top = df[col_name].max()+(df[col_name].max()*0.05)\n",
    "        ax.set_ylim(bottom=bottom, top=top)\n",
    "        ax.set_yticks(t)\n",
    "        ax.set_yticklabels([format(i,\",\")+\" ha\" for i in t])\n",
    "        ax.tick_params(axis='y', direction='in', pad=-110)\n",
    "    elif file[:-16] == 'DARLING RIVER' or file[:-16] == 'WARREGO RIVER':\n",
    "        t = [round(int(df[col_name].max()), -2)]\n",
    "        bottom = -750\n",
    "        top = df[col_name].max()+(df[col_name].max()*0.05)\n",
    "        ax.set_ylim(bottom=bottom, top=top)\n",
    "        ax.set_yticks(t)\n",
    "        ax.set_yticklabels([format(i,\",\")+\" ha\" for i in t])\n",
    "        ax.tick_params(axis='y', direction='in', pad=-130)\n",
    "    else:\n",
    "        t = [round(int(df[col_name].max()), -3)]\n",
    "        bottom = -3000\n",
    "        top = df[col_name].max()+(df[col_name].max()*0.05)\n",
    "        ax.set_ylim(bottom=bottom, top=top)\n",
    "        ax.set_yticks(t)\n",
    "        ax.set_yticklabels([format(i,\",\")+\" ha\" for i in t])\n",
    "        ax.tick_params(axis='y', direction='in', pad=-145)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "    ax.xaxis.set_label_text(\"\")\n",
    "#     ax.grid(True, linestyle='--', alpha=0.75, axis='y', color=\"gray\")\n",
    "    ax.axvspan(2010, 2013, alpha=0.4, color='k')\n",
    "    ax.tick_params(length=8, width=4,labelsize=fontsize)\n",
    "    ax.set_title(file[:-16], fontsize=fontsize)\n",
    "    ax.set_facecolor('cornsilk')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results/nmdb_plots/plots/NMDB_annual_area_subcatchment.pdf\",\n",
    "   orientation='portrait', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumualtive growth in new irrigated areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The script is divided into four sections\n",
    "\n",
    "1. The first section cumulatively unions the annual irrigated area files. ie. years 1987-1988 are unioned, then 1987-88-89, then 1987-88-89-90 etc. These unioned shapefiles are exported to a folder called 'interim-NMDB'. This code will take hours to run.\n",
    "\n",
    "2. The second part of the script finds the difference in irrigated area between adjacent time ranges. ie. difference between '1987-88' and '1987-88-89,' etc.  Shapefiles of the difference are exported. The cumulative sum is then computed on these areal differences, and the result is added to a dataframe and exported as a csv file. This section will take a few hours to complete\n",
    "\n",
    "3. The 3rd part of the script clips the results of part 2 to each subcatchment and finds the cumulative sum, exporting the results as a csv.\n",
    "\n",
    "4. Plotting of the sub-catchment cumulative trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/g/data/r78/cb3058/dea-notebooks/ICE_project/results/nmdb/\"\n",
    "individual_catchments_dir =\"data/spatial/nmdb_individual_catchments/\"\n",
    "AOI = \"nmdb_Summer\"\n",
    "interim_results = \"results/nmdb_plots/shapes/interim_NMDB/\"\n",
    "suffix = \"_Irrigated_OEHandLS_masked\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1.\n",
    "\n",
    "Creating the cumulatively unioned files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of time strings for function\n",
    "timerangelist = [str(t) for t in range(1987,2019,1)]\n",
    "timerangelist = [e for e in timerangelist if e not in ('2011', '2012')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulativelyUnion(timerangelist, shapes):\n",
    "    for t in timerangelist:\n",
    "        print(\"\\r\", \"working on \"+t, end = '')\n",
    "        #open the year and add it to a list\n",
    "        nextyear= str(int(t)+1)[2:]\n",
    "        irr = gpd.read_file(directory+AOI+t+\"_\"+nextyear+\"/\"+AOI+t+\"_\"+nextyear+suffix+\".shp\")\n",
    "        shapes.append(irr)\n",
    "        print(\"..length of [shapes] = \"+str(len(shapes)))\n",
    "        #now do the concatentation & dissolve\n",
    "        x = pd.concat(shapes)\n",
    "        x['DISS_ID'] = 1\n",
    "        x = x.dissolve(by='DISS_ID', aggfunc='sum')\n",
    "        x['year_range'] = \"1987_\" + t\n",
    "        x['catchment'] = \"NMDB\"\n",
    "        print(\"...exporting \"+t)\n",
    "        x.to_file(interim_results+\"/NMDB_1987_\"+t+\".shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes=[]\n",
    "cumulativelyUnion(timerangelist,shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2. \n",
    "\n",
    "calculate cumulative new area for entire basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def areaofFirstYear(area_list):\n",
    "    #open the first timerange\n",
    "    firstyear = gpd.read_file(interim_results + \"/NMDB_1987_1987.shp\")\n",
    "    area_list.append((firstyear.area.sum()/ 10000))\n",
    "        \n",
    "def getdifferenceAreas(yr1, yr2, area_list):\n",
    "    df1 = gpd.read_file(interim_results+\"/NMDB_1987_\"+ yr1 + \".shp\")\n",
    "    df2 = gpd.read_file(interim_results+\"/NMDB_1987_\"+ yr2 + \".shp\")\n",
    "    diff = gpd.overlay(df2, df1, how='difference')\n",
    "    diff = diff.explode() #need to explode to filter for small areas\n",
    "    diff['area_diff'] = diff\n",
    "    toosmall = diff['area_diff'] >= 100000 #less than 10ha\n",
    "    diff = diff[toosmall]\n",
    "    print(\"...exporting \"+yr2+\"_minus_\"+yr1)\n",
    "    diff.to_file(\"results/nmdb_plots/shapes/difference_NMDB/NMDB_\"+yr2+\"_minus_\"+yr1+\".shp\")\n",
    "    area_list.append(float(diff.area.sum() / 10000))\n",
    "        \n",
    "def runpart2(area_list):\n",
    "    areaofFirstYear(area_list)\n",
    "    for i in range(1, len(timerangelist)):\n",
    "        print(\"\\r\", \"working on \"+ timerangelist[i], end = '')\n",
    "        getdifferenceAreas(timerangelist[i-1],timerangelist[i], area_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_list = []\n",
    "os.mkdir(\"results/nmdb_plots/shapes/difference_NMDB\")\n",
    "runpart2(area_list)\n",
    "\n",
    "#create empty dataframe to add results too\n",
    "df = pd.DataFrame(index=timerangelist)\n",
    "df['NMDB'] = area_list\n",
    "df = df.cumsum(axis = 0)\n",
    "df.to_csv(\"results/nmdb_plots/csvs/NMDB_cumulative_area.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative whole-of-catchment plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 17\n",
    "df = pd.read_csv(\"results/nmdb_plots/csvs/NMDB_cumulative_area.csv\", index_col=0)\n",
    "ax = df.plot(colormap='jet', linestyle='--', marker='o', legend=False,figsize=(20,8))\n",
    "# ax.xaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "ax.set_xlabel('Year Range', fontsize=fontsize)\n",
    "ax.set_ylabel('Irrigatable Area ($10^6$ Ha)', fontsize=fontsize)\n",
    "ax.ticklabel_format(axis='y', style='sci', scilimits=(0, 3), useMathText=True)\n",
    "ax.set_ylim(bottom=int((df['NMDB'].max()*0.35)), top=(df['NMDB'].max()+(df['NMDB'].max()*0.05)))\n",
    "plt.tick_params(labelsize=fontsize)\n",
    "ax.grid(True, linestyle='--', alpha=0.75, color=\"gray\")\n",
    "ax.axvspan(2010, 2013, alpha=0.4, color='grey')\n",
    "ax.set_facecolor('cornsilk')\n",
    "ax.set_title(\"Northern MDB Cumulative Irrigable area\", fontsize=fontsize)\n",
    "# plt.tight_layout()\n",
    "plt.savefig(\"results/nmdb_plots/plots/NMDB_cumulative_area.pdf\",\n",
    "           orientation='landscape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 \n",
    "\n",
    "Subcatchment cumulative area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset the location strings\n",
    "individual_catchments_dir =\"data/spatial/nmdb_individual_catchments/\"\n",
    "basin_epochs = \"results/nmdb_plots/shapes/difference_NMDB/\"\n",
    "\n",
    "# create list of time strings for function\n",
    "timerangelist = [str(t) for t in range(1987,2019,1)]\n",
    "timerangelist = [e for e in timerangelist if e not in ('2011', '2012')]\n",
    "\n",
    "#get a list of catchment names as input to functions\n",
    "catchments = []\n",
    "for file in os.listdir(individual_catchments_dir):\n",
    "    if file.endswith(\".shp\"):\n",
    "        catchments.append(file[:-4])\n",
    "\n",
    "#create list of catchment shapefiles\n",
    "catchment_shps = []\n",
    "for file in os.listdir(individual_catchments_dir):\n",
    "    if file.endswith(\".shp\"):\n",
    "        catchment_shps.append(os.path.join(individual_catchments_dir, file))\n",
    "\n",
    "#get list of NMDB difference files \n",
    "epochs = []\n",
    "for file in os.listdir(basin_epochs):\n",
    "    if file.endswith(\".shp\"):\n",
    "        epochs.append(os.path.join(basin_epochs, file))\n",
    "epochs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for catch_shp, catchment in zip(catchment_shps, catchments):\n",
    "    area_list = []\n",
    "    try:\n",
    "        print(\"; working on \" + catchment)\n",
    "        clipBoundary = gpd.read_file(catch_shp)\n",
    "        firstyear = gpd.read_file(interim_results+ \"NMDB_1987_1987.shp\")\n",
    "        firstYearClip = gpd.overlay(firstyear, clipBoundary, how='intersection')\n",
    "        area_list.append((firstYearClip.area.sum()/ 10000))\n",
    "    except:\n",
    "        area_list.append(0)\n",
    "\n",
    "    for epoch in epochs:\t\n",
    "        print(\"\\r\", \" \"+ epoch[47:62], end = '')\n",
    "        catch = gpd.read_file(catch_shp)\n",
    "        irr = gpd.read_file(epoch)\n",
    "        diff = gpd.overlay(irr, catch, how='intersection')\n",
    "        area_list.append(float(diff.area.sum() / 10000))\n",
    "    \n",
    "    df = pd.DataFrame(index=timerangelist)\n",
    "    df[catchment] = area_list\n",
    "    df = df.cumsum(axis = 0)\n",
    "    df.to_csv(\"results/nmdb_plots/csvs/cumulative/\" + catchment + \"_cumulative_area.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4 \n",
    "\n",
    "plotting of sub-catchment cumulative area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot and save\n",
    "folder = \"results/nmdb_plots/csvs/cumulative/\"\n",
    "\n",
    "fig, axs = plt.subplots(5,2, figsize=(25, 30), edgecolor='k')\n",
    "files = os.listdir(folder)\n",
    "files.sort()\n",
    "for ax,file in zip(axs.ravel(), files):\n",
    "    fontsize = 23\n",
    "    df = pd.read_csv(folder+file, index_col=0)\n",
    "    df.plot(ax=ax,colormap='jet', linestyle='--', marker='o', legend = False)\n",
    "    if file[:-20] == 'PAROO RIVER':\n",
    "        t = [10, 200]\n",
    "        bottom = -10\n",
    "        top = 225\n",
    "        ax.set_ylim(bottom=bottom, top=top)\n",
    "        ax.set_yticks(t)\n",
    "        ax.set_yticklabels([str(i)+\" ha\" for i in t])\n",
    "        ax.tick_params(axis='y', direction='in', pad=-100)\n",
    "    elif file[:-20] == 'MOONIE RIVER':\n",
    "        t = [600, round(int(df[file[:-20]].max()), -2)]\n",
    "        bottom = df[file[:-20]].min() - df[file[:-20]].min()*0.025\n",
    "        top = df[file[:-20]].max()+(df[file[:-20]].max()*0.05)\n",
    "        ax.set_ylim(bottom=bottom, top=top)\n",
    "        ax.set_yticks(t)\n",
    "        ax.set_yticklabels([format(i,\",\")+\" ha\" for i in t])\n",
    "        ax.tick_params(axis='y', direction='in', pad=-115)\n",
    "    elif file[:-20] == 'CASTLEREAGH RIVER':\n",
    "        t = [round(int(df[file[:-20]].min()), -2) , round(int(df[file[:-20]].max()), -3)]\n",
    "        bottom = df[file[:-20]].min() - df[file[:-20]].min()*0.3\n",
    "        top = df[file[:-20]].max()+(df[file[:-20]].max()*0.1)\n",
    "        ax.set_ylim(bottom=bottom, top=top)\n",
    "        ax.set_yticks(t)\n",
    "        ax.set_yticklabels([format(i,\",\")+\" ha\" for i in t])\n",
    "        ax.tick_params(axis='y', direction='in', pad=-120)\n",
    "    elif file[:-20] == 'WARREGO RIVER':\n",
    "        t = [round(int(df[file[:-20]].min()), -3) , round(int(df[file[:-20]].max()), -3)]\n",
    "        bottom = df[file[:-20]].min() - df[file[:-20]].min()*0.2\n",
    "        top = df[file[:-20]].max()+(df[file[:-20]].max()*0.075)\n",
    "        ax.set_ylim(bottom=bottom, top=top)\n",
    "        ax.set_yticks(t)\n",
    "        ax.set_yticklabels([format(i,\",\")+\" ha\" for i in t])\n",
    "        ax.tick_params(axis='y', direction='in', pad=-145)\n",
    "    elif file[:-20] == 'DARLING RIVER':\n",
    "        t = [round(int(df[file[:-20]].min()), -3) , round(int(df[file[:-20]].max()), -3)]\n",
    "        bottom = df[file[:-20]].min() - df[file[:-20]].min()*0.25\n",
    "        top = df[file[:-20]].max()+(df[file[:-20]].max()*0.05)\n",
    "        ax.set_ylim(bottom=bottom, top=top)\n",
    "        ax.set_yticks(t)\n",
    "        ax.set_yticklabels([format(i,\",\")+\" ha\" for i in t])\n",
    "        ax.tick_params(axis='y', direction='in', pad=-145)\n",
    "    else:\n",
    "        t = [round(int(df[file[:-20]].min()), -3) , round(int(df[file[:-20]].max()), -3)]\n",
    "        bottom = df[file[:-20]].min() - df[file[:-20]].min()*0.1\n",
    "        top = df[file[:-20]].max()+(df[file[:-20]].max()*0.05)\n",
    "        ax.set_ylim(bottom=bottom, top=top)\n",
    "        ax.set_yticks(t)\n",
    "        ax.set_yticklabels([format(i,\",\")+\" ha\" for i in t])\n",
    "        ax.tick_params(axis='y', direction='in', pad=-145)\n",
    "    ax.xaxis.set_label_text(\"\")\n",
    "    ax.tick_params(length=10, width=3, labelsize=fontsize)\n",
    "    ax.set_title(file[:-20], fontsize=fontsize)\n",
    "    ax.axvspan(2010, 2013, alpha=0.4, color='grey')\n",
    "    ax.set_facecolor('cornsilk')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results/nmdb_plots/plots/NMDB_cumulative_area_subcatchment.pdf\",\n",
    "   orientation='portrait', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change in Irrigable Area\n",
    "\n",
    "This script will union 3 successive years of the annual irrigation files and then calculate the area through time\n",
    "- Part 1 does the entire basin\n",
    "- Part 2 clips the analysis to sub-catchments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/g/data/r78/cb3058/dea-notebooks/ICE_project/results/nmdb/\"\n",
    "individual_catchments_dir =\"data/spatial/nmdb_individual_catchments/\"\n",
    "AOI = \"nmdb_Summer\"\n",
    "interim_results = \"results/nmdb_plots/shapes/threeYearUnion/\"\n",
    "suffix = \"_Irrigated_OEHandLS_masked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of time strings for function\n",
    "t1 = [str(t) for t in range(1987,1990,1)]\n",
    "t2 = [str(t) for t in range(1990,1993,1)]\n",
    "t3 = [str(t) for t in range(1993,1996,1)]\n",
    "t4 = [str(t) for t in range(1996,1999,1)]\n",
    "t5 = [str(t) for t in range(1999,2002,1)]\n",
    "t6 = [str(t) for t in range(2002,2005,1)]\n",
    "t7 = [str(t) for t in range(2005,2008,1)]\n",
    "t8 = [str(t) for t in range(2008,2011,1)]\n",
    "t9 = [str(t) for t in range(2013,2016,1)]\n",
    "t10 = [str(t) for t in range(2016,2019,1)]\n",
    "\n",
    "timerangelist=[t1,t2,t3,t4,t5,t6,t7,t8,t9,t10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through the irrigation files and union every 3 years, \n",
    "#exporting the unioned shapefile and calculating area \n",
    "area = []\n",
    "for timerange in timerangelist:\n",
    "    print(\"\\r\", 'working on ' + timerange[0]+\"_\"+timerange[-1], end ='')\n",
    "    shapes = []\n",
    "    year1 = str(int(timerange[0]))\n",
    "    year2 = str(int(timerange[1]))\n",
    "    year3 = str(int(timerange[2]))\n",
    "    y1_shp = gpd.read_file(directory+AOI+year1+\"_\"+str(int(year1)+1)[2:]+\"/\"+AOI+year1+\"_\"+str(int(year1)+1)[2:]+suffix+\".shp\")\n",
    "    y2_shp = gpd.read_file(directory+AOI+year2+\"_\"+str(int(year2)+1)[2:]+\"/\"+AOI+year2+\"_\"+str(int(year2)+1)[2:]+suffix+\".shp\")\n",
    "    y3_shp = gpd.read_file(directory+AOI+year3+\"_\"+str(int(year3)+1)[2:]+\"/\"+AOI+year3+\"_\"+str(int(year3)+1)[2:]+suffix+\".shp\")\n",
    "    shapes.extend([y1_shp, y2_shp]) #yr3_shp\n",
    "    x = pd.concat(shapes)\n",
    "    x['DISS_ID'] = 1\n",
    "    x = x.dissolve(by='DISS_ID', aggfunc='sum')\n",
    "    x['year_range'] = timerange[0]+\"_\"+timerange[-1]\n",
    "    area.append(x.area.sum()/10000)\n",
    "    print('; exporting shapefile')\n",
    "    x.to_file(interim_results+timerange[0]+\"_\"+timerange[-1]+\"_twoYearUnion.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threeyearstrings = ['1987_1989','1990_1992', '1993_1995','1996_1998', '1999_2001', \n",
    "                   '2002_2004','2005_2007', '2008_2010', '2013_2015','2016_2018']\n",
    "\n",
    "df = pd.DataFrame.from_dict({'Year Range':threeyearstrings, 'Irrigated Area (ha)':area})\n",
    "df = df.set_index('Year Range')\n",
    "df.to_csv(\"results/nmdb_plots/csvs/NMDB_twoYearUnion_area.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"results/nmdb_plots/csvs/NMDB_threeYearUnion_area.csv\", index_col ='Year Range')\n",
    "df2 = pd.read_csv(\"results/nmdb_plots/csvs/NMDB_twoYearUnion_area.csv\", index_col ='Year Range')\n",
    "\n",
    "fig = plt.figure(figsize=(20,12))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax1.plot(df1, color='blue', linestyle='--', marker='o')\n",
    "ax2.plot(df2, color='blue', linestyle='--', marker='o')\n",
    "ax1.set_ylim(400000,850000)\n",
    "ax1.set_ylabel('Ha')\n",
    "ax1.grid(True, linestyle='--', alpha=0.75, color=\"gray\")\n",
    "ax2.grid(True, linestyle='--', alpha=0.75, color=\"gray\")\n",
    "ax2.set_ylim(400000,850000)\n",
    "ax2.set_ylabel('Ha')\n",
    "ax1.set_title('Three Year Union')\n",
    "ax2.set_title('Two Year Union')\n",
    "plt.savefig(\"results/nmdb_plots/plots/NMDB_unioned_irrigated_Area.pdf\",\n",
    "           orientation='landscape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "Subcatchments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset the location strings\n",
    "individual_catchments_dir =\"data/spatial/nmdb_individual_catchments/\"\n",
    "basin_epochs = \"results/nmdb_plots/shapes/threeYearUnion/\"\n",
    "\n",
    "# create list of time strings for function\n",
    "timerangelist = [str(t) for t in range(1987,2019,1)]\n",
    "timerangelist = [e for e in timerangelist if e not in ('2011', '2012')]\n",
    "\n",
    "#get a list of catchment names as input to functions\n",
    "catchments = []\n",
    "for file in os.listdir(individual_catchments_dir):\n",
    "    if file.endswith(\".shp\"):\n",
    "        catchments.append(file[:-4])\n",
    "\n",
    "#create list of catchment shapefiles\n",
    "catchment_shps = []\n",
    "for file in os.listdir(individual_catchments_dir):\n",
    "    if file.endswith(\".shp\"):\n",
    "        catchment_shps.append(os.path.join(individual_catchments_dir, file))\n",
    "\n",
    "#get list of NMDB difference files \n",
    "epochs = []\n",
    "for file in os.listdir(basin_epochs):\n",
    "    if file.endswith(\".shp\"):\n",
    "        epochs.append(os.path.join(basin_epochs, file))\n",
    "epochs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "threeyearstrings = ['1987_1989','1990_1992', '1993_1995','1996_1998', '1999_2001', \n",
    "                   '2002_2004','2005_2007', '2008_2010', '2013_2015','2016_2018']\n",
    "\n",
    "for catch_shp, catchment in zip(catchment_shps, catchments):\n",
    "    area_list = []\n",
    "    print(catchment)\n",
    "    for epoch in epochs:\t\n",
    "        print(\"\\r\", \" \"+ epoch[41:50], end = '')\n",
    "        catch = gpd.read_file(catch_shp)\n",
    "        irr = gpd.read_file(epoch)\n",
    "        diff = gpd.overlay(irr, catch, how='intersection')\n",
    "        area_list.append(float(diff.area.sum() / 10000))\n",
    "    \n",
    "    df = pd.DataFrame(index=threeyearstrings)\n",
    "    df[catchment] = area_list\n",
    "    df.to_csv(\"results/nmdb_plots/csvs/unioned_areas/\" + catchment + \"_threeYearUnioned_area.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
