{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of Annual Summer Irrigated Cropping Area (SICA)\n",
    "Using a variety of measures. Firstly, compare the overall area between the validation dataset and the prediction dataset, secondly calculate a Jaccard Similarity Score to test how similar the two datasets are, then generate confusion matrix with a number of measures describing the precion, omission, commission, accuracy etc.\n",
    "\n",
    "Relying on Claire Kraus's notebook for guidance:\n",
    "\n",
    "https://github.com/GeoscienceAustralia/dea-notebooks/blob/ClaireK/Crop_mapping/NamoiPilotProjectWorkflow/ValidateAutomaticIrrigatedCropAreaGeotiffs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import custom functions\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "import DEAPlotting, SpatialTools\n",
    "from transform_tuple import transform_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provide the filepaths to the irrigated cropping extent tif and the validation shapefile\n",
    "irrigated = \"/g/data/r78/cb3058/dea-notebooks/ICE_project/results/nmdb/nmdb_Summer1993_94/nmdb_Summer1993_94_multithreshold_masked.tif\"\n",
    "\n",
    "validation = \"/g/data/r78/cb3058/dea-notebooks/ICE_project/data/spatial/merged_IrrigatedCrop_1993110.shp\"\n",
    "\n",
    "clip_shp = \"/g/data/r78/cb3058/dea-notebooks/ICE_project/data/spatial/validation_boundary.shp\"\n",
    "\n",
    "#what year are we validating\n",
    "year = '1993-94'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the irrigatation tif\n",
    "irr  = xr.open_rasterio(irrigated).drop('band').squeeze()\n",
    "#grab some transform info from it\n",
    "transform, projection = transform_tuple(irr, (irr.x, irr.y), epsg=3577)\n",
    "width,height = irr.shape\n",
    "#rasterize the catchment boundaries that encompass our validation area\n",
    "boundary = SpatialTools.rasterize_vector(clip_shp, height, width,\n",
    "                                         transform, projection, raster_path=None)\n",
    "#clip extent to the catchment boundaries\n",
    "irr = irr.where(boundary)\n",
    "#convert to a boolean array of irr/not-irr\n",
    "AutomaticCropBoolean  = np.isfinite(irr.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert validation shapefile to array first\n",
    "ValidationMaskBoolean  = SpatialTools.rasterize_vector(validation, height, width,\n",
    "                                            transform, projection, raster_path=None)\n",
    "# ValidationMaskBoolean = np.where(boundary, ValidationMaskBoolean, 0\n",
    "ValidationMaskBoolean = ValidationMaskBoolean.astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-site specific accuracy (compare areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_area = np.count_nonzero(ValidationMaskBoolean) *(25*25) / 10000\n",
    "irrigated_area = np.count_nonzero(AutomaticCropBoolean)*(25*25) / 10000\n",
    "print(\"The area under irrigation in the vali  dation dataset is: \" + str(validation_area) + \" ha\")\n",
    "print(\"The area under irrigation in the irrigated area dataset is: \" + str(irrigated_area) + \" ha\")\n",
    "print(\"irrigated vs validation % is : \" + str(round((irrigated_area/validation_area*100), 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Similarity index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, jaccard_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jss = jaccard_similarity_score(ValidationMaskBoolean, AutomaticCropBoolean, normalize=True)\n",
    "# ac = accuracy_score(ValidationMaskBoolean, AutomaticCropBoolean, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Normalised Jaccard Similarity Score is: \"+ str(round(ac, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YesRealYesAuto = np.logical_and(AutomaticCropBoolean, ValidationMaskBoolean)\n",
    "NoRealNoAuto = np.logical_and(~AutomaticCropBoolean, ~ValidationMaskBoolean)\n",
    "\n",
    "YesRealNoAuto = np.logical_and(AutomaticCropBoolean, ~ValidationMaskBoolean)\n",
    "NoRealYesAuto = np.logical_and(~AutomaticCropBoolean, ValidationMaskBoolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Correct_positives = YesRealYesAuto.sum()\n",
    "Incorrect_positives = NoRealYesAuto.sum()\n",
    "Correct_negatives = NoRealNoAuto.sum()\n",
    "Incorrect_negatives = YesRealNoAuto.sum()\n",
    "\n",
    "Totalpixels = (width * height)\n",
    "\n",
    "Accuracy = (Correct_positives + Correct_negatives) / Totalpixels\n",
    "Misclassification_rate = (Incorrect_positives + Incorrect_negatives) / Totalpixels\n",
    "True_Positive_Rate = Correct_positives / ValidationMaskBoolean.sum()\n",
    "False_Positive_Rate = Correct_positives / ((~ValidationMaskBoolean).sum())\n",
    "Specificity = Correct_negatives / ((~ValidationMaskBoolean).sum())\n",
    "Precision = Correct_positives / AutomaticCropBoolean.sum()\n",
    "Prevalence = (ValidationMaskBoolean.sum() ) / Totalpixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1m' + '{0} Automatic Irrigated Crop Extent'.format(year) + '\\033[0m')\n",
    "print('Accuracy = %.5f' % Accuracy)\n",
    "print('Misclassification_rate = %.5f' % Misclassification_rate)\n",
    "print('True_Positive_Rate = %.5f' % True_Positive_Rate)\n",
    "print('False_Positive_Rate = %.5f' % False_Positive_Rate)\n",
    "print('Specificity = %.5f' % Specificity)\n",
    "print('Precision = %.5f' % Precision)\n",
    "print('Prevalence = %.5f' % Prevalence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
