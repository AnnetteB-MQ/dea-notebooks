{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from osgeo import gdal, ogr, gdal_array\n",
    "import dask\n",
    "import datacube \n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from datacube.storage import masking\n",
    "from datacube.utils import geometry\n",
    "import os\n",
    "#import custom functions\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "import DEAPlotting, SpatialTools, BandIndices, DEADataHandling\n",
    "from load_data import load_data\n",
    "from transform_tuple import transform_tuple\n",
    "from query_from_shp import query_from_shp\n",
    "from rsgislib.segmentation import segutils\n",
    "from rasterstats import zonal_stats\n",
    "from imageSeg import imageSeg\n",
    "import fiona\n",
    "import rasterio.features\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where is your data and results folder?\n",
    "results = \"results/\"\n",
    "# data = 'data/'\n",
    "\n",
    "sensors = ['ls5','ls7','ls8']\n",
    "\n",
    "#are we using a polygon to mask the AOI?\n",
    "shp_fpath = 'data/spatial/murrumbidgee_boundingbox.shp'\n",
    "\n",
    "#Input your area of interest's name, coords, and \n",
    "#the year you're interested in?\n",
    "AOI = 'Murrum_randomForest'\n",
    "year = 'Winter2013'\n",
    "\n",
    "time_period = ('2013-05-01', '2013-09-30')\n",
    "\n",
    "#What thresholds should I use?\n",
    "threshold = 0.8\n",
    "wofs_theshold = 0.15\n",
    "#-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a folder to keep things neat\n",
    "directory = results + AOI + \"_\" + year\n",
    "if not os.path.exists(directory):\n",
    "    os.mkdir(directory)\n",
    "\n",
    "results = results + AOI + \"_\" + year + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up query\n",
    "query = query_from_shp(shp_fpath, time_period[0], time_period[1], dask_chunks = 500)\n",
    "#landsat\n",
    "# dc = datacube.Datacube(app='dc_name')\n",
    "# landsat = DEADataHandling.load_clearlandsat(dc,query=query, sensors=sensors, product='nbart',\n",
    "#                        masked_prop=0.75)\n",
    "\n",
    "landsat = load_data(dc_name = 'irrigated_areas', sensors=sensors, export_name = 'fh',query=query)\n",
    "#wofs\n",
    "# dc = datacube.Datacube(app='wofs')\n",
    "# del query['time'] \n",
    "# wofs_alltime = dc.load(product = 'wofs_summary', **query)\n",
    "\n",
    "#masking the returned array to the polygon area\n",
    "with fiona.open(shp_fpath) as shapes:\n",
    "        crs = geometry.CRS(shapes.crs_wkt)\n",
    "        first_geometry = next(iter(shapes))['geometry']\n",
    "        geom = geometry.Geometry(first_geometry, crs=crs)\n",
    "\n",
    "mask = rasterio.features.geometry_mask([geom.to_crs(landsat.geobox.crs) for geoms in [geom]],\n",
    "                                           out_shape=landsat.geobox.shape,\n",
    "                                           transform=landsat.geobox.affine,\n",
    "                                           all_touched=False,\n",
    "                                           invert=True)\n",
    "# Mask the xarrays\n",
    "landsat = landsat.where(mask)\n",
    "#wofs_alltime = wofs_alltime.where(mask)\n",
    "#datacube.storage.storage.write_dataset_to_netcdf(landsat, results + AOI \"_\" + year + '.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#band indices calculation\n",
    "def ndvi_ufunc(ds):\n",
    "    def ndvi_func(nir, red):\n",
    "        return ((nir - red)/(nir + red))\n",
    "    \n",
    "    return xr.apply_ufunc(\n",
    "        ndvi_func, ds.nir, ds.red,\n",
    "        dask='parallelized',\n",
    "        output_dtypes=[float])\n",
    "\n",
    "def brightness_ufunc(ds):\n",
    "    def brightness_func(g,r,nir,swir):\n",
    "        return (g**2 + r**2 + nir**2 + swir**2)**(1/2.0)\n",
    "    \n",
    "    return xr.apply_ufunc(\n",
    "        brightness_func, ds.green,ds.red, ds.nir, ds.swir1,\n",
    "        dask='parallelized',\n",
    "        output_dtypes=[float])\n",
    "\n",
    "NDVI_landsat = ndvi_ufunc(landsat)\n",
    "brightness_landsat = brightness_ufunc(landsat)\n",
    "NDMI_landsat = BandIndices.calculate_indices(landsat, index='NDMI-nir')\n",
    "\n",
    "#calculate NDVI & NDMI stats\n",
    "print('calculating NDVI & NDMI stats')\n",
    "NDVI_max = NDVI_landsat.max('time').rename('NDVI_max')\n",
    "NDVI_mean = NDVI_landsat.mean('time').rename('NDVI_mean')\n",
    "NDVI_std = NDVI_landsat.std('time').rename('NDVI_std')\n",
    "NDVI_min = NDVI_landsat.min('time').rename('NDVI_min')\n",
    "NDVI_range = NDVI_max - NDVI_min\n",
    "NDVI_range = NDVI_range.rename('NDVI_range')\n",
    "\n",
    "NDMI_max = NDMI_landsat.max('time').rename('NDMI_max')\n",
    "NDMI_mean = NDMI_landsat.mean('time').rename('NDMI_mean')\n",
    "NDMI_std = NDMI_landsat.std('time').rename('NDMI_std')\n",
    "NDMI_min = NDMI_landsat.min('time').rename('NDMI_min')\n",
    "\n",
    "#brightness stats\n",
    "print('calculating brightness stats')\n",
    "brightness_max = brightness_landsat.max('time').rename('brightness_max')\n",
    "brightness_mean = brightness_landsat.mean('time').rename('brightness_mean')\n",
    "brightness_std = brightness_landsat.std('time').rename('brightness_std')\n",
    "brightness_min = brightness_landsat.min('time').rename('brightness_min')\n",
    "\n",
    "print('calculating rate and argmax,min')\n",
    "NDVI_landsat_resample = NDVI_landsat.resample(time='M').mean('time')\n",
    "def nanarg(xarr, dim, stat):\n",
    "    \"\"\"\n",
    "    Deals with all-NaN slices by first identifying the offending cells\n",
    "    to create a mask, then filling NaNs with an integer to calculate\n",
    "    nanargmax(min), then masking out all-NaN cells using the mask.\n",
    "    The fill number is set such that it will never be returned as the min\n",
    "    or max of the argmax(min).\n",
    "    \"\"\"\n",
    "    mask = xarr.min(dim=dim, skipna=True).isnull()\n",
    "    if stat=='max':\n",
    "        fill = np.nanmin(xarr.values) -1\n",
    "        y = xarr.fillna(fill)\n",
    "        y = y.argmax(dim=dim, skipna=True).astype(float)\n",
    "        y = y.where(~mask)\n",
    "        return y\n",
    "    if stat == 'min':\n",
    "        fill = np.nanmax(xarr.values) + 1\n",
    "        y = xarr.fillna(fill)\n",
    "        y = y.argmin(dim=dim, skipna=True).astype(float)\n",
    "        y = y.where(~mask)\n",
    "        return y\n",
    "\n",
    "timeofmax = nanarg(NDVI_landsat_resample,dim ='time', stat='max')\n",
    "timeofmin = nanarg(NDVI_landsat_resample,dim ='time', stat='min')\n",
    "\n",
    "rate = (NDVI_max-NDVI_min)/(timeofmax - timeofmin)\n",
    "rate = rate.where(~np.isinf(rate), other=3) #remove unreasonable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xray_list = [NDVI_max, NDVI_mean, NDVI_std, NDVI_min, NDVI_range,\n",
    "             NDMI_max, NDMI_mean, NDMI_std, NDMI_min,timeofmax, timeofmin, rate,\n",
    "             brightness_max, brightness_mean, brightness_std, brightness_std]\n",
    "names = ['NDVI_max', 'NDVI_mean', 'NDVI_std', 'NDVI_min', 'NDVI_range',\n",
    "         'NDMI_max', 'NDMI_mean', 'NDMI_std', 'NDMI_min','timeofmax', 'timeofmin','rate',\n",
    "            'brightness_max', 'brightness_mean', 'brightness_std', 'brightness_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to numpy arrays (SLOW BECAUSE DASK ARRAYS ARE COMPUTED)\n",
    "x,y = NDVI_max.shape\n",
    "z = len(xray_list)\n",
    "img = np.zeros((x,y,z))\n",
    "count=0\n",
    "for b,c in zip(xray_list, range(img.shape[2])):\n",
    "    count += 1\n",
    "    progress = round((count/z) * 100, 3)\n",
    "    print(\"\\r\", \"adding slice: \" + str(count) + \", \" + str(progress) + \"%\" + \" complete. \", end = '')\n",
    "    img[:, :, c] = b.values \n",
    "    \n",
    "img_noNaNs = np.nan_to_num(img) #remove nans as they f/w classifier\n",
    "np.save(results + 'img_noNaNs_winter2013.npy', img_noNaNs) #save it as binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we need to load back in the trained RF model:\n",
    "from joblib import load\n",
    "rf = load(results + 'murrumbidgee_rfModel.joblib')\n",
    "\n",
    "# img_noNaNs = np.where(img_noNaNs >1.0e+307, 3, img_noNaNs) #run this if rate is being a bastard\n",
    "\n",
    "# Take our full image, and reshape into long 2d array (nrow * ncol, nband) for classification\n",
    "new_shape = (img_noNaNs.shape[0] * img_noNaNs.shape[1], img_noNaNs.shape[2])\n",
    "\n",
    "img_as_array = img_noNaNs[:, :, :z].reshape(new_shape)\n",
    "print('Reshaped from {o} to {n}'.format(o=img_noNaNs.shape,\n",
    "                                        n=img_as_array.shape))\n",
    "\n",
    "# Now predict for each pixel\n",
    "print('generating prediction')\n",
    "class_prediction = rf.predict(img_as_array)\n",
    "\n",
    "# Reshape our classification map\n",
    "class_prediction = class_prediction.reshape(img_noNaNs[:, :, 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a plot of the predictions\n",
    "import matplotlib.patches as mpatches\n",
    "values = np.unique(class_prediction.ravel())\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(121)\n",
    "im = plt.imshow(class_prediction, interpolation='none')\n",
    "# colors = [im.cmap(im.norm(value)) for value in values]\n",
    "# patches = [ mpatches.Patch(color=colors[i], label=\"Level {l}\".format(l=values[i]) ) for i in range(len(values)) ]\n",
    "# plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0. )\n",
    "\n",
    "plt.subplot(122)\n",
    "irr = np.where(class_prediction==430, 1, 0)\n",
    "plt.imshow(irr)\n",
    "plt.title('Irrigation Pixels Only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export out the results\n",
    "transform, projection = transform_tuple(NDVI_max, (NDVI_max.x, NDVI_max.y), epsg=3577)\n",
    "SpatialTools.array_to_geotiff(results + AOI + \"_\" + year + \"classpredict_handtrain_winter2013.tif\",\n",
    "              class_prediction, geo_transform = transform, \n",
    "              projection = projection, nodata_val=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_predict = xr.open_rasterio(results + AOI + \"_\" + year + \"classpredict_handtrain_winter2013.tif\")\n",
    "class_predict = class_predict.squeeze()\n",
    "\n",
    "gdf = gpd.read_file(results + AOI + '_' + year + '_SEGpolygons.shp')\n",
    "#calculate majority values inside segments\n",
    "gdf['majority'] = pd.DataFrame(zonal_stats(vectors=gdf['geometry'], raster=results + AOI + \"_\" + year + \"classpredict_handtrain_winter2013.tif\", stats='majority'))['majority']\n",
    "#calculate area of polygons\n",
    "gdf['area'] = gdf['geometry'].area\n",
    "#filter by area and majority values\n",
    "smallArea = gdf['area'] <= 5500000\n",
    "irrigated = gdf['majority'] == 430.0 #filtering for irrigated areas only\n",
    "gdf = gdf[smallArea&irrigated]\n",
    "#export shapefile\n",
    "gdf.to_file(results + AOI + \"_\" + year + \"_Irrigated_winter2013.shp\")\n",
    "\n",
    "#get the transform and projection of our gtiff\n",
    "transform, projection = transform_tuple(class_predict, (class_predict.x, class_predict.y), epsg=3577)\n",
    "#find the width and height of the xarray dataset we want to mask\n",
    "width,height = class_predict.shape\n",
    "# rasterize vector\n",
    "gdf_raster = SpatialTools.rasterize_vector(results + AOI + \"_\" + year + \"_Irrigated_winter2013.shp\",\n",
    "                                           height, width, transform, projection, raster_path=results + AOI + \"_\" + year + \"_Irrigated_winter2013.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(gdf_raster, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
