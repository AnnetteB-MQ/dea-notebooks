{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing a time-weighted dynamic time warping algorithm\n",
    "This scripts generates and exports data for the testing, along with a training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get some data and export netcdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import dask\n",
    "import datacube \n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from datacube.storage import masking\n",
    "from datacube.utils import geometry\n",
    "\n",
    "import fiona\n",
    "import rasterio.features\n",
    "from osgeo import gdal, ogr\n",
    "import os\n",
    "from rsgislib.segmentation import segutils\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "#import custom functions\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "import DEAPlotting, SpatialTools, BandIndices\n",
    "from load_data import load_data\n",
    "from transform_tuple import transform_tuple\n",
    "from imageSeg import imageSeg\n",
    "from query_from_shp import query_from_shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where is your data and results folder?\n",
    "data = 'data/'\n",
    "results = 'results/'\n",
    "\n",
    "sensors = ['ls7','ls8']\n",
    "\n",
    "#are we using a polygon to mask the AOI?\n",
    "polygon_mask = True\n",
    "shp_fpath = 'data/spatial/PeelR_AOI_test.shp'\n",
    "\n",
    "#If not using a polygon then enter your AOI coords\n",
    "#below:\n",
    "lat, lon = -35.125, 147.55\n",
    "latLon_adjust = 0.2\n",
    "\n",
    "#Input your area of interest's name, coords, and \n",
    "#the year you're interested in?\n",
    "AOI = 'Peel_TWDTW_test'\n",
    "year = 'Summer2018-19'\n",
    "\n",
    "time_period = ('2013-01-01', '2013-12-31')\n",
    "\n",
    "#What thresholds should I use?\n",
    "threshold = 0.8\n",
    "wofs_theshold = 0.15\n",
    "#-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a folder to keep things neat\n",
    "directory = results + AOI + \"_\" + year\n",
    "if not os.path.exists(directory):\n",
    "    os.mkdir(directory)\n",
    "\n",
    "results = results + AOI + \"_\" + year + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls7_loading...\n",
      "ls7_loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "src/load_data.py:24: FutureWarning: casting an xarray.Dataset to a boolean will change in xarray v0.11 to only include data variables, not coordinates. Cast the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n",
      "  if not landsat_ds:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls8_loading...\n",
      "ls8_loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "src/load_data.py:24: FutureWarning: casting an xarray.Dataset to a boolean will change in xarray v0.11 to only include data variables, not coordinates. Cast the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n",
      "  if not landsat_ds:\n"
     ]
    }
   ],
   "source": [
    "#load landsat data    \n",
    "\n",
    "if polygon_mask == True:\n",
    "    #set up query\n",
    "    query = query_from_shp(shp_fpath, time_period[0], time_period[1], dask_chunks = 0)\n",
    "    #landsat\n",
    "    landsat = load_data(dc_name = 'irrigated_areas', sensors=sensors,\n",
    "              export_name = data + AOI + \"_\" + year + '.nc', query=query)\n",
    "    #wofs\n",
    "    dc = datacube.Datacube(app='wofs')\n",
    "    del query['time'] \n",
    "    wofs_alltime = dc.load(product = 'wofs_summary', **query)\n",
    "\n",
    "    #masking the returned array to the polygon area\n",
    "    with fiona.open(shp_fpath) as shapes:\n",
    "            crs = geometry.CRS(shapes.crs_wkt)\n",
    "            first_geometry = next(iter(shapes))['geometry']\n",
    "            geom = geometry.Geometry(first_geometry, crs=crs)\n",
    "\n",
    "    mask = rasterio.features.geometry_mask([geom.to_crs(landsat.geobox.crs) for geoms in [geom]],\n",
    "                                               out_shape=landsat.geobox.shape,\n",
    "                                               transform=landsat.geobox.affine,\n",
    "                                               all_touched=False,\n",
    "                                               invert=True)\n",
    "    # Mask the xarrays\n",
    "    landsat = landsat.where(mask)\n",
    "    #wofs_alltime = wofs_alltime.where(mask)\n",
    "    #datacube.storage.storage.write_dataset_to_netcdf(landsat, results + AOI \"_\" + year + '.nc')\n",
    "else:\n",
    "    # Set up query\n",
    "    query = {'lon': (lon - latLon_adjust, lon + latLon_adjust),\n",
    "             'lat': (lat - latLon_adjust, lat + latLon_adjust),\n",
    "             'time': time_period}\n",
    "    query['dask_chunks']= {'x': 200, 'y': 200}\n",
    "\n",
    "    #landsat\n",
    "    landsat = load_data(dc_name = 'irrigated_areas', sensors=sensors,\n",
    "              export_name = data + AOI + \"_\" + year + '.nc', query=query)\n",
    "    #wofs\n",
    "    dc = datacube.Datacube(app='wofs')\n",
    "    del query['time'] \n",
    "    wofs_alltime = dc.load(product = 'wofs_summary', **query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The formula we are using is (nir - swir1)/(nir + swir1)\n"
     ]
    }
   ],
   "source": [
    "#band indices calculation\n",
    "def ndvi_func(nir, red):\n",
    "    return ((nir - red)/(nir + red))\n",
    "\n",
    "def ndvi_ufunc(ds):\n",
    "    return xr.apply_ufunc(\n",
    "        ndvi_func, ds.nir, ds.red,\n",
    "        dask='parallelized',\n",
    "        output_dtypes=[float])\n",
    "\n",
    "NDVI_landsat = ndvi_ufunc(landsat)\n",
    "NDMI_landsat = BandIndices.calculate_indices(landsat, index='NDMI-nir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 35, x: 849, y: 837)\n",
       "Coordinates:\n",
       "  * y        (y) float64 -3.506e+06 -3.506e+06 ... -3.527e+06 -3.527e+06\n",
       "  * x        (x) float64 1.759e+06 1.759e+06 1.759e+06 ... 1.78e+06 1.78e+06\n",
       "  * time     (time) datetime64[ns] 2013-01-04T23:45:15.500000 ... 2013-12-30T23:50:30\n",
       "Data variables:\n",
       "    NDVI     (time, y, x) float64 nan nan nan nan nan ... nan nan nan nan nan\n",
       "    NDMI     (time, y, x) float64 nan nan nan nan nan ... nan nan nan nan nan\n",
       "Attributes:\n",
       "    crs:      EPSG:3577"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expprt band indices for exploration\n",
    "\n",
    "x = NDVI_landsat.to_dataset(name='NDVI')\n",
    "y = NDMI_landsat.to_dataset(name='NDMI')\n",
    "a = xr.merge([x,y])\n",
    "a.attrs=dict(crs=landsat.crs)\n",
    "\n",
    "#datacube.storage.storage.write_dataset_to_netcdf(a, results + AOI + \"_\" + year + 'bandIndices.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 4, x: 849, y: 837)\n",
       "Coordinates:\n",
       "  * y        (y) float64 -3.506e+06 -3.506e+06 ... -3.527e+06 -3.527e+06\n",
       "  * x        (x) float64 1.759e+06 1.759e+06 1.759e+06 ... 1.78e+06 1.78e+06\n",
       "  * time     (time) datetime64[ns] 2013-02-28 2013-05-31 2013-08-31 2013-11-30\n",
       "Data variables:\n",
       "    NDVI     (time, y, x) float64 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
       "    NDMI     (time, y, x) float64 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpm = {'noleap': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       '365_day': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       'standard': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       'gregorian': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       'proleptic_gregorian': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       'all_leap': [0, 31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       '366_day': [0, 31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       '360_day': [0, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]}\n",
    "\n",
    "def leap_year(year, calendar='standard'):\n",
    "    \"\"\"Determine if year is a leap year\"\"\"\n",
    "    leap = False\n",
    "    if ((calendar in ['standard', 'gregorian',\n",
    "        'proleptic_gregorian', 'julian']) and\n",
    "        (year % 4 == 0)):\n",
    "        leap = True\n",
    "        if ((calendar == 'proleptic_gregorian') and\n",
    "            (year % 100 == 0) and\n",
    "            (year % 400 != 0)):\n",
    "            leap = False\n",
    "        elif ((calendar in ['standard', 'gregorian']) and\n",
    "                 (year % 100 == 0) and (year % 400 != 0) and\n",
    "                 (year < 1583)):\n",
    "            leap = False\n",
    "    return leap\n",
    "\n",
    "def get_dpm(time, calendar='standard'):\n",
    "    \"\"\"\n",
    "    return a array of days per month corresponding to the months provided in `months`\n",
    "    \"\"\"\n",
    "    month_length = np.zeros(len(time), dtype=np.int)\n",
    "\n",
    "    cal_days = dpm[calendar]\n",
    "\n",
    "    for i, (month, year) in enumerate(zip(time.month, time.year)):\n",
    "        month_length[i] = cal_days[month]\n",
    "        if leap_year(year, calendar=calendar):\n",
    "            month_length[i] += 1\n",
    "    return month_length\n",
    "\n",
    "def season_mean(ds, calendar='standard'):\n",
    "    # Make a DataArray of season/year groups\n",
    "    year_season = xr.DataArray(ds.time.to_index().to_period(freq='Q-NOV').to_timestamp(how='E'),\n",
    "                               coords=[ds.time], name='year_season')\n",
    "\n",
    "    # Make a DataArray with the number of days in each month, size = len(time)\n",
    "    month_length = xr.DataArray(get_dpm(ds.time.to_index(), calendar=calendar),\n",
    "                                coords=[ds.time], name='month_length')\n",
    "    # Calculate the weights by grouping by 'time.season'\n",
    "    weights = month_length.groupby('time.season') / month_length.groupby('time.season').sum()\n",
    "\n",
    "    # Test that the sum of the weights for each season is 1.0\n",
    "    np.testing.assert_allclose(weights.groupby('time.season').sum().values, np.ones(4))\n",
    "\n",
    "    # Calculate the weighted average\n",
    "    return (ds * weights).groupby('time.season').sum(dim='time'), year_season\n",
    "\n",
    "b, c = season_mean(a)\n",
    "time = (np.unique(c.values))[0:4]\n",
    "b = b.assign_coords(season = time)\n",
    "b = b.rename({'season':'time'})\n",
    "\n",
    "#b.attrs=dict(crs=landsat.crs)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.to_netcdf(results + AOI + \"_\" + year + 'SeasonalbandIndices.nc')\n",
    "#datacube.storage.storage.write_dataset_to_netcdf(b, results + AOI + \"_\" + year + 'SeasonalbandIndices.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2013-02-28T00:00:00.000000000', '2013-05-31T00:00:00.000000000',\n",
       "       '2013-08-31T00:00:00.000000000', '2013-11-30T00:00:00.000000000'],\n",
       "      dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.time.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make rudimentry training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "peel_landuse = gpd.read_file('data/spatial/Peel_landuse_small.shp')\n",
    "peel_landuse = peel_landuse.to_crs(epsg=3577)\n",
    "\n",
    "peel_trainset = peel_landuse[(peel_landuse.d_Tertiary == '4.3.0 Irrigated cropping') | \n",
    "                        (peel_landuse.d_Tertiary == '3.3.0 Cropping') |\n",
    "                        (peel_landuse.d_Tertiary == '5.4.1 Urban residential')]\n",
    "\n",
    "peel_trainset.d_Tertiary.unique()\n",
    "\n",
    "def getXY(pt):\n",
    "    return (pt.x, pt.y)\n",
    "centroidseries = peel_trainset['geometry'].centroid\n",
    "lon,lat = [list(t) for t in zip(*map(getXY, centroidseries))]\n",
    "\n",
    "from datetime import datetime\n",
    "start = datetime(2013,1,1)\n",
    "finish =datetime(2013,12,31)\n",
    "\n",
    "dict_ = {'longitude': lon, 'latitude': lat, 'from': start,'to':finish, 'label':peel_trainset.d_Tertiary}\n",
    "peel_samples = pd.DataFrame(dict_)\n",
    "\n",
    "peel_samples.to_csv('results/peel_fieldsamples.csv', index=False)\n",
    "\n",
    "peel_samples.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
