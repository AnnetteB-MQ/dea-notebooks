{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the irrigated extents MaxNDVI workflow\n",
    "\n",
    "multithreaded version below 18/4/19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from osgeo import gdal, ogr\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from rsgislib.segmentation import segutils\n",
    "from rsgislib.segmentation import tiledsegsingle\n",
    "\n",
    "import datacube \n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from datacube.storage import masking\n",
    "from datacube.utils import geometry\n",
    "\n",
    "#import custom functions\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "import DEAPlotting, SpatialTools\n",
    "from transform_tuple import transform_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "#User Inputs\n",
    "############\n",
    "\n",
    "# where are the dcStats MaxNDVI tifs?\n",
    "MaxNDVItiffs = \"/g/data/r78/cb3058/dea-notebooks/dcStats/results/mdb_NSW/New folder/maxndvi/\"\n",
    "\n",
    "# where are the dcStats NDVIArgMaxMin tifs?\n",
    "NDVIArgMaxMintiffs = \"/g/data/r78/cb3058/dea-notebooks/dcStats/results/mdb_NSW/New folder/argmaxndvi/\"\n",
    "\n",
    "# where should I put the results?\n",
    "results = '/g/data/r78/cb3058/dea-notebooks/dcStats/results/mdb_NSW/summer/previous_run/testing_mosaics/results/'\n",
    "\n",
    "#what season are we processing?\n",
    "season = 'Summer'\n",
    "\n",
    "#Input your area of interest's name\n",
    "AOI = 'rsgislibe_test_tiled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def irrigated_extent(tif):\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    print(\"starting processing of \" + tif)\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    results_ = results\n",
    "    if season == 'Summer':\n",
    "        year = tif[9:13]\n",
    "        nextyear = str(int(year) + 1)[2:] \n",
    "        year = year + \"_\" + nextyear\n",
    "        year = season + year\n",
    "        argmaxminyear = \"NDVIArgMaxMin_\" + year[6:10] + \"1101.tif\" \n",
    "    if season == 'Winter':\n",
    "        year = tif[7:11]\n",
    "        year = season + year\n",
    "        argmaxminyear = \"NDVIArgMaxMin_\" + year[6:10] + \"0501.tif\" \n",
    "\n",
    "    #Creating a folder to keep things neat\n",
    "    directory = results_ + AOI + \"_\" + year\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    results_ = results_ + AOI + \"_\" + year + \"/\"\n",
    "    \n",
    "    #inputs to GDAL and RSGISlib\n",
    "    InputNDVIStats = MaxNDVItiffs + tif\n",
    "    KEAFile = results_ + AOI + '_' + year + '.kea'\n",
    "    SegmentedKEAFile = results_ + AOI + '_' + year + '_sheperdSEG.kea'\n",
    "    meanImage = results_ + AOI + '_' + year + \"_ClumpMean.kea\"\n",
    "     \n",
    "    # Change the tiff to a kea file\n",
    "    gdal.Translate(KEAFile, InputNDVIStats, format='KEA', outputSRS='EPSG:3577')\n",
    "    \n",
    "    # Run segmentation, with creation of clump means\n",
    "#     segutils.runShepherdSegmentation(KEAFile, SegmentedKEAFile,\n",
    "#                         meanImage, numClusters=20, minPxls=100)\n",
    "\n",
    "    tiledsegsingle.performTiledSegmentation(KEAFile, SegmentedKEAFile, tmpDIR='./tiledsegtmp'+year,\n",
    "                                        tileWidth=1000, tileHeight=1000, minPxls=100)\n",
    "    \n",
    "    print('done')\n",
    "#     segment_means= xr.open_rasterio(meanImage).squeeze()\n",
    "    \n",
    "#     #reclassify and threshold by different values\n",
    "#     a = np.where(segment_means.values>=0.8, 80, segment_means)\n",
    "#     b = np.where((a>=0.75) & (a<0.8), 75, a)\n",
    "#     c = np.where((b>=0.70) & (b<0.75), 70, b)\n",
    "#     d = np.where(c>=70, c, np.nan)\n",
    "    \n",
    "#     print('exporting the multithreshold as Gtiff')\n",
    "#     transform, projection = transform_tuple(segment_means, (segment_means.x, segment_means.y), epsg=3577)\n",
    "#     #find the width and height of the xarray dataset we want to mask\n",
    "#     width,height = segment_means.shape\n",
    "    \n",
    "#     SpatialTools.array_to_geotiff(results_ + AOI + \"_\" + year + \"_multithreshold.tif\",\n",
    "#                   d, geo_transform = transform, \n",
    "#                   projection = projection, \n",
    "#                   nodata_val=np.nan)\n",
    "    \n",
    "#     #converting irrigated areas results to polygons\n",
    "#     print('converting multithreshold tiff to polygons...')\n",
    "#     multithresholdTIFF = results_ + AOI + \"_\" + year + \"_multithreshold.tif\"\n",
    "#     multithresholdPolygons = results_ + AOI + '_' + year + '_multithreshold.shp'\n",
    "    \n",
    "#     os.system('gdal_polygonize.py ' + multithresholdTIFF + ' -f' + ' ' + '\"ESRI Shapefile\"' + ' ' + multithresholdPolygons)\n",
    "    \n",
    "#     #filter by the area of the polygons to get rid of any forests etc\n",
    "#     print('filtering polygons by size, exporting, then rasterizing')\n",
    "#     gdf = gpd.read_file(multithresholdPolygons)\n",
    "#     gdf['area'] = gdf['geometry'].area\n",
    "#     smallArea = gdf['area'] <= 10000000\n",
    "#     gdf = gdf[smallArea]\n",
    "#     #export shapefile\n",
    "#     gdf.to_file(results_ + AOI + \"_\" + year + \"_Irrigated.shp\")\n",
    "    \n",
    "#     gdf_raster = SpatialTools.rasterize_vector(results_ + AOI + \"_\" + year + \"_Irrigated.shp\",\n",
    "#                                                height, width, transform, projection, raster_path=None)\n",
    "    \n",
    "#     print('loading, then masking timeof rasters')\n",
    "#     argmaxmin = xr.open_rasterio(NDVIArgMaxMintiffs+argmaxminyear)\n",
    "#     timeofmax = argmaxmin[0] \n",
    "#     timeofmin = argmaxmin[1]\n",
    "\n",
    "#     # mask timeof layers by irrigated extent\n",
    "#     timeofmax = timeofmax.where(gdf_raster)\n",
    "#     timeofmin = timeofmin.where(gdf_raster)\n",
    "\n",
    "#     # export masked timeof layers.\n",
    "#     print('exporting the timeofmaxmin Gtiffs')\n",
    "#     SpatialTools.array_to_geotiff(results_ + AOI + \"_\" + year + \"_timeofmaxNDVI.tif\",\n",
    "#                   timeofmax.values,\n",
    "#                   geo_transform = transform, \n",
    "#                   projection = projection, \n",
    "#                   nodata_val=-9999)\n",
    "\n",
    "#     SpatialTools.array_to_geotiff(results_ + AOI + \"_\" + year + \"_timeofminNDVI.tif\",\n",
    "#                   timeofmin.values,\n",
    "#                   geo_transform = transform, \n",
    "#                   projection = projection, \n",
    "#                   nodata_val=-9999)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxNDVItiffFiles = os.listdir(MaxNDVItiffs)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pool = Pool(os.cpu_count()-5)  #use 3 cpus on vdi\n",
    "    pool.map(irrigated_extent, maxNDVItiffFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxNDVItiffFiles = os.listdir(MaxNDVItiffs)\n",
    "\n",
    "irrigated_extent(maxNDVItiffFiles[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.open_rasterio('path/to/data').squeeze()\n",
    "area = np.count_nonzero(~np.isnan(data.values))*(25*25) / 10000\n",
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from osgeo import gdal, ogr\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from rsgislib.segmentation import segutils\n",
    "\n",
    "import datacube \n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from datacube.storage import masking\n",
    "from datacube.utils import geometry\n",
    "\n",
    "#import custom functions\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "import DEAPlotting, SpatialTools\n",
    "from transform_tuple import transform_tuple\n",
    "\n",
    "############\n",
    "#User Inputs\n",
    "############\n",
    "\n",
    "#how many cpus should the job be distrubuted over?\n",
    "# cpus = 8\n",
    "\n",
    "# where are the dcStats MaxNDVI tifs?\n",
    "MaxNDVItiffs = \"/g/data/r78/cb3058/dea-notebooks/dcStats/results/mdb_NSW/summer/ndvi_max/mosaics/\"\n",
    "\n",
    "# where are the dcStats NDVIArgMaxMin tifs?\n",
    "NDVIArgMaxMintiffs = \"/g/data/r78/cb3058/dea-notebooks/dcStats/results/mdb_NSW/summer/ndviArgMaxMin/mosaics\"\n",
    "\n",
    "#Is there an irrigatable area shapefile we're using for masking?\n",
    "# irrigatable_area = False\n",
    "# irrigatable_area_shp_fpath = \"/g/data/r78/cb3058/dea-notebooks/ICE_project/data/spatial/NSW_OEH_irrigated_2013.shp\"\n",
    "\n",
    "#Shapefile we're using for clipping the extent? e.g. just the northern basins\n",
    "northernBasins_shp = \"/g/data/r78/cb3058/dea-notebooks/ICE_project/data/spatial/northern_basins.shp\"\n",
    "\n",
    "# where should I put the results?\n",
    "results = '/g/data/r78/cb3058/dea-notebooks/ICE_project/results/nmdb/'\n",
    "\n",
    "#what season are we processing (Must be 'Summmer' or 'Winter')?\n",
    "season = 'Summer'\n",
    "\n",
    "#Input your area of interest's name\n",
    "AOI = 'nmdb'\n",
    "\n",
    "# script proper-----------------------------\n",
    "\n",
    "def irrigated_extent(tif):\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    print(\"starting processing of \" + tif)\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    results_ = results\n",
    "    \n",
    "    if season == 'Summer':\n",
    "        year = tif[9:13]\n",
    "        nextyear = str(int(year) + 1)[2:] \n",
    "        year = year + \"_\" + nextyear\n",
    "        year = season + year\n",
    "        argmaxminyear = \"ndviArgMaxMin_\" + year[6:10] + \"1101_mosaic.tif\" \n",
    "    if season == 'Winter':\n",
    "        year = tif[7:11]\n",
    "        year = season + year\n",
    "        argmaxminyear = \"ndviArgMaxMin_\" + year[6:10] + \"0501_mosaic.tif\" \n",
    "\n",
    "    #Creating a folder to keep things neat\n",
    "    directory = results_ + AOI + \"_\" + year\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    results_ = results_ + AOI + \"_\" + year + \"/\"\n",
    "    \n",
    "    #limiting the extent to the northern basins\n",
    "    print('clipping extent to provided polygon')\n",
    "    NDVI_max = xr.open_rasterio(MaxNDVItiffs + tif).squeeze()\n",
    "\n",
    "    transform, projection = transform_tuple(NDVI_max, (NDVI_max.x, NDVI_max.y), epsg=3577)\n",
    "    width,height = NDVI_max.shape\n",
    "\n",
    "    clip_raster = SpatialTools.rasterize_vector(northernBasins_shp, height, width,\n",
    "                                                transform, projection, raster_path=None)\n",
    "\n",
    "    NDVI_max = NDVI_max.where(clip_raster)\n",
    "    print(\"exporting clippedndvi_max geotiff\")\n",
    "    SpatialTools.array_to_geotiff(results_ + AOI + \"_\" + year + \"_NDVI_max.tif\",\n",
    "          NDVI_max.values,\n",
    "          geo_transform = transform, \n",
    "          projection = projection, \n",
    "          nodata_val = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpus=1\n",
    "maxNDVItiffFiles = os.listdir(MaxNDVItiffs)    \n",
    "pool = Pool(cpus)  \n",
    "pool.map(irrigated_extent, maxNDVItiffFiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for threaded image seg\n",
    "\n",
    "Pete's bit bucket for the function is here:\n",
    "\n",
    "https://bitbucket.org/petebunting/rsgislib/src/default/python/rsgislib/segmentation/tiledsegsingle.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threadedTiledImgSeg(imgTile):\n",
    "    baseName = os.path.splitext(os.path.basename(imgTile))[0]\n",
    "    tileID = baseName.split('_')[-1]\n",
    "    clumpsFile = os.path.join(stage1TilesSegsDIR, baseName + '_segs.kea')\n",
    "    tmpStatsJSON = os.path.join(tilesImgDIR, baseName + '_segstats.json')\n",
    "    strchStatsOutFile = strchStatsBase + \"_\" + tileID + '.txt'\n",
    "    kCentresOutFile = kCentresBase + \"_\" + tileID\n",
    "    print(clumpsFile)\n",
    "    segutils.runShepherdSegmentation(imgTile, clumpsFile, outputMeanImg=None, tmpath=os.path.join(tmpDIR,tileID+'_segstemp'), gdalformat='KEA', noStats=False, noStretch=False, noDelete=False, numClusters=numClustersVal, minPxls=minPxlsVal, distThres=distThresVal, bands=bandsVal, sampling=samplingVal, kmMaxIter=kmMaxIterVal, processInMem=False, saveProcessStats=True, imgStretchStats=strchStatsOutFile, kMeansCentres=kCentresOutFile, imgStatsJSONFile=tmpStatsJSON)\n",
    "\n",
    "    with open(tmpStatsJSON, 'r') as f:\n",
    "        jsonStrData = f.read()\n",
    "    segStatsInfo = json.loads(jsonStrData)\n",
    "    tileStatsFiles[baseName] = segStatsInfo\n",
    "    os.remove(tmpStatsJSON)\n",
    "\n",
    "pool = Pool(7)\n",
    "pool.map(threadedTiledImgSeg, imgTiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
