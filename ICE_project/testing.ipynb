{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for testing code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date of first emergence of irrigated cropping area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from rasterstats import zonal_stats\n",
    "from scipy.ndimage.morphology import binary_erosion\n",
    "from scipy.ndimage.morphology import binary_dilation\n",
    "from scipy import ndimage\n",
    "from scipy.stats import mode\n",
    "\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "import DEAPlotting, SpatialTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstyearshp = 'results/nmdb/nmdb_Summer1987_88/nmdb_Summer1987_88_Irrigated_OEHandLS_masked.shp'\n",
    "differenceFolder = 'results/nmdb_plots/shapes/difference_NMDB/'\n",
    "results = 'results/nmdb_plots/yearFirstObserved/'\n",
    "cumulative_all = \"results/nmdb_plots/shapes/interim_NMDB/NMDB_1987_2018.shp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstyear = gpd.read_file(firstyearshp)\n",
    "firstyear['firstObser'] = 1987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of NMDB difference files \n",
    "diff = []\n",
    "for file in os.listdir(differenceFolder):\n",
    "    if file.endswith(\".shp\"):\n",
    "        diff.append(os.path.join(differenceFolder, file))\n",
    "diff.sort()\n",
    "#create empty list for results\n",
    "diffwithDate = []\n",
    "#append the first year to the list\n",
    "diffwithDate.append(firstyear)\n",
    "#loop through the difference files and,\n",
    "#add a datefirstobserved column and append to lisy\n",
    "for file in diff:\n",
    "    gdf = gpd.read_file(file)\n",
    "    gdf['firstObser'] = int(file[47:51])\n",
    "    diffwithDate.append(gdf) \n",
    "#concatenate all polygons together\n",
    "x = pd.concat(diffwithDate, sort=True)\n",
    "#clean up dataframe\n",
    "x = x.reset_index()\n",
    "x = x.drop(['DN',  'index','area', 'year_range', 'catchment', 'area_diff'], axis=1)\n",
    "#export\n",
    "x.to_file(results + \"yearFirstObserved_prelim.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab any tiff to grab the dimensions \n",
    "tif = 'results/nmdb/nmdb_Summer1992_93/nmdb_Summer1992_93_multithreshold_65Thres.tif'\n",
    "a = xr.open_rasterio(tif).squeeze()\n",
    "transform, projection = SpatialTools.geotransform(a, (a.x, a.y), epsg=3577)\n",
    "width,height = a.shape\n",
    "\n",
    "#rasterize our shapefile and export as geotiff\n",
    "yfo_array = SpatialTools.rasterize_vector(results + \"yearFirstObserved_prelim.shp\",\n",
    "                                   height, width, transform, projection, field='firstObser',\n",
    "                                   raster_path=results +\"yearFirstObserved_prelim.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the final year of our cumulative union analysis, and explode\n",
    "#so we have individual polygons\n",
    "gdf = gpd.read_file(cumulative_all)\n",
    "gdf = gdf.explode()\n",
    "gdf = gdf.reset_index(drop=True)\n",
    "gdf = gdf.drop(['DN','area', 'year_range', 'catchment'], axis=1)\n",
    "gdf.to_file(results+'exploded_cumulativeAll.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rasterize the exploded polygons\n",
    "tif = results +\"yearFirstObserved_prelim.tif\"\n",
    "a = xr.open_rasterio(tif).squeeze()\n",
    "transform, projection = SpatialTools.geotransform(a, (a.x, a.y), epsg=3577)\n",
    "width,height = a.shape\n",
    "\n",
    "#rasterize our shapefile and keep it as numpy array\n",
    "explodedGDF_raster = SpatialTools.rasterize_vector(results+'exploded_cumulativeAll.shp',\n",
    "                                   height, width, transform, projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "binary_dilation() got an unexpected keyword argument 'iteration'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-98d660ba4d47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#erode, then dilate the numpy array to help seperate adjacent polygons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0meroded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_erosion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplodedGDF_raster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdilated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_dilation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meroded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m SpatialTools.array_to_geotiff(results+'cumulativeAll_erodeDilate.tif',\n",
      "\u001b[0;31mTypeError\u001b[0m: binary_dilation() got an unexpected keyword argument 'iteration'"
     ]
    }
   ],
   "source": [
    "#erode, then dilate the numpy array to help seperate adjacent polygons\n",
    "eroded = binary_erosion(explodedGDF_raster, iterations=2)\n",
    "dilated = binary_dilation(eroded, iterations=1)\n",
    "#export\n",
    "SpatialTools.array_to_geotiff(results+'cumulativeAll_erodeDilate.tif',\n",
    "              eroded, geo_transform = transform, \n",
    "              projection = projection, \n",
    "              nodata_val=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polygonize the raster\n",
    "os.system('gdal_polygonize.py ' + results+\"cumulativeAll_erodeDilate.tif\" + ' -f' + ' ' + '\"ESRI Shapefile\"' + ' ' + results+\"cumulativeAll_erodeDilate.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine each polygon and assign a datefirstobserved to the majority date inside the polygon  \n",
    "gdf_final = gpd.read_file(results+\"cumulativeAll_erodeDilate.shp\")\n",
    "\n",
    "def mymajority(x):\n",
    "    \"\"\"\n",
    "    A little function for the majority filter to\n",
    "    ignore zeros when deciding on the most common\n",
    "    yearfirstobserved. Passed to 'zonal_stats'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x = x[np.nonzero(x)]\n",
    "        (values,counts) = np.unique(x,return_counts=True)\n",
    "        ind=np.nanargmax(counts)\n",
    "        return float(values[ind])\n",
    "    except ValueError:\n",
    "        return -999\n",
    "\n",
    "#zonal stats\n",
    "gdf_final['firstObser'] = pd.DataFrame(zonal_stats(vectors=gdf_final['geometry'], \n",
    "                                        raster=results+\"yearFirstObserved_prelim.tif\",\n",
    "                                        add_stats={'mymajority':mymajority}))['mymajority']\n",
    "\n",
    "#clean and export\n",
    "gdf_final = gdf_final.drop('DN', axis=1)\n",
    "gdf_final.to_file(results + \"yearFirstObserved_filtered_cleaned.shp\")\n",
    "\n",
    "# #area filter?\n",
    "# gdf_final['area'] = gdf_final['geometry'].area\n",
    "# gdf_final = gdf_final[gdf_final.area<500000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could use simplify for display purposes\n",
    "# z = gdf_final.copy()\n",
    "# z_simplified = z.copy()\n",
    "# z_simplified[\"geometry\"] = z.geometry.simplify(tolerance=50,preserve_topology=True)\n",
    "# z_simplified.to_file(results+'simplified_exploded_cumulativeAll.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplifying polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely.geometry import asShape\n",
    "from shapely.geometry import MultiLineString\n",
    "from shapely.geometry import asLineString\n",
    "from shapely.wkt import dumps\n",
    "#from pprint import pprint\n",
    "\n",
    "import shapefile\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('src/')\n",
    "import bezier\n",
    "import bendsimplify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = \"results/SICA/nmdb_Summer1998_99_Irrigated_OEHandLS_masked.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nothihng seems to happen...\n",
    "bendsimplify.bend_simplify(\"results/nmdb_Summer1998_99_Irrigated_OEHandLS_masked_objectID.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works but is not topologically aware so overlaps/slivers occur (if not\n",
    "# for important analysis then could use overlay to remove overlaps)\n",
    "gdf = gpd.read_file(shape)\n",
    "gdf_simplified = gdf.copy()\n",
    "gdf_simplified[\"geometry\"] = gdf.geometry.simplify(tolerance=50,preserve_topology=True)\n",
    "gdf.to_file(\"results/test_simplify_1998_99_tolerance50_shapely.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
