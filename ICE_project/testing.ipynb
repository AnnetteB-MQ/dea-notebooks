{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the irrigated extents MaxNDVI workflow\n",
    "\n",
    "multithreaded version below 18/4/19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "#User Inputs\n",
    "############\n",
    "\n",
    "# where are the dcStats MaxNDVI tifs?\n",
    "MaxNDVItiffs = \"/g/data/r78/cb3058/dea-notebooks/dcStats/results/mdb_NSW/New folder/maxndvi/\"\n",
    "\n",
    "# where are the dcStats NDVIArgMaxMin tifs?\n",
    "NDVIArgMaxMintiffs = \"/g/data/r78/cb3058/dea-notebooks/dcStats/results/mdb_NSW/New folder/argmaxndvi/\"\n",
    "\n",
    "# where should I put the results?\n",
    "results = '/g/data/r78/cb3058/dea-notebooks/dcStats/results/mdb_NSW/summer/previous_run/testing_mosaics/results/'\n",
    "\n",
    "#what season are we processing?\n",
    "season = 'Summer'\n",
    "\n",
    "#Input your area of interest's name\n",
    "AOI = 'rsgislibe_test_tiled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pathos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bbfb4d8c41bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpathos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcessingPool\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pathos'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def irrigated_extent(tif):\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    print(\"starting processing of \" + tif)\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    results_ = results\n",
    "    if season == 'Summer':\n",
    "        year = tif[9:13]\n",
    "        nextyear = str(int(year) + 1)[2:] \n",
    "        year = year + \"_\" + nextyear\n",
    "        year = season + year\n",
    "        argmaxminyear = \"NDVIArgMaxMin_\" + year[6:10] + \"1101.tif\" \n",
    "    if season == 'Winter':\n",
    "        year = tif[7:11]\n",
    "        year = season + year\n",
    "        argmaxminyear = \"NDVIArgMaxMin_\" + year[6:10] + \"0501.tif\" \n",
    "\n",
    "    #Creating a folder to keep things neat\n",
    "    directory = results_ + AOI + \"_\" + year\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    results_ = results_ + AOI + \"_\" + year + \"/\"\n",
    "    \n",
    "    #inputs to GDAL and RSGISlib\n",
    "    InputNDVIStats = MaxNDVItiffs + tif\n",
    "    KEAFile = results_ + AOI + '_' + year + '.kea'\n",
    "    SegmentedKEAFile = results_ + AOI + '_' + year + '_sheperdSEG.kea'\n",
    "    meanImage = results_ + AOI + '_' + year + \"_ClumpMean.kea\"\n",
    "     \n",
    "    # Change the tiff to a kea file\n",
    "    gdal.Translate(KEAFile, InputNDVIStats, format='KEA', outputSRS='EPSG:3577')\n",
    "    \n",
    "    # Run segmentation, with creation of clump means\n",
    "#     segutils.runShepherdSegmentation(KEAFile, SegmentedKEAFile,\n",
    "#                         meanImage, numClusters=20, minPxls=100)\n",
    "\n",
    "    tiledsegsingle.performTiledSegmentation(KEAFile, SegmentedKEAFile, tmpDIR='tmps/tiledsegtmp'+year,\n",
    "                                        tileWidth=1000, tileHeight=1000, minPxls=100)\n",
    "    \n",
    "    print('done')\n",
    "#     segment_means= xr.open_rasterio(meanImage).squeeze()\n",
    "    \n",
    "#     #reclassify and threshold by different values\n",
    "#     a = np.where(segment_means.values>=0.8, 80, segment_means)\n",
    "#     b = np.where((a>=0.75) & (a<0.8), 75, a)\n",
    "#     c = np.where((b>=0.70) & (b<0.75), 70, b)\n",
    "#     d = np.where(c>=70, c, np.nan)\n",
    "    \n",
    "#     print('exporting the multithreshold as Gtiff')\n",
    "#     transform, projection = transform_tuple(segment_means, (segment_means.x, segment_means.y), epsg=3577)\n",
    "#     #find the width and height of the xarray dataset we want to mask\n",
    "#     width,height = segment_means.shape\n",
    "    \n",
    "#     SpatialTools.array_to_geotiff(results_ + AOI + \"_\" + year + \"_multithreshold.tif\",\n",
    "#                   d, geo_transform = transform, \n",
    "#                   projection = projection, \n",
    "#                   nodata_val=np.nan)\n",
    "    \n",
    "#     #converting irrigated areas results to polygons\n",
    "#     print('converting multithreshold tiff to polygons...')\n",
    "#     multithresholdTIFF = results_ + AOI + \"_\" + year + \"_multithreshold.tif\"\n",
    "#     multithresholdPolygons = results_ + AOI + '_' + year + '_multithreshold.shp'\n",
    "    \n",
    "#     os.system('gdal_polygonize.py ' + multithresholdTIFF + ' -f' + ' ' + '\"ESRI Shapefile\"' + ' ' + multithresholdPolygons)\n",
    "    \n",
    "#     #filter by the area of the polygons to get rid of any forests etc\n",
    "#     print('filtering polygons by size, exporting, then rasterizing')\n",
    "#     gdf = gpd.read_file(multithresholdPolygons)\n",
    "#     gdf['area'] = gdf['geometry'].area\n",
    "#     smallArea = gdf['area'] <= 10000000\n",
    "#     gdf = gdf[smallArea]\n",
    "#     #export shapefile\n",
    "#     gdf.to_file(results_ + AOI + \"_\" + year + \"_Irrigated.shp\")\n",
    "    \n",
    "#     gdf_raster = SpatialTools.rasterize_vector(results_ + AOI + \"_\" + year + \"_Irrigated.shp\",\n",
    "#                                                height, width, transform, projection, raster_path=None)\n",
    "    \n",
    "#     print('loading, then masking timeof rasters')\n",
    "#     argmaxmin = xr.open_rasterio(NDVIArgMaxMintiffs+argmaxminyear)\n",
    "#     timeofmax = argmaxmin[0] \n",
    "#     timeofmin = argmaxmin[1]\n",
    "\n",
    "#     # mask timeof layers by irrigated extent\n",
    "#     timeofmax = timeofmax.where(gdf_raster)\n",
    "#     timeofmin = timeofmin.where(gdf_raster)\n",
    "\n",
    "#     # export masked timeof layers.\n",
    "#     print('exporting the timeofmaxmin Gtiffs')\n",
    "#     SpatialTools.array_to_geotiff(results_ + AOI + \"_\" + year + \"_timeofmaxNDVI.tif\",\n",
    "#                   timeofmax.values,\n",
    "#                   geo_transform = transform, \n",
    "#                   projection = projection, \n",
    "#                   nodata_val=-9999)\n",
    "\n",
    "#     SpatialTools.array_to_geotiff(results_ + AOI + \"_\" + year + \"_timeofminNDVI.tif\",\n",
    "#                   timeofmin.values,\n",
    "#                   geo_transform = transform, \n",
    "#                   projection = projection, \n",
    "#                   nodata_val=-9999)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxNDVItiffFiles = os.listdir(MaxNDVItiffs)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pool = Pool(os.cpu_count()-5)  #use 3 cpus on vdi\n",
    "    pool.map(irrigated_extent, maxNDVItiffFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxNDVItiffFiles = os.listdir(MaxNDVItiffs)\n",
    "\n",
    "irrigated_extent(maxNDVItiffFiles[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.open_rasterio('path/to/data').squeeze()\n",
    "area = np.count_nonzero(~np.isnan(data.values))*(25*25) / 10000\n",
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate list of inputs for GNU parallel\n",
    "import os\n",
    "maxNDVItiffFiles = os.listdir(\"/g/data/r78/cb3058/dea-notebooks/dcStats/results/renmark\")\n",
    "maxNDVItiffFiles.sort()\n",
    "with open('renmark_maxNDVItiffFiles.txt', 'w') as f:\n",
    "    for item in maxNDVItiffFiles:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff = \"/g/data1a/r78/cb3058/dea-notebooks/ICE_project/results/renmark/renmark_Summer2016_17/renmark_Summer2016_17_multithreshold_irrigated.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_max_Irrigated = xr.open_rasterio(tiff).squeeze()\n",
    "# NDVI_max_Irrigated.plot(figsize=(20,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width,height = NDVI_max_Irrigated.shape\n",
    "transform, projection = transform_tuple(NDVI_max_Irrigated, (NDVI_max_Irrigated.x, NDVI_max_Irrigated.y), epsg=3577)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove pixels that cross over the major rivers in the region\n",
    "rivers_raster = SpatialTools.rasterize_vector(\"data/spatial/major_rivers_aus.shp\", height, width, transform, projection, raster_path=None)\n",
    "rivers_raster = rivers_raster.astype(bool)\n",
    "from scipy.ndimage.morphology import binary_dilation as bd\n",
    "rivers_raster = bd(rivers_raster)\n",
    "\n",
    "rivers_raster = xr.DataArray(rivers_raster, coords = [NDVI_max_Irrigated.y, NDVI_max_Irrigated.x], dims = ['y', 'x'], name='rivers')\n",
    "masked_irr = NDVI_max_Irrigated.where(rivers_raster == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_irr.plot(figsize=(20,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.count_nonzero((~np.isnan(masked_irr.values)))\n",
    "area = (ones*(25*25)) / 1000000\n",
    "print(str(area) + \" km2 was under irrigated cultivation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.count_nonzero((~np.isnan(NDVI_max_Irrigated.values)))\n",
    "area = (ones*(25*25)) / 1000000\n",
    "print(str(area) + \" km2 was under irrigated cultivation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, projection = transform_tuple(a, (a.x, a.y), epsg=3577)\n",
    "#find the width and height of the xarray dataset we want to mask\n",
    "width,height = a.shape\n",
    "\n",
    "SpatialTools.array_to_geotiff(\"/g/data/r78/cb3058/dea-notebooks/ICE_project/results/renmark/renmark_Summer2015_16/renmark_Summer2015_16_ClumpMean.tif\",\n",
    "              a.values, geo_transform = transform, \n",
    "              projection = projection, \n",
    "              nodata_val=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from osgeo import gdal, ogr\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from rsgislib.segmentation import segutils\n",
    "\n",
    "import datacube \n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from datacube.storage import masking\n",
    "from datacube.utils import geometry\n",
    "\n",
    "#import custom functions\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "import DEAPlotting, SpatialTools\n",
    "from transform_tuple import transform_tuple\n",
    "\n",
    "############\n",
    "#User Inputs\n",
    "############\n",
    "\n",
    "#how many cpus should the job be distrubuted over?\n",
    "# cpus = 8\n",
    "\n",
    "# where are the dcStats MaxNDVI tifs?\n",
    "MaxNDVItiffs = \"/g/data/r78/cb3058/dea-notebooks/dcStats/results/mdb_NSW/summer/ndvi_max/mosaics/\"\n",
    "\n",
    "# where are the dcStats NDVIArgMaxMin tifs?\n",
    "NDVIArgMaxMintiffs = \"/g/data/r78/cb3058/dea-notebooks/dcStats/results/mdb_NSW/summer/ndviArgMaxMin/mosaics\"\n",
    "\n",
    "#Is there an irrigatable area shapefile we're using for masking?\n",
    "# irrigatable_area = False\n",
    "# irrigatable_area_shp_fpath = \"/g/data/r78/cb3058/dea-notebooks/ICE_project/data/spatial/NSW_OEH_irrigated_2013.shp\"\n",
    "\n",
    "#Shapefile we're using for clipping the extent? e.g. just the northern basins\n",
    "northernBasins_shp = \"/g/data/r78/cb3058/dea-notebooks/ICE_project/data/spatial/northern_basins.shp\"\n",
    "\n",
    "# where should I put the results?\n",
    "results = '/g/data/r78/cb3058/dea-notebooks/ICE_project/results/nmdb/'\n",
    "\n",
    "#what season are we processing (Must be 'Summmer' or 'Winter')?\n",
    "season = 'Summer'\n",
    "\n",
    "#Input your area of interest's name\n",
    "AOI = 'nmdb'\n",
    "\n",
    "# script proper-----------------------------\n",
    "\n",
    "def irrigated_extent(tif):\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    print(\"starting processing of \" + tif)\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    results_ = results\n",
    "    \n",
    "    if season == 'Summer':\n",
    "        year = tif[9:13]\n",
    "        nextyear = str(int(year) + 1)[2:] \n",
    "        year = year + \"_\" + nextyear\n",
    "        year = season + year\n",
    "        argmaxminyear = \"ndviArgMaxMin_\" + year[6:10] + \"1101_mosaic.tif\" \n",
    "    if season == 'Winter':\n",
    "        year = tif[7:11]\n",
    "        year = season + year\n",
    "        argmaxminyear = \"ndviArgMaxMin_\" + year[6:10] + \"0501_mosaic.tif\" \n",
    "\n",
    "    #Creating a folder to keep things neat\n",
    "    directory = results_ + AOI + \"_\" + year\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    results_ = results_ + AOI + \"_\" + year + \"/\"\n",
    "    \n",
    "    #limiting the extent to the northern basins\n",
    "    print('clipping extent to provided polygon')\n",
    "    NDVI_max = xr.open_rasterio(MaxNDVItiffs + tif).squeeze()\n",
    "\n",
    "    transform, projection = transform_tuple(NDVI_max, (NDVI_max.x, NDVI_max.y), epsg=3577)\n",
    "    width,height = NDVI_max.shape\n",
    "\n",
    "    clip_raster = SpatialTools.rasterize_vector(northernBasins_shp, height, width,\n",
    "                                                transform, projection, raster_path=None)\n",
    "\n",
    "    NDVI_max = NDVI_max.where(clip_raster)\n",
    "    print(\"exporting clippedndvi_max geotiff\")\n",
    "    SpatialTools.array_to_geotiff(results_ + AOI + \"_\" + year + \"_NDVI_max.tif\",\n",
    "          NDVI_max.values,\n",
    "          geo_transform = transform, \n",
    "          projection = projection, \n",
    "          nodata_val = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpus=1\n",
    "maxNDVItiffFiles = os.listdir(MaxNDVItiffs)    \n",
    "pool = Pool(cpus)  \n",
    "pool.map(irrigated_extent, maxNDVItiffFiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for threaded image seg\n",
    "\n",
    "Pete's bit bucket for the function is here:\n",
    "\n",
    "https://bitbucket.org/petebunting/rsgislib/src/default/python/rsgislib/segmentation/tiledsegsingle.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threadedTiledImgSeg(imgTile):\n",
    "    baseName = os.path.splitext(os.path.basename(imgTile))[0]\n",
    "    tileID = baseName.split('_')[-1]\n",
    "    clumpsFile = os.path.join(stage1TilesSegsDIR, baseName + '_segs.kea')\n",
    "    tmpStatsJSON = os.path.join(tilesImgDIR, baseName + '_segstats.json')\n",
    "    strchStatsOutFile = strchStatsBase + \"_\" + tileID + '.txt'\n",
    "    kCentresOutFile = kCentresBase + \"_\" + tileID\n",
    "    print(clumpsFile)\n",
    "    segutils.runShepherdSegmentation(imgTile, clumpsFile, outputMeanImg=None, tmpath=os.path.join(tmpDIR,tileID+'_segstemp'), gdalformat='KEA', noStats=False, noStretch=False, noDelete=False, numClusters=numClustersVal, minPxls=minPxlsVal, distThres=distThresVal, bands=bandsVal, sampling=samplingVal, kmMaxIter=kmMaxIterVal, processInMem=False, saveProcessStats=True, imgStretchStats=strchStatsOutFile, kMeansCentres=kCentresOutFile, imgStatsJSONFile=tmpStatsJSON)\n",
    "\n",
    "    with open(tmpStatsJSON, 'r') as f:\n",
    "        jsonStrData = f.read()\n",
    "    segStatsInfo = json.loads(jsonStrData)\n",
    "    tileStatsFiles[baseName] = segStatsInfo\n",
    "    os.remove(tmpStatsJSON)\n",
    "\n",
    "pool = Pool(7)\n",
    "pool.map(threadedTiledImgSeg, imgTiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
