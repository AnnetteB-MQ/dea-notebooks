{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "from datacube.storage import masking\n",
    "from datacube import Datacube\n",
    "from datetime import datetime\n",
    "from skimage import exposure\n",
    "\n",
    "#load requiered modules #load r \n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "#from matplotlib import pyplot as plt #don't need unless want to plot\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gfif_full(file_name, x=1):\n",
    "\n",
    "\n",
    "    dataset = rasterio.open(file_name) #open using Raterio\n",
    "    {i: dtype for i, dtype in zip(dataset.indexes, dataset.dtypes)}\n",
    "    data_array = dataset.read(x) #read selected band into np array\n",
    "    data_xr = xr.DataArray(data_array) #turn into Xr array for fuctionality #Now don't need xr yet\n",
    "    return(data_xr) #return np array into program "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function make_classification in module sklearn.datasets.samples_generator:\n",
      "\n",
      "make_classification(n_samples=100, n_features=20, n_informative=2, n_redundant=2, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
      "    Generate a random n-class classification problem.\n",
      "    \n",
      "    This initially creates clusters of points normally distributed (std=1)\n",
      "    about vertices of an `n_informative`-dimensional hypercube with sides of\n",
      "    length `2*class_sep` and assigns an equal number of clusters to each\n",
      "    class. It introduces interdependence between these features and adds\n",
      "    various types of further noise to the data.\n",
      "    \n",
      "    Prior to shuffling, `X` stacks a number of these primary \"informative\"\n",
      "    features, \"redundant\" linear combinations of these, \"repeated\" duplicates\n",
      "    of sampled features, and arbitrary noise for and remaining features.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <sample_generators>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    n_samples : int, optional (default=100)\n",
      "        The number of samples.\n",
      "    \n",
      "    n_features : int, optional (default=20)\n",
      "        The total number of features. These comprise `n_informative`\n",
      "        informative features, `n_redundant` redundant features, `n_repeated`\n",
      "        duplicated features and `n_features-n_informative-n_redundant-\n",
      "        n_repeated` useless features drawn at random.\n",
      "    \n",
      "    n_informative : int, optional (default=2)\n",
      "        The number of informative features. Each class is composed of a number\n",
      "        of gaussian clusters each located around the vertices of a hypercube\n",
      "        in a subspace of dimension `n_informative`. For each cluster,\n",
      "        informative features are drawn independently from  N(0, 1) and then\n",
      "        randomly linearly combined within each cluster in order to add\n",
      "        covariance. The clusters are then placed on the vertices of the\n",
      "        hypercube.\n",
      "    \n",
      "    n_redundant : int, optional (default=2)\n",
      "        The number of redundant features. These features are generated as\n",
      "        random linear combinations of the informative features.\n",
      "    \n",
      "    n_repeated : int, optional (default=0)\n",
      "        The number of duplicated features, drawn randomly from the informative\n",
      "        and the redundant features.\n",
      "    \n",
      "    n_classes : int, optional (default=2)\n",
      "        The number of classes (or labels) of the classification problem.\n",
      "    \n",
      "    n_clusters_per_class : int, optional (default=2)\n",
      "        The number of clusters per class.\n",
      "    \n",
      "    weights : list of floats or None (default=None)\n",
      "        The proportions of samples assigned to each class. If None, then\n",
      "        classes are balanced. Note that if `len(weights) == n_classes - 1`,\n",
      "        then the last class weight is automatically inferred.\n",
      "        More than `n_samples` samples may be returned if the sum of `weights`\n",
      "        exceeds 1.\n",
      "    \n",
      "    flip_y : float, optional (default=0.01)\n",
      "        The fraction of samples whose class are randomly exchanged. Larger\n",
      "        values introduce noise in the labels and make the classification\n",
      "        task harder.\n",
      "    \n",
      "    class_sep : float, optional (default=1.0)\n",
      "        The factor multiplying the hypercube size.  Larger values spread\n",
      "        out the clusters/classes and make the classification task easier.\n",
      "    \n",
      "    hypercube : boolean, optional (default=True)\n",
      "        If True, the clusters are put on the vertices of a hypercube. If\n",
      "        False, the clusters are put on the vertices of a random polytope.\n",
      "    \n",
      "    shift : float, array of shape [n_features] or None, optional (default=0.0)\n",
      "        Shift features by the specified value. If None, then features\n",
      "        are shifted by a random value drawn in [-class_sep, class_sep].\n",
      "    \n",
      "    scale : float, array of shape [n_features] or None, optional (default=1.0)\n",
      "        Multiply features by the specified value. If None, then features\n",
      "        are scaled by a random value drawn in [1, 100]. Note that scaling\n",
      "        happens after shifting.\n",
      "    \n",
      "    shuffle : boolean, optional (default=True)\n",
      "        Shuffle the samples and the features.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, optional (default=None)\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    X : array of shape [n_samples, n_features]\n",
      "        The generated samples.\n",
      "    \n",
      "    y : array of shape [n_samples]\n",
      "        The integer labels for class membership of each sample.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The algorithm is adapted from Guyon [1] and was designed to generate\n",
      "    the \"Madelon\" dataset.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] I. Guyon, \"Design of experiments for the NIPS 2003 variable\n",
      "           selection benchmark\", 2003.\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    make_blobs: simplified variant\n",
      "    make_multilabel_classification: unrelated generator for multilabel tasks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(make_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda_training= pd.read_csv('/g/data/u46/users/ck9738/Datasets/training_madtrees_two.CSV.csv', usecols=(0,1,2))\n",
    "#panda_training_y = pd.read_csv('/g/data/u46/users/ck9738/Datasets/training_madtrees_one.CSV.csv', usecols=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Max Green?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>0.673635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.669357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.659658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.656174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.656103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009059</td>\n",
       "      <td>0.654314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>0.652005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006264</td>\n",
       "      <td>0.650922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>0.649112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.647981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004475</td>\n",
       "      <td>0.641900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003466</td>\n",
       "      <td>0.636750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.633685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.632788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>0.629857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>0.628369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>0.625382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.623370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004553</td>\n",
       "      <td>0.623108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003963</td>\n",
       "      <td>0.621835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.620419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>0.619851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.619388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.618807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004911</td>\n",
       "      <td>0.612521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004911</td>\n",
       "      <td>0.612521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.608233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.608233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.607085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.607085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0</td>\n",
       "      <td>0.057712</td>\n",
       "      <td>0.670502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>0.316304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006746</td>\n",
       "      <td>0.363688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007242</td>\n",
       "      <td>0.429920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.389234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>0.412979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.371302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>0.325096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.335815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>0.373499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.266447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008812</td>\n",
       "      <td>0.383474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.355610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.163848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008572</td>\n",
       "      <td>0.413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>0.442204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.422505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>0.345420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007987</td>\n",
       "      <td>0.398569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>0.316086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.356953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019827</td>\n",
       "      <td>0.479580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0</td>\n",
       "      <td>0.029213</td>\n",
       "      <td>0.546329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008934</td>\n",
       "      <td>0.405385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0</td>\n",
       "      <td>0.010223</td>\n",
       "      <td>0.417323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0</td>\n",
       "      <td>0.024303</td>\n",
       "      <td>0.506442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.338750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008959</td>\n",
       "      <td>0.424969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0</td>\n",
       "      <td>0.037611</td>\n",
       "      <td>0.615772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0</td>\n",
       "      <td>0.011049</td>\n",
       "      <td>0.524080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     classification  Variation  Max Green?\n",
       "0                 1   0.007144    0.673635\n",
       "1                 1   0.004680    0.669357\n",
       "2                 1   0.005444    0.659658\n",
       "3                 1   0.005654    0.656174\n",
       "4                 1   0.003867    0.656103\n",
       "5                 1   0.009059    0.654314\n",
       "6                 1   0.004028    0.652005\n",
       "7                 1   0.006264    0.650922\n",
       "8                 1   0.004249    0.649112\n",
       "9                 1   0.004143    0.647981\n",
       "10                1   0.004475    0.641900\n",
       "11                1   0.003466    0.636750\n",
       "12                1   0.005575    0.633685\n",
       "13                1   0.004303    0.632788\n",
       "14                1   0.005842    0.629857\n",
       "15                1   0.007390    0.628369\n",
       "16                1   0.004039    0.625382\n",
       "17                1   0.002759    0.623370\n",
       "18                1   0.004553    0.623108\n",
       "19                1   0.003963    0.621835\n",
       "20                1   0.003910    0.620419\n",
       "21                1   0.003749    0.619851\n",
       "22                1   0.004683    0.619388\n",
       "23                1   0.005360    0.618807\n",
       "24                1   0.004911    0.612521\n",
       "25                1   0.004911    0.612521\n",
       "26                1   0.002569    0.608233\n",
       "27                1   0.002569    0.608233\n",
       "28                1   0.004875    0.607085\n",
       "29                1   0.004875    0.607085\n",
       "..              ...        ...         ...\n",
       "334               0   0.057712    0.670502\n",
       "335               0   0.003471    0.316304\n",
       "336               0   0.006746    0.363688\n",
       "337               0   0.007242    0.429920\n",
       "338               0   0.008692    0.389234\n",
       "339               0   0.008455    0.412979\n",
       "340               0   0.006734    0.371302\n",
       "341               0   0.003966    0.325096\n",
       "342               0   0.002347    0.335815\n",
       "343               0   0.004234    0.373499\n",
       "344               0   0.001935    0.266447\n",
       "345               0   0.008812    0.383474\n",
       "346               0   0.005376    0.355610\n",
       "347               0   0.002322    0.163848\n",
       "348               0   0.008572    0.413500\n",
       "349               0   0.010549    0.442204\n",
       "350               0   0.011488    0.422505\n",
       "351               0   0.004336    0.345420\n",
       "352               0   0.007987    0.398569\n",
       "353               0   0.003833    0.316086\n",
       "354               0   0.007589    0.356953\n",
       "355               0   0.019827    0.479580\n",
       "356               0   0.029213    0.546329\n",
       "357               0   0.008934    0.405385\n",
       "358               0   0.010223    0.417323\n",
       "359               0   0.024303    0.506442\n",
       "360               0   0.003175    0.338750\n",
       "361               0   0.008959    0.424969\n",
       "362               0   0.037611    0.615772\n",
       "363               0   0.011049    0.524080\n",
       "\n",
       "[364 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panda_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "panda_training= pd.read_csv('/g/data/u46/users/ck9738/Datasets/training_madtrees_two.CSV.csv', usecols=(0,1,2,3))\n",
    "\n",
    "np_x = panda_training['Variation'].values.tolist()\n",
    "np_y = panda_training['Max Green?'].values.tolist()\n",
    "np_z = panda_training['Min Green?'].values.tolist()\n",
    "classification = panda_training['classification'].values.tolist()\n",
    "#create array of features to use in classifier \n",
    "how_many = len(np_y)\n",
    "how_many\n",
    "\n",
    "features = []\n",
    "\n",
    "for i in range(how_many):\n",
    "    features.append((np_x[i],np_y[i],np_z[i]))\n",
    "features\n",
    "features_array = np.asarray(features)\n",
    "\n",
    "classification_array = np.asarray(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00714351, 0.67363495, 0.62958115],\n",
       "       [0.00467985, 0.6693569 , 0.6437405 ],\n",
       "       [0.00544358, 0.6596582 , 0.6252777 ],\n",
       "       ...,\n",
       "       [0.008959  , 0.4249685 , 0.37304375],\n",
       "       [0.03761126, 0.6157719 , 0.50086665],\n",
       "       [0.01104896, 0.52407956, 0.4854343 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = LinearSVC(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.fit(features_array,classification_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method predict in module sklearn.linear_model.base:\n",
      "\n",
      "predict(X) method of sklearn.svm.classes.LinearSVC instance\n",
      "    Predict class labels for samples in X.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      "        Samples.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    C : array, shape = [n_samples]\n",
      "        Predicted class label per sample.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(classify.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variation</th>\n",
       "      <th>Max Green?</th>\n",
       "      <th>Min Green?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.617152</td>\n",
       "      <td>0.577899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.631524</td>\n",
       "      <td>0.609126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005181</td>\n",
       "      <td>0.592763</td>\n",
       "      <td>0.576217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.634920</td>\n",
       "      <td>0.617691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.632306</td>\n",
       "      <td>0.614566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004930</td>\n",
       "      <td>0.594165</td>\n",
       "      <td>0.574796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004973</td>\n",
       "      <td>0.624549</td>\n",
       "      <td>0.600419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.006759</td>\n",
       "      <td>0.631801</td>\n",
       "      <td>0.602896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.605760</td>\n",
       "      <td>0.591883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.572194</td>\n",
       "      <td>0.557420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.645427</td>\n",
       "      <td>0.625214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.640683</td>\n",
       "      <td>0.607942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.620630</td>\n",
       "      <td>0.602029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.006566</td>\n",
       "      <td>0.581410</td>\n",
       "      <td>0.551196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.006234</td>\n",
       "      <td>0.556045</td>\n",
       "      <td>0.530458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.579241</td>\n",
       "      <td>0.563017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.583668</td>\n",
       "      <td>0.571810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.008807</td>\n",
       "      <td>0.586952</td>\n",
       "      <td>0.560708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.004979</td>\n",
       "      <td>0.612027</td>\n",
       "      <td>0.599014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.575717</td>\n",
       "      <td>0.559409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.591725</td>\n",
       "      <td>0.553752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.004644</td>\n",
       "      <td>0.572053</td>\n",
       "      <td>0.558152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.571543</td>\n",
       "      <td>0.549095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.540407</td>\n",
       "      <td>0.525689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.005404</td>\n",
       "      <td>0.444524</td>\n",
       "      <td>0.434616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.005689</td>\n",
       "      <td>0.371019</td>\n",
       "      <td>0.381827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.005182</td>\n",
       "      <td>0.502433</td>\n",
       "      <td>0.480800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.008928</td>\n",
       "      <td>0.432087</td>\n",
       "      <td>0.408966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.529790</td>\n",
       "      <td>0.518727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.004330</td>\n",
       "      <td>0.407616</td>\n",
       "      <td>0.405989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.012683</td>\n",
       "      <td>0.492159</td>\n",
       "      <td>0.450183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.004519</td>\n",
       "      <td>0.351051</td>\n",
       "      <td>0.362528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.011277</td>\n",
       "      <td>0.431066</td>\n",
       "      <td>0.417268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.345072</td>\n",
       "      <td>0.357085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.006805</td>\n",
       "      <td>0.419681</td>\n",
       "      <td>0.415021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.009357</td>\n",
       "      <td>0.390249</td>\n",
       "      <td>0.375655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.029312</td>\n",
       "      <td>0.522249</td>\n",
       "      <td>0.451085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.005116</td>\n",
       "      <td>0.333217</td>\n",
       "      <td>0.324775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.003480</td>\n",
       "      <td>0.322996</td>\n",
       "      <td>0.340958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.006613</td>\n",
       "      <td>0.379041</td>\n",
       "      <td>0.376901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.013970</td>\n",
       "      <td>0.439026</td>\n",
       "      <td>0.418069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.010754</td>\n",
       "      <td>0.480935</td>\n",
       "      <td>0.464092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.003348</td>\n",
       "      <td>0.311514</td>\n",
       "      <td>0.323047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.339562</td>\n",
       "      <td>0.351173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.009308</td>\n",
       "      <td>0.420021</td>\n",
       "      <td>0.405808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.043521</td>\n",
       "      <td>0.583052</td>\n",
       "      <td>0.468598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.415175</td>\n",
       "      <td>0.421646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.011408</td>\n",
       "      <td>0.440254</td>\n",
       "      <td>0.419434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.010004</td>\n",
       "      <td>0.419870</td>\n",
       "      <td>0.416893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.035475</td>\n",
       "      <td>0.485622</td>\n",
       "      <td>0.301235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.336674</td>\n",
       "      <td>0.354397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.006727</td>\n",
       "      <td>0.343729</td>\n",
       "      <td>0.365277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.003451</td>\n",
       "      <td>0.335413</td>\n",
       "      <td>0.337533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.024303</td>\n",
       "      <td>0.506442</td>\n",
       "      <td>0.447684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.019548</td>\n",
       "      <td>0.416857</td>\n",
       "      <td>0.351756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.005728</td>\n",
       "      <td>0.347218</td>\n",
       "      <td>0.371202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.017171</td>\n",
       "      <td>0.515260</td>\n",
       "      <td>0.476767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.309806</td>\n",
       "      <td>0.317139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.004978</td>\n",
       "      <td>0.369770</td>\n",
       "      <td>0.372842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.007375</td>\n",
       "      <td>0.429309</td>\n",
       "      <td>0.425953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Variation  Max Green?  Min Green?\n",
       "0    0.005142    0.617152    0.577899\n",
       "1    0.005405    0.631524    0.609126\n",
       "2    0.005181    0.592763    0.576217\n",
       "3    0.005624    0.634920    0.617691\n",
       "4    0.003853    0.632306    0.614566\n",
       "5    0.004930    0.594165    0.574796\n",
       "6    0.004973    0.624549    0.600419\n",
       "7    0.006759    0.631801    0.602896\n",
       "8    0.003467    0.605760    0.591883\n",
       "9    0.003521    0.572194    0.557420\n",
       "10   0.004161    0.645427    0.625214\n",
       "11   0.006937    0.640683    0.607942\n",
       "12   0.003950    0.620630    0.602029\n",
       "13   0.006566    0.581410    0.551196\n",
       "14   0.006234    0.556045    0.530458\n",
       "15   0.003692    0.579241    0.563017\n",
       "16   0.003418    0.583668    0.571810\n",
       "17   0.008807    0.586952    0.560708\n",
       "18   0.004979    0.612027    0.599014\n",
       "19   0.003216    0.575717    0.559409\n",
       "20   0.006173    0.591725    0.553752\n",
       "21   0.004644    0.572053    0.558152\n",
       "22   0.005308    0.571543    0.549095\n",
       "23   0.002747    0.540407    0.525689\n",
       "24   0.005404    0.444524    0.434616\n",
       "25   0.005689    0.371019    0.381827\n",
       "26   0.005182    0.502433    0.480800\n",
       "27   0.008928    0.432087    0.408966\n",
       "28   0.003784    0.529790    0.518727\n",
       "29   0.004330    0.407616    0.405989\n",
       "..        ...         ...         ...\n",
       "50   0.012683    0.492159    0.450183\n",
       "51   0.004519    0.351051    0.362528\n",
       "52   0.011277    0.431066    0.417268\n",
       "53   0.004113    0.345072    0.357085\n",
       "54   0.006805    0.419681    0.415021\n",
       "55   0.009357    0.390249    0.375655\n",
       "56   0.029312    0.522249    0.451085\n",
       "57   0.005116    0.333217    0.324775\n",
       "58   0.003480    0.322996    0.340958\n",
       "59   0.006613    0.379041    0.376901\n",
       "60   0.013970    0.439026    0.418069\n",
       "61   0.010754    0.480935    0.464092\n",
       "62   0.003348    0.311514    0.323047\n",
       "63   0.003894    0.339562    0.351173\n",
       "64   0.009308    0.420021    0.405808\n",
       "65   0.043521    0.583052    0.468598\n",
       "66   0.007591    0.415175    0.421646\n",
       "67   0.011408    0.440254    0.419434\n",
       "68   0.010004    0.419870    0.416893\n",
       "69   0.035475    0.485622    0.301235\n",
       "70   0.002907    0.336674    0.354397\n",
       "71   0.006727    0.343729    0.365277\n",
       "72   0.003451    0.335413    0.337533\n",
       "73   0.024303    0.506442    0.447684\n",
       "74   0.019548    0.416857    0.351756\n",
       "75   0.005728    0.347218    0.371202\n",
       "76   0.017171    0.515260    0.476767\n",
       "77   0.004662    0.309806    0.317139\n",
       "78   0.004978    0.369770    0.372842\n",
       "79   0.007375    0.429309    0.425953\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.random.randint(1,high=20,size=(15,10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 100)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_test = test.reshape(15,100)\n",
    "flat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 10, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1000, 1000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_file = '/g/data/u46/users/dxr251/woody-v6/woody_60_-149.tif'\n",
    "\n",
    "sample_data = load_gfif_full(sample_file, x=(1,2,3))\n",
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_stack = sample_data.reshape(3,1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1000000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (dim_0: 3, dim_1: 1000, dim_2: 1000)>\n",
       "array([[[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]]], dtype=float32)\n",
       "Dimensions without coordinates: dim_0, dim_1, dim_2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
