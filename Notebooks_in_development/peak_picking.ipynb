{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just run this box once with 'Shift'+'Enter'. It loads all the things you need to work with the data. \n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import datacube\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.dates\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "from datacube.utils import geometry \n",
    "from datacube.utils.geometry import CRS\n",
    "from datacube.storage import masking\n",
    "from datacube.helpers import ga_pq_fuser, write_geotiff\n",
    "\n",
    "sys.path.append('../Scripts/')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='datacube')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter your variables in the box below and choose values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barmah choke: \n",
    "lat = -35.92\n",
    "lon = 145.00\n",
    "buffer = 10000\n",
    "\n",
    "Boundary Bend:\n",
    "lat = -34.71966901\n",
    "lon = 143.1698626\n",
    "buffer = 10000\n",
    "\n",
    "Niemur:\n",
    "lat = -35.277\n",
    "lon = 144.3477\n",
    "buffer = 5500\n",
    "\n",
    "Macquarie Marshes:\n",
    "lat = -30.8072\n",
    "lon = 147.5149\n",
    "buffer = 10000\n",
    "\n",
    "Gunbower:\n",
    "lat = -35.942574\n",
    "lon = 144.46466\n",
    "buffer = 10000\n",
    "\n",
    "Wee Wai:\n",
    "lat = -30.2033\n",
    "lon = 149.4361\n",
    "buffer = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What are the latitudes and longtitudes of the area you want to make a picture of?\n",
    "lat = -34.71966901\n",
    "lon = 143.1698626\n",
    "buffer = 7000\n",
    "#Where abouts is your csv file located on your computer?\n",
    "csv_file_location = 'Boundary_Bend.csv'\n",
    "\n",
    "#Loading and organising guage data\n",
    "gauge_data = pd.read_csv(csv_file_location,\n",
    "                error_bad_lines = False, skiprows=9, escapechar='#', \n",
    "                         parse_dates=['Timestamp'], #Tells it this column is date format\n",
    "                         index_col=('Timestamp'),\n",
    "                        date_parser=lambda x: pd.to_datetime(x.rsplit('+', 1)[0]))\n",
    "gauge_data = gauge_data.dropna()\n",
    "\n",
    "gauge_data = gauge_data.drop(columns='Interpolation Type')\n",
    "gauge_data = gauge_data.drop(columns='Quality Code')\n",
    "gauge_data.plot(y='Value', figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What discharge level range do you want to look at?\n",
    "yaxis_lower_parameter = 300\n",
    "yaxis_higher_parameter = 2500\n",
    "\n",
    "#Dask loading wofs_albers data\n",
    "x, y = geometry.point(lon, lat, CRS('WGS84')).to_crs(CRS('EPSG:3577')).points[0]\n",
    "query = {'x': (x - buffer, x + buffer),\n",
    "         'y': (y - buffer, y + buffer),    \n",
    "         'time': ('1988-01-01', '2019-08-22'), \n",
    "         'crs': 'EPSG:3577'} \n",
    "dc = datacube.Datacube(app='dc-WOfS')\n",
    "wofs_albers= dc.load(product = 'wofs_albers', dask_chunks = {}, group_by='solar_day', **query)\n",
    "\n",
    "#convert Pandas dataframe to xArray for merging with WOfS\n",
    "gauge_data_xr = gauge_data.to_xarray() \n",
    "\n",
    "#this is the xArray merge function\n",
    "merged_data = gauge_data_xr.interp(Timestamp=wofs_albers.time) \n",
    "\n",
    "#Now define the passes to load based on user input\n",
    "specified_satellite_passes = merged_data.where((merged_data.Value > yaxis_lower_parameter) & \n",
    "                                    (merged_data.Value < yaxis_higher_parameter), drop=True)\n",
    "specified_satellite_passes = specified_satellite_passes.drop('Timestamp')\n",
    "\n",
    "#Check how many passes you are about to load. I recommend loading 100 to 400 passes.\n",
    "specified_satellite_passes  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load satellite data so you can cloud mask it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of dates for the for-loop to load\n",
    "date_list = specified_satellite_passes.time.values\n",
    "\n",
    "#Re-do query without time\n",
    "x, y = geometry.point(lon, lat, CRS('WGS84')).to_crs(CRS('EPSG:3577')).points[0]\n",
    "query = {'x': (x - buffer, x + buffer),\n",
    "         'y': (y - buffer, y + buffer), \n",
    "         'crs': 'EPSG:3577'} \n",
    "\n",
    "#loop selecting data based on user input\n",
    "xr_list = []\n",
    "for date in date_list:\n",
    "    date = str(date)  \n",
    "    wofs_albers= dc.load(product = 'wofs_albers', time=date,  **query)\n",
    "    xr_list.append(wofs_albers)\n",
    "specified_passes = xr.concat(xr_list, dim='time')\n",
    "\n",
    "#Cloud Mask\n",
    "ClearTimesteps = []\n",
    "for ix, timestep in enumerate(specified_passes.time):\n",
    "    SingleTime = specified_passes.water.isel(time=ix)\n",
    "    IsItCloudy = masking.make_mask(SingleTime, cloud=True)\n",
    "    CountClouds = IsItCloudy.sum()   \n",
    "    PercentCloudy = CountClouds.values.item()/(len(specified_passes.x)*len(specified_passes.y))*100\n",
    "    IsItClearEnough = PercentCloudy <= 20  \n",
    "    if IsItClearEnough:\n",
    "        ClearTimesteps.append(ix)     \n",
    "clear_specified_passes = specified_passes.water.isel(time = ClearTimesteps)\n",
    "#See how many clear passes you got. I would recommend to have at least 50 for this application:\n",
    "clear_specified_passes.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use pandas to merge the clear satellite data with the gauge data and plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now take the clear passes and make it into a pandas dataframe that lists time of clear passes and corresponding gauge value\n",
    "clear_specified_passes_pd = clear_specified_passes.time.to_dataframe()\n",
    "clear_specified_passes_pd = clear_specified_passes_pd.rename(columns = {'time': 'date'})#can't have 2 columns called 'time' for the merge\n",
    "merged_data_pd = merged_data.to_dataframe()\n",
    "\n",
    "#Merge clear satellite passes with gauge data by the time dimension\n",
    "clear_merged_data = pd.merge(clear_specified_passes_pd, merged_data_pd, left_on= 'time', \n",
    "                            right_index=True, how='inner')\n",
    "clear_merged_data = clear_merged_data.drop(columns='date')\n",
    "clear_merged_data = clear_merged_data.drop(columns='Timestamp')\n",
    "\n",
    "#Plot the clear satellite passes over the hydrograph\n",
    "ax = clear_merged_data.plot(marker = 'o', color='red', linestyle = 'None', figsize=(18,10))\n",
    "plt.axhspan(yaxis_lower_parameter, yaxis_higher_parameter, color='red', alpha=0.2)\n",
    "plt.ylabel('cubic meters per second (daily)')\n",
    "gauge_data.plot(ax=ax, color='blue')\n",
    "ax.legend([\"clear_merged_data\", \"gauge_data\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use scipy.signal to pick peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "xx = gauge_data.values.ravel()\n",
    "pp,_ = scipy.signal.find_peaks(xx, height=500, width=20, distance=100)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(18, 6))\n",
    "ax.plot(xx, 'b-')\n",
    "ax.plot(pp, xx[pp], 'rs');\n",
    "plt.axhspan(yaxis_lower_parameter, yaxis_higher_parameter, color='red', alpha=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xx = gauge_data.values.ravel() - yaxis_lower_parameter\n",
    "hi = xx > 0\n",
    "lo = xx <= 0\n",
    "crosses_up = lo[:-1] * hi[1:] \n",
    "crosses_lo = hi[:-1]*lo[1:]\n",
    "\n",
    "crosses_up = np.hstack([crosses_up, np.r_[False]])\n",
    "crosses_lo = np.hstack([crosses_lo, np.r_[False]])\n",
    "\n",
    "ii = np.arange(0, xx.shape[0])\n",
    "fig, ax = plt.subplots(1, figsize=(17,4))\n",
    "ax.plot(ii, xx, '-', \n",
    "        ii[crosses_up], xx[crosses_up] , 'gs',\n",
    "        ii[crosses_lo], xx[crosses_lo] , 'mo',\n",
    "\n",
    "        ii[pp], xx[pp], 'rs'\n",
    "       );\n",
    "\n",
    "#green squares are called crosses_up\n",
    "#purple circles are called crosses_lo\n",
    "#Red squares are called pp\n",
    "#Hydrograph data (blue line) is called gauge_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
