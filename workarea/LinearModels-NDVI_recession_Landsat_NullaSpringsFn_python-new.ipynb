{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running linear models on DEA indices using Sentinel\n",
    "\n",
    "**Background:** This document presents an example of applying a linear model to analyse Landsat data extracted from Digital Earth Australia (DEA) to make inferences about physical processes. Here we are testing the rate of decline in vegetation condition during the dry season in NW Australia. Rainfall in this part of Australia is highly seasonal. During the dry season (April to October) there is very little rain and we assume that soil moisture declines throughout.\n",
    "\n",
    "A common approach for assessing the likelihood of vegetation being dependent on groundwater is applying the 'green island' principle. This involves inferring gorudnwater use from vegetation that maintains higher condition during dry periods. In our area of interest, we expect that vegetation condition will decline much more rapidly in vegetation communities that are wholly reliant on surface water compared to communities that access groundwater (i.e. groundwater dependent ecosystems). We use NDVI as a proxy for vegetation condition.\n",
    "\n",
    "\n",
    "**What does this document do?**\n",
    "\n",
    "- Retrieve Landsat data for temporal and spatial extents\n",
    "- Calculate NDVI and groupby months\n",
    "- Demonstrate how to build a linear model to analyse the rate of decay in NDVI throughout the dry season\n",
    "- Plot linear model parameters and use spatial patterns to infer distribuition of potential GDEs\n",
    "\n",
    "**Requirements**\n",
    "\n",
    "You need to run the following commands from the command line prior to launching jupyter notebooks from the same terminal so that the required libraries and paths are set:\n",
    "\n",
    "`module use /g/data/v10/public/modules/modulefiles` \n",
    "\n",
    "`module load dea`\n",
    "\n",
    "If you find an error or bug in this notebook, please either create an 'Issue' in the Github repository, or fix it yourself and create a 'Pull' request to contribute the updated notebook back into the repository (See the repository [README](https://github.com/GeoscienceAustralia/dea-notebooks/blob/master/README.rst) for instructions on creating a Pull request).\n",
    "\n",
    "**Date**: June 2019\n",
    "\n",
    "**Authors**: Neil Symington, Robbi Bishop-Taylor, Bex Dunn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Tags: :index:`NDVI`, :index:`regression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Landsat data\n",
    "Here we import data Landsat data from the DEA. In our experience using the larger number of observations decreases our signal-to-noise ration and thus enables us to resolve landscape features at a higher resolution. Hence, for the actual data product we used the entire landsat archive and ran the processing through the raijin supercomputer.  However for this example we will only consider data from 2009-2019 from landsat 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import warnings\n",
    "import datacube\n",
    "import matplotlib.pyplot as plt\n",
    "from datacube.storage import masking\n",
    "from datacube.helpers import write_geotiff\n",
    "import calendar\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "sys.path.append('/g/data/zk34/pxk547/old_dea-notebooks/10_Scripts/')\n",
    "import DEADataHandling, DEAPlotting\n",
    "\n",
    "# Dictoinary for mapping month number to months names \n",
    "mnths =dict((k,v) for k,v in enumerate(calendar.month_name) if k!= 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Connect to a datacube\n",
    "dc = datacube.Datacube(app='LinearModels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def linregress_3D(x, y):\n",
    "    \"\"\"\n",
    "    \n",
    "    Input: Two xr.Datarrays of any dimensions with the first dim being time. \n",
    "    Thus the input data could be a 1D time series, or for example, have three \n",
    "    dimensions (time,lat,lon). \n",
    "    Datasets can be provided in any order, but note that the regression slope \n",
    "    and intercept will be calculated for y with respect to x.\n",
    "    Output: Covariance, correlation, regression slope and intercept, p-value, \n",
    "    and standard error on regression between the two datasets along their \n",
    "    aligned time dimension.  \n",
    "    \"\"\" \n",
    "    # Ensure that the data are properly aligned to each other. \n",
    "    x,y = xr.align(x,y)\n",
    "\n",
    "    \n",
    "    #Compute data length, mean and standard deviation along time axis: \n",
    "    n = y.notnull().sum(dim='month')\n",
    "    xmean = x.mean(axis=0)\n",
    "    ymean = y.mean(axis=0)\n",
    "    xstd  = x.std(axis=0)\n",
    "    ystd  = y.std(axis=0)\n",
    "\n",
    "    #4. Compute covariance along time axis\n",
    "    cov   =  np.sum((x - xmean)*(y - ymean), axis=0)/(n)\n",
    "\n",
    "    #5. Compute correlation along time axis\n",
    "    cor   = cov/(xstd*ystd)\n",
    "\n",
    "    #6. Compute regression slope and intercept:\n",
    "    LRslope    = cov/(xstd**2)\n",
    "    LRintercept = ymean - xmean*LRslope  \n",
    "\n",
    "    #7. Compute P-value and standard error\n",
    "    #Compute t-statistics\n",
    "    tstats = cor*np.sqrt(n-2)/np.sqrt(1-cor**2)\n",
    "    stderr = LRslope/tstats\n",
    "\n",
    "    from scipy.stats import t\n",
    "    pval   = t.sf(tstats, n-2)*2\n",
    "    pval   = xr.DataArray(pval, dims=cor.dims, coords=cor.coords)\n",
    "\n",
    "    return cov,cor,LRslope,LRintercept,pval,stderr\n",
    "\n",
    "def regression_pixel_drill_ndvi(x, y, ax, slope, intercept, scatter_kwargs = None,\n",
    "                          plot_kwargs = None):\n",
    "    \"\"\"\n",
    "    Function  for plotting regression points and line on an axis\n",
    "    @param x: x coordinate\n",
    "    @param y: y coordinate\n",
    "    @param ax: matplotlib axis\n",
    "    @param scatter_kwargs: matplotlib keyword arguments for a scatter plot\n",
    "    @param plot_kwargs: matplotlib keyword arguments for a plot\n",
    "    \"\"\"\n",
    "    ndvi_pt = ndvi_dry.sel(x = x, y = y,\n",
    "                           method = 'nearest').values\n",
    "    months = ndvi_dry.month.values\n",
    "    \n",
    "    ax.scatter(months, ndvi_pt, **scatter_kwargs)\n",
    "    \n",
    "    # Get the slope and intercepth\n",
    "    \n",
    "    slope_ = slope.sel(x = x, y = y,\n",
    "                       method = 'nearest').values\n",
    "    \n",
    "    intercept_ = intercept.sel(x = x, y = y,\n",
    "                       method = 'nearest').values\n",
    "    # Add a line to the graph\n",
    "    \n",
    "    xs = np.array([months[0], months[-1]])\n",
    "\n",
    "    ys = np.array([slope_*v + intercept_ for v in xs])\n",
    "    \n",
    "    # Plot the line on the axis\n",
    "    \n",
    "    ax.plot(xs, ys, **plot_kwargs)\n",
    "    \n",
    "def regression_pixel_drill_ndmi(x, y, ax, slope, intercept, scatter_kwargs = None,\n",
    "                          plot_kwargs = None):\n",
    "    \"\"\"\n",
    "    Function  for plotting regression points and line on an axis\n",
    "    @param x: x coordinate\n",
    "    @param y: y coordinate\n",
    "    @param ax: matplotlib axis\n",
    "    @param scatter_kwargs: matplotlib keyword arguments for a scatter plot\n",
    "    @param plot_kwargs: matplotlib keyword arguments for a plot\n",
    "    \"\"\"\n",
    "    ndmi_pt = ndmi_dry.sel(x = x, y = y,\n",
    "                           method = 'nearest').values\n",
    "    months = ndmi_dry.month.values\n",
    "    \n",
    "    ax.scatter(months, ndmi_pt, **scatter_kwargs)\n",
    "        \n",
    "    slope_ = slope.sel(x = x, y = y,\n",
    "                       method = 'nearest').values\n",
    "    \n",
    "    intercept_ = intercept.sel(x = x, y = y,\n",
    "                       method = 'nearest').values\n",
    "    # Add a line to the graph\n",
    "    \n",
    "    xs = np.array([months[0], months[-1]])\n",
    "\n",
    "    ys = np.array([slope_*v + intercept_ for v in xs])\n",
    "    \n",
    "    # Plot the line on the axis\n",
    "    \n",
    "    ax.plot(xs, ys, **plot_kwargs)\n",
    "    \n",
    "def regression_pixel_drill_ndwi(x, y, ax, slope, intercept, scatter_kwargs = None,\n",
    "                          plot_kwargs = None):\n",
    "    \"\"\"\n",
    "    Function  for plotting regression points and line on an axis\n",
    "    @param x: x coordinate\n",
    "    @param y: y coordinate\n",
    "    @param ax: matplotlib axis\n",
    "    @param scatter_kwargs: matplotlib keyword arguments for a scatter plot\n",
    "    @param plot_kwargs: matplotlib keyword arguments for a plot\n",
    "    \"\"\"\n",
    "    ndwi_pt = ndwi_dry.sel(x = x, y = y,\n",
    "                           method = 'nearest').values\n",
    "    months = ndwi_dry.month.values\n",
    "    \n",
    "    ax.scatter(months, ndwi_pt, **scatter_kwargs)\n",
    "    \n",
    "    # Get the slope and intercepth\n",
    "    \n",
    "    slope_ = slope.sel(x = x, y = y,\n",
    "                       method = 'nearest').values\n",
    "    \n",
    "    intercept_ = intercept.sel(x = x, y = y,\n",
    "                       method = 'nearest').values\n",
    "    # Add a line to the graph\n",
    "    \n",
    "    xs = np.array([months[0], months[-1]])\n",
    "\n",
    "    ys = np.array([slope_*v + intercept_ for v in xs])\n",
    "    \n",
    "    # Plot the line on the axis\n",
    "    \n",
    "    ax.plot(xs, ys, **plot_kwargs)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spatial and temporal query\n",
    "\n",
    "#query to do with Nulla area\n",
    "#query = {'lat': (-20.06, -19.6),\n",
    "#         'lon': (144.95, 146.0),\n",
    "#         'time':('1990-01-10', '2019-01-10')}\n",
    "\n",
    "#spring in Nulla area\n",
    "query = {'lat': (-19.786, -19.6765),\n",
    "         'lon': (145.32, 145.42),\n",
    "         'time':('2015-10-22', '2019-01-10')}\n",
    "\n",
    "#'time':('1980-01-01', '2019-01-10')}\n",
    "\n",
    "# Define query coordinate reference system\n",
    "\n",
    "query['crs'] = 'EPSG:4326'\n",
    "query['output_crs'] = 'EPSG:28355'\n",
    "query['resolution'] = (25.,25.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for the specified query extent using `dc.load`:\n",
    "ds = dc.load(product='ls8_nbar_albers', group_by='solar_day', **query\n",
    "            )\n",
    "#ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding code in to extract cloud free data only (from stacked plot script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ls5\n",
      "    Skipping ls5; no valid data for query\n",
      "Loading ls7\n",
      "    Ignoring SLC-off observations for ls7\n",
      "    Skipping ls7; no valid data for query\n",
      "Loading ls8\n",
      "    Loading 41 filtered ls8 timesteps\n",
      "Returning ls8 data\n",
      "    Replacing invalid -999 values with NaN (data will be coerced to float32)\n"
     ]
    }
   ],
   "source": [
    "#set cloudmasking threshold and load landsat nbart data\n",
    "landsat_masked_prop = 0.90\n",
    "ls578_ds = DEADataHandling.load_clearlandsat(dc=dc, query=query, product='nbart', masked_prop=landsat_masked_prop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls578_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls578_ds.isel(time=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the rgb image\n",
    "\n",
    "#ls578_ds[['blue','green', 'red']].isel(time=10).to_array().plot.imshow(robust=True, figsize=(8,8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our study area is the margin of a sandy, unconfined aquifer system to the south and mud flats to the north. In the middle of the area are a number of 'islands' of thick vegetation (dark green). We want to assess the likelihood of these communities having some degree of groudnwater water dependence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate NDVI and NDMI\n",
    "\n",
    "ndvi = ((ls578_ds.nir - ls578_ds.red)/(ls578_ds.nir + ls578_ds.red))\n",
    "ndmi = ((ls578_ds.nir - ls578_ds.swir2)/(ls578_ds.nir + ls578_ds.swir2))\n",
    "ndwi = ((ls578_ds.green - ls578_ds.nir)/(ls578_ds.green + ls578_ds.nir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting NDVI\n",
    "\n",
    "# Make a plot for each month\n",
    "\n",
    "To investigate the difference in vegetation condition we plot the median and standard devation ndvi for each month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run trend analysis\n",
    "\n",
    "From the median plots it appears that the vegetation condition declines from about April until January. This is somewhat counter intuitive given that we expect rains in December January. The very high standard deviation in the wet months suggest we may be getting some influence of spurious measurements, perhaps from cloud shadow and/ or surface water.\n",
    "\n",
    "From this we decide the best way to test vegetation is to use April to November. UB looking at figures, more July - November (so 7 - 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (time: 22, y: 489, x: 425)>\n",
      "array([[[0.412961, 0.420809, ..., 0.372372, 0.356964],\n",
      "        [0.395556, 0.406872, ..., 0.412495, 0.374777],\n",
      "        ...,\n",
      "        [0.429423, 0.408592, ..., 0.255975, 0.245333],\n",
      "        [0.434952, 0.431266, ..., 0.234171, 0.227508]],\n",
      "\n",
      "       [[0.296703, 0.33632 , ..., 0.339012, 0.319767],\n",
      "        [0.314507, 0.305091, ..., 0.374492, 0.353719],\n",
      "        ...,\n",
      "        [0.337365, 0.316083, ..., 0.200706, 0.193024],\n",
      "        [0.401429, 0.351077, ..., 0.188488, 0.178754]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.272832, 0.271993, ..., 0.355774, 0.336281],\n",
      "        [0.259087, 0.249718, ..., 0.382462, 0.374966],\n",
      "        ...,\n",
      "        [0.288594, 0.268155, ..., 0.26257 , 0.243416],\n",
      "        [0.282903, 0.275968, ..., 0.251239, 0.234292]],\n",
      "\n",
      "       [[0.260188, 0.305171, ..., 0.344441, 0.321503],\n",
      "        [0.245993, 0.240754, ..., 0.379334, 0.359673],\n",
      "        ...,\n",
      "        [0.247748, 0.270377, ..., 0.268923, 0.255108],\n",
      "        [0.308475, 0.277922, ..., 0.255086, 0.242243]]], dtype=float32)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2016-05-16T00:16:45.500000 ... 2018-10-29T00:17:06\n",
      "  * y        (y) float64 7.811e+06 7.811e+06 7.811e+06 ... 7.824e+06 7.824e+06\n",
      "  * x        (x) float64 3.239e+05 3.239e+05 3.239e+05 ... 3.345e+05 3.345e+05\n",
      "<xarray.DataArray (month: 6, y: 489, x: 425)>\n",
      "array([[[0.405901, 0.41696 , ..., 0.470322, 0.474692],\n",
      "        [0.388027, 0.393143, ..., 0.499909, 0.489291],\n",
      "        ...,\n",
      "        [0.442593, 0.418008, ..., 0.343305, 0.329162],\n",
      "        [0.459112, 0.444503, ..., 0.335242, 0.30266 ]],\n",
      "\n",
      "       [[0.376359, 0.42167 , ..., 0.539568, 0.541161],\n",
      "        [0.360515, 0.371971, ..., 0.571571, 0.563737],\n",
      "        ...,\n",
      "        [0.491651, 0.502113, ..., 0.307558, 0.294185],\n",
      "        [0.504651, 0.510327, ..., 0.280813, 0.263444]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.277468, 0.281381, ..., 0.351694, 0.33427 ],\n",
      "        [0.260734, 0.250859, ..., 0.380257, 0.373586],\n",
      "        ...,\n",
      "        [0.283262, 0.27071 , ..., 0.261835, 0.249865],\n",
      "        [0.28997 , 0.275553, ..., 0.247199, 0.226607]],\n",
      "\n",
      "       [[0.289164, 0.313066, ..., 0.337508, 0.316456],\n",
      "        [0.278818, 0.269472, ..., 0.366747, 0.347769],\n",
      "        ...,\n",
      "        [0.300075, 0.293996, ..., 0.258538, 0.248092],\n",
      "        [0.32888 , 0.306011, ..., 0.243461, 0.233257]]], dtype=float32)\n",
      "Coordinates:\n",
      "  * y        (y) float64 7.811e+06 7.811e+06 7.811e+06 ... 7.824e+06 7.824e+06\n",
      "  * x        (x) float64 3.239e+05 3.239e+05 3.239e+05 ... 3.345e+05 3.345e+05\n",
      "  * month    (month) int64 5 6 7 8 9 10\n"
     ]
    }
   ],
   "source": [
    "# We group the data by dry season for NDVI\n",
    "\n",
    "#dry_months = [4,5,6,7,8,9,10,1]\n",
    "dry_months = [5,6,7,8,9,10]\n",
    "\n",
    "#REtrieve the dry months\n",
    "ndvi_dryT = ndvi[ndvi['time.month'].isin(dry_months)]\n",
    "print(ndvi_dryT)\n",
    "ndvi_dry = ndvi_dryT.groupby('time.month').median(dim = 'time')\n",
    "print(ndvi_dry)\n",
    "#ndvi_dry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to extract out median NDVI image, need to have individual values, not time based\n",
    "ndvi_dry2 = ndvi_dryT.median(dim = 'time')\n",
    "#ndvi_dry2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We group the data by dry season for NDMI\n",
    "\n",
    "#dry_months = [4,5,6,7,8,9,10,11]\n",
    "dry_months = [5,6,7,8,9,10]\n",
    "\n",
    "#REtrieve the dry months\n",
    "ndmi_dryT = ndmi[ndmi['time.month'].isin(dry_months)]\n",
    "ndmi_dry = ndmi_dryT.groupby('time.month').median(dim = 'time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to extract out median NDVI image, need to have individual values, not time based\n",
    "ndmi_dry2 = ndmi_dryT.median(dim = 'time')\n",
    "#ndmi_dry2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We group the data by dry season for NDWI\n",
    "\n",
    "#dry_months = [4,5,6,7,8,9,10,11]\n",
    "dry_months = [5,6,7,8,9,10]\n",
    "\n",
    "#REtrieve the dry months\n",
    "ndwi_dry = ndwi[ndwi['time.month'].isin(dry_months)]\n",
    "ndwi_dry = ndwi_dry.groupby('time.month').median(dim = 'time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the linear regression on the monthly ndvi\n",
    "NDVIcov,NDVIcor,NDVIslope,NDVIintercept,NDVIpval,NDVIstderr = linregress_3D(ndvi_dry.month, ndvi_dry)\n",
    "NDVIr_squ = NDVIcor**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the linear regression on the monthly ndmi\n",
    "NDMIcov,NDMIcor,NDMIslope,NDMIintercept,NDMIpval,NDMIstderr = linregress_3D(ndmi_dry.month, ndmi_dry)\n",
    "NDMIr_squ = NDMIcor**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the linear regression on the monthly ndwi\n",
    "NDWIcov,NDWIcor,NDWIslope,NDWIintercept,NDWIpval,NDWIstderr = linregress_3D(ndwi_dry.month, ndwi_dry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these plots it appears that most of the veg communities have a negative slope (i.e. declining NDVI/ vegetation condition). High r-squared values suggest a strong linear relationship in these areas. However there is a spring/vegetation at the bottom ~(327875,7813000) with a positive or small negative slope and a low-rsquared. We conclude that these communities retain their condition during the dry season and thus have a greater probability of groundwater dependence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these plots it appears that most of this area has a negative slope (i.e. declining NDMI/ moisture). High r-squared values suggest a strong linear relationship in these areas. However there is an area at the bottom ~(327875,7813000) with a positive or small negative slope and a low-rsquared. We conclude that this area retains moisture during the dry season and thus have a greater probability of influence from groundwater."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting out NDVI image with 3 bands (slope, r squared, NDVI median value for dry period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate = str(ls578_ds.isel(time=0).time.values)[0:10]\n",
    "endDate = str(ls578_ds.isel(time=-1).time.values)[0:10]\n",
    "#endDate[0:4] + \" \" + endDate\n",
    "#print (\"NDVI of dry period (months \" + str(dry_months[0])+ \"-\"+str(dry_months[-1]) + \" from \"+startDate+\" to \" +endDate)\n",
    "#print ('NDVI_landsat_dry_'+startDate+'_'+endDate[0:4]+'.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your metadata file is being created\n",
      "NDVI_landsat_dry.txt has been saved to /g/data/zk34/pxk547/\n"
     ]
    }
   ],
   "source": [
    "#Export out NDVI values, slope and r-squared for dry period specified\n",
    "\n",
    "#set variable for path to save files\n",
    "savefilepath = '/g/data/zk34/pxk547/'\n",
    "\n",
    "#Exporting NDVI slope into new dataset\n",
    "NDVIslopeDS = NDVIslope.to_dataset(name='NDVI_slope')\n",
    "\n",
    "# We can now add other attributes (Rsquared) into our dataset as new data variables (can't add NDVI as has monthly values):\n",
    "\n",
    "NDVIslopeDS[\"NDVI_rsqu\"] = NDVIr_squ\n",
    "NDVIslopeDS[\"NDVI_dry_median\"] = ndvi_dry2\n",
    "#NDVIslopeDS\n",
    "\n",
    "#converting type from float64 to float32 to reduce file size\n",
    "NDVIslopeDS = NDVIslopeDS.astype(np.float32)\n",
    "#Adding CRS back into dataset\n",
    "NDVIslopeDS.attrs = ds.attrs\n",
    "#NDVIslopeDS\n",
    "\n",
    "#this writes the geotiff with 3 bands: NDVI_slope, NDVI-rsqu, NDVI_dry_median\n",
    "write_geotiff(savefilepath+'NDVI_landsat_dry_'+startDate[0:4]+'_'+endDate[0:4]+'.tif', NDVIslopeDS)\n",
    "\n",
    "#creating metadata file for NDVI_landsat_dry.tif\n",
    "print ('your metadata file is being created')\n",
    "f = open(savefilepath+\"NDVI_landsat_dry.txt\",'w')  #w - writes, r - reads; a- appends\n",
    "\n",
    "f.write(\"NDVI of dry period (months \" + str(dry_months[0])+ \"-\"+str(dry_months[-1]) + \" from \"+startDate+\" to \" +endDate+ \"\\n\" +\n",
    "        \"NDVI_slope, NDVI_rsqu and NDVI_dry_median are the 3 bands. \" + \"\\n\" +\n",
    "        \"Where slope is 0 is where NDVI values don't change much during the dry period. \" + \"\\n\" + \n",
    "        \"Where rsqu is 1 is where correlation is high between months, therefore no variation \"+ \"\\n\" + \n",
    "        \"Ndvi_dry_median is the median value of NDVI over the dry months\"+ \"\\n\" +\n",
    "        \"Can use the ndvi value to select where areas are green and intersect those \"+ \"\\n\" +\n",
    "         \"where slope is near 0 to find potential GDV sites.\")\n",
    "f.write(str(ds)) #if don't have text to hand, could use this\n",
    "f.close()\n",
    "print ('NDVI_landsat_dry_'+startDate[0:4]+'_'+endDate[0:4]+'.txt has been saved to '+savefilepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting out NDMI image with 3 bands (slope, r squared, NDMI median value for dry period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your metadata file is being created\n",
      "NDMI_landsat_dry.txt has been saved to /g/data/zk34/pxk547/\n"
     ]
    }
   ],
   "source": [
    "#Exporting NDMI slope\n",
    "NDMIslopeDS = NDMIslope.to_dataset(name='slope')\n",
    "\n",
    "# We can now add other attributes (Rsquared) into our dataset as new data variables (can't add NDVI as has monthly values):\n",
    "\n",
    "NDMIslopeDS[\"NDVI_rsqu\"] = NDMIr_squ\n",
    "NDMIslopeDS[\"NDVI_dry_median\"] = ndmi_dry2\n",
    "\n",
    "#converting type from float64 to float32 to reduce file size\n",
    "NDMIslopeDS = NDMIslopeDS.astype(np.float32)\n",
    "#Adding CRS back into dataset\n",
    "NDMIslopeDS.attrs = ds.attrs\n",
    "#NDMIslopeDS\n",
    "\n",
    "write_geotiff(savefilepath+'NDMI_landsat_dry_'+startDate[0:4]+'_'+endDate[0:4]+'.tif', NDMIslopeDS)\n",
    "\n",
    "#creating metadata file for Barest Earth using same name as tif\n",
    "print ('your metadata file is being created')\n",
    "f = open(savefilepath+\"NDMI_landsat_dry.txt\",'w')  #w - writes, r - reads; a- appends\n",
    "\n",
    "f.write(\"NDMI of dry period over time with NDMI_slope, NDMI_rsqu and NDMI_dry_median as the 3 bands. \" + \"\\n\" +\n",
    "        \"Where slope is 0 is where NDMI values don't change much during the dry period. \" + \"\\n\" + \n",
    "        \"Where rsqu is 1 is where correlation is high between months, therefore no variation \"+ \"\\n\" + \n",
    "        \"NDMI_dry_median is the median value of NDMI over the dry months\"+ \"\\n\" +\n",
    "        \"Can use the ndmi value to select where areas are wet and intersect those \"+ \"\\n\" +\n",
    "         \"where slope is near 0 to find potential permanently wet sites.\")\n",
    "f.write(str(ds)) #if don't have text to hand, could use this\n",
    "f.close()\n",
    "\n",
    "print ('NDMI_landsat_dry_'+startDate[0:4]+'_'+endDate[0:4]+'.txt has been saved to '+savefilepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Our conclusion from this investigation is that there are vegetation communities in the area of interest that appear to that show statistically negligible change in condition despite prolonged dry conditions. In contrast, adjacent vegetation communities decline linearly throughout the dry season as soil moisture becomes scarce. We hypothesise that the lack of recession is due to the availability of groundwater within the root zones throughout the dry season. Follow up work including field observations and chemistry are required to validate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
