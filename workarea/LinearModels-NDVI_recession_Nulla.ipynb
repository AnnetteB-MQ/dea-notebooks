{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running linear models on DEA indices\n",
    "\n",
    "**Background:** This document presents an example of applying a linear model to analyse Landsat data extracted from Digital Earth Australia (DEA) to make inferences about physical processes. Here we are testing the rate of decline in vegetation condition during the dry season in NW Australia. Rainfall in this part of Australia is highly seasonal. During the dry season (April to October) there is very little rain and we assume that soil moisture declines throughout.\n",
    "\n",
    "A common approach for assessing the likelihood of vegetation being dependent on groundwater is applying the 'green island' principle. This involves inferring gorudnwater use from vegetation that maintains higher condition during dry periods. In our area of interest, we expect that vegetation condition will decline much more rapidly in vegetation communities that are wholly reliant on surface water compared to communities that access groundwater (i.e. groundwater dependent ecosystems). We use NDVI as a proxy for vegetation condition.\n",
    "\n",
    "\n",
    "**What does this document do?**\n",
    "\n",
    "- Retrieve Landsat data for temporal and spatial extents\n",
    "- Calculate NDVI and groupby months\n",
    "- Demonstrate how to build a linear model to analyse the rate of decay in NDVI throughout the dry season\n",
    "- Plot linear model parameters and use spatial patterns to infer distribuition of potential GDEs\n",
    "\n",
    "**Requirements**\n",
    "\n",
    "You need to run the following commands from the command line prior to launching jupyter notebooks from the same terminal so that the required libraries and paths are set:\n",
    "\n",
    "`module use /g/data/v10/public/modules/modulefiles` \n",
    "\n",
    "`module load dea`\n",
    "\n",
    "If you find an error or bug in this notebook, please either create an 'Issue' in the Github repository, or fix it yourself and create a 'Pull' request to contribute the updated notebook back into the repository (See the repository [README](https://github.com/GeoscienceAustralia/dea-notebooks/blob/master/README.rst) for instructions on creating a Pull request).\n",
    "\n",
    "**Date**: June 2019\n",
    "\n",
    "**Authors**: Neil Symington, Robbi Bishop-Taylor, Bex Dunn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Tags: :index:`NDVI`, :index:`regression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Landsat data\n",
    "Here we import data Landsat data from the DEA. In our experience using the larger number of observations decreases our signal-to-noise ration and thus enables us to resolve landscape features at a higher resolution. Hence, for the actual data product we used the entire landsat archive and ran the processing through the raijin supercomputer.  However for this example we will only consider data from 2009-2019 from landsat 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import warnings\n",
    "import datacube\n",
    "import matplotlib.pyplot as plt\n",
    "from datacube.storage import masking\n",
    "import calendar\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "sys.path.append('/home/547/pxk547/JupyterNotebooks/dea-notebooks/10_Scripts/')\n",
    "import DEADataHandling, DEAPlotting\n",
    "\n",
    "# Dictoinary for mapping month number to months names \n",
    "mnths =dict((k,v) for k,v in enumerate(calendar.month_name) if k!= 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Connect to a datacube\n",
    "dc = datacube.Datacube(app='LinearModels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def linregress_3D(x, y):\n",
    "    \"\"\"\n",
    "    \n",
    "    Input: Two xr.Datarrays of any dimensions with the first dim being time. \n",
    "    Thus the input data could be a 1D time series, or for example, have three \n",
    "    dimensions (time,lat,lon). \n",
    "    Datasets can be provided in any order, but note that the regression slope \n",
    "    and intercept will be calculated for y with respect to x.\n",
    "    Output: Covariance, correlation, regression slope and intercept, p-value, \n",
    "    and standard error on regression between the two datasets along their \n",
    "    aligned time dimension.  \n",
    "    \"\"\" \n",
    "    # Ensure that the data are properly aligned to each other. \n",
    "    x,y = xr.align(x,y)\n",
    "\n",
    "    \n",
    "    #Compute data length, mean and standard deviation along time axis: \n",
    "    n = y.notnull().sum(dim='month')\n",
    "    xmean = x.mean(axis=0)\n",
    "    ymean = y.mean(axis=0)\n",
    "    xstd  = x.std(axis=0)\n",
    "    ystd  = y.std(axis=0)\n",
    "\n",
    "    #4. Compute covariance along time axis\n",
    "    cov   =  np.sum((x - xmean)*(y - ymean), axis=0)/(n)\n",
    "\n",
    "    #5. Compute correlation along time axis\n",
    "    cor   = cov/(xstd*ystd)\n",
    "\n",
    "    #6. Compute regression slope and intercept:\n",
    "    slope     = cov/(xstd**2)\n",
    "    intercept = ymean - xmean*slope  \n",
    "\n",
    "    #7. Compute P-value and standard error\n",
    "    #Compute t-statistics\n",
    "    tstats = cor*np.sqrt(n-2)/np.sqrt(1-cor**2)\n",
    "    stderr = slope/tstats\n",
    "\n",
    "    from scipy.stats import t\n",
    "    pval   = t.sf(tstats, n-2)*2\n",
    "    pval   = xr.DataArray(pval, dims=cor.dims, coords=cor.coords)\n",
    "\n",
    "    return cov,cor,slope,intercept,pval,stderr\n",
    "\n",
    "def regression_pixel_drill(x, y, ax, scatter_kwargs = None,\n",
    "                          plot_kwargs = None):\n",
    "    \"\"\"\n",
    "    Function  for plotting regression points and line on an axis\n",
    "    @param x: x coordinate\n",
    "    @param y: y coordinate\n",
    "    @param ax: matplotlib axis\n",
    "    @param scatter_kwargs: matplotlib keyword arguments for a scatter plot\n",
    "    @param plot_kwargs: matplotlib keyword arguments for a plot\n",
    "    \"\"\"\n",
    "    ndvi_pt = ndvi_dry.sel(x = x, y = y,\n",
    "                           method = 'nearest').values\n",
    "    months = ndvi_dry.month.values\n",
    "    \n",
    "    ax.scatter(months, ndvi_pt, **scatter_kwargs)\n",
    "    \n",
    "    # Get the slope and intercepth\n",
    "    \n",
    "    slope_ = slope.sel(x = x, y = y,\n",
    "                       method = 'nearest').values\n",
    "    \n",
    "    intercept_ = intercept.sel(x = x, y = y,\n",
    "                       method = 'nearest').values\n",
    "    # Add a line to the graph\n",
    "    \n",
    "    xs = np.array([months[0], months[-1]])\n",
    "\n",
    "    ys = np.array([slope_*v + intercept_ for v in xs])\n",
    "    \n",
    "    # Plot the line on the axis\n",
    "    \n",
    "    ax.plot(xs, ys, **plot_kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spatial and temporal query\n",
    "\n",
    "\n",
    "query = {'lat': (-19.84, -19.87),\n",
    "         'lon': (145.74, 145.79),\n",
    "         'time':('2009-01-01', '2019-01-10')}\n",
    "\n",
    "# Define query coordinate reference system\n",
    "\n",
    "query['crs'] = 'EPSG:4326'\n",
    "query['output_crs'] = 'EPSG:28355'\n",
    "query['resolution'] = (25.,25.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:          (time: 124, x: 211, y: 135)\n",
       "Coordinates:\n",
       "  * time             (time) datetime64[ns] 2013-04-03T00:19:01 ... 2019-01-01T00:17:04.500000\n",
       "  * y                (y) float64 7.802e+06 7.802e+06 ... 7.806e+06 7.806e+06\n",
       "  * x                (x) float64 3.681e+05 3.681e+05 ... 3.733e+05 3.733e+05\n",
       "Data variables:\n",
       "    coastal_aerosol  (time, y, x) int16 6983 7048 6979 6870 ... 541 534 554 557\n",
       "    blue             (time, y, x) int16 6643 6697 6646 6551 ... 445 438 455 464\n",
       "    green            (time, y, x) int16 6640 6642 6550 6504 ... 563 562 569 594\n",
       "    red              (time, y, x) int16 6725 6724 6642 6568 ... 479 477 500 509\n",
       "    nir              (time, y, x) int16 7140 7159 7106 7015 ... 1960 1996 2126\n",
       "    swir1            (time, y, x) int16 5026 4951 4889 4859 ... 1381 1435 1505\n",
       "    swir2            (time, y, x) int16 3551 3490 3436 3396 ... 896 897 948 959\n",
       "Attributes:\n",
       "    crs:      EPSG:28355"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data for the specified query extent using `dc.load`:\n",
    "ds = dc.load(product='ls8_nbar_albers', group_by='solar_day', **query\n",
    "            )\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding code in to extract cloud free data only (from Bex's stacked plot script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DEADataHandling' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c6c99ef3b810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#set cloudmasking threshold and load landsat nbart data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlandsat_masked_prop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.90\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m ls578_ds = DEADataHandling.load_clearlandsat(dc=dc, query=query, product='nbart',\n\u001b[0m\u001b[1;32m      4\u001b[0m         masked_prop=landsat_masked_prop)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DEADataHandling' is not defined"
     ]
    }
   ],
   "source": [
    "#set cloudmasking threshold and load landsat nbart data\n",
    "landsat_masked_prop = 0.90\n",
    "ls578_ds = DEADataHandling.load_clearlandsat(dc=dc, query=query, product='nbart',\n",
    "        masked_prop=landsat_masked_prop)\n",
    "\n",
    "\n",
    "#to load more than just landsat 8:\n",
    "#ls578_ds = DEADataHandling.load_clearlandsat(dc=dc, query=query, product='nbart',masked_prop=landsat_masked_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all nodata pixels to `NaN`:  DON\"T NEED THIS IF USING DEADataHandling as does it within code there\n",
    "#ds = masking.mask_invalid_data(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the rgb image\n",
    "\n",
    "ls578_ds[['red', 'green', 'blue']].isel(time=1).to_array().plot.imshow(robust=True, figsize=(6,6))\n",
    "\n",
    "#Neils original code: (which doesn't take out cloud)\n",
    "#ds[['red', 'green', 'blue']].isel(time=1).to_array().plot.imshow(robust=True, figsize=(6,6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our study area is the margin of a sandy, unconfined aquifer system to the south and mud flats to the north. In the middle of the area are a number of 'islands' of thick vegetation (dark green). We want to assess the likelihood of these communities having some degree of groudnwater water dependence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate NDVI\n",
    "\n",
    "ndvi = ((ls578_ds.nir - ls578_ds.red)/(ls578_ds.nir + ls578_ds.red))\n",
    "\n",
    "ndmi = ((ls578_ds.nir - ls578_ds.swir1)/(ls578_ds.nir + ls578_ds.swir1))\n",
    "#Neils original code (not using cloud free):\n",
    "#ndvi = ((ds.nir - ds.red)/(ds.nir + ds.red))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting NDVI\n",
    "\n",
    "# Make a plot for each month\n",
    "\n",
    "To investigate the difference in vegetation condition we plot the median and standard devation ndvi for each month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the figure\n",
    "fig, ax_array = plt.subplots(4,3, figsize = (8,11), sharey = True)\n",
    "\n",
    "# Colour settings\n",
    "grid_settings = {'cmap':'RdYlGn', 'vmin': 0, 'vmax': 0.75}\n",
    "\n",
    "fig.suptitle('Median monthly NDVI', fontsize = 16)\n",
    "# Iterate through the months\n",
    "for i in range(12):\n",
    "    # Assign subplots\n",
    "    row,col = int(i/3), i%3\n",
    "    \n",
    "    #PLot image\n",
    "    month_ndvi = ndvi.groupby('time.month').median(dim = 'time').isel(month = i)\n",
    "    \n",
    "    im = ax_array[row, col].imshow(month_ndvi[::-1], **grid_settings)\n",
    "    # Add title\n",
    "    ax_array[row, col].set_title(mnths[i + 1])\n",
    "\n",
    "# Add colourbar\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the figure\n",
    "fig, ax_array = plt.subplots(4,3, figsize = (8,11), sharey = True)\n",
    "\n",
    "# Colour settings\n",
    "grid_settings = {'cmap':'RdYlGn', 'vmin': -0.30, 'vmax': 0.3}\n",
    "\n",
    "fig.suptitle('Median monthly NDMI', fontsize = 16)\n",
    "# Iterate through the months\n",
    "for i in range(12):\n",
    "    # Assign subplots\n",
    "    row,col = int(i/3), i%3\n",
    "    \n",
    "    #PLot image\n",
    "    month_ndmi = ndmi.groupby('time.month').median(dim = 'time').isel(month = i)\n",
    "    \n",
    "    im = ax_array[row, col].imshow(month_ndmi[::-1], **grid_settings)\n",
    "    # Add title\n",
    "    ax_array[row, col].set_title(mnths[i + 1])\n",
    "\n",
    "# Add colourbar\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the figure\n",
    "fig, ax_array = plt.subplots(4,3, figsize = (8,11), sharey = True)\n",
    "\n",
    "# Colour settings\n",
    "grid_settings = {'cmap':'viridis', 'vmin': 0, 'vmax': 0.25}\n",
    "\n",
    "fig.suptitle('Standard deviation monthly NDVI', fontsize = 16)\n",
    "# Iterate through the months\n",
    "for i in range(12):\n",
    "    row,col = int(i/3), i%3\n",
    "    \n",
    "    #PLot image\n",
    "    month_std_ndvi = ndvi.groupby('time.month').std(dim = 'time').isel(month = i)\n",
    "\n",
    "    im = ax_array[row, col].imshow(month_std_ndvi[::-1],\n",
    "                       **grid_settings)\n",
    "    ax_array[row, col].set_title(mnths[i + 1])\n",
    "\n",
    "    \n",
    "# Add colourbar\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the figure\n",
    "fig, ax_array = plt.subplots(4,3, figsize = (8,11), sharey = True)\n",
    "\n",
    "# Colour settings\n",
    "grid_settings = {'cmap':'viridis', 'vmin': 0, 'vmax': 0.3}\n",
    "\n",
    "fig.suptitle('Standard deviation monthly NDMI', fontsize = 16)\n",
    "# Iterate through the months\n",
    "for i in range(12):\n",
    "    row,col = int(i/3), i%3\n",
    "    \n",
    "    #PLot image\n",
    "    month_std_ndmi = ndmi.groupby('time.month').std(dim = 'time').isel(month = i)\n",
    "\n",
    "    im = ax_array[row, col].imshow(month_std_ndmi[::-1],\n",
    "                       **grid_settings)\n",
    "    ax_array[row, col].set_title(mnths[i + 1])\n",
    "\n",
    "    \n",
    "# Add colourbar\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run trend analysis\n",
    "\n",
    "From the median plots it appears that the vegetation condition declines from about April until January. This is somewhat counter intuitive given that we expect rains in December January. The very high standard deviation in the wet months suggest we may be getting some influence of spurious measurements, perhaps from cloud shadow and/ or surface water.\n",
    "\n",
    "From this we decide the best way to test vegetation is to use April to November. UB looking at figures, more July - November (so 7 - 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We group the data by dry season for NDVI\n",
    "\n",
    "dry_months = [4,5,6,7,8,9,10,11]\n",
    "\n",
    "#REtrieve the dry months\n",
    "ndvi_dry = ndvi[ndvi['time.month'].isin(dry_months)]\n",
    "ndvi_dry = ndvi_dry.groupby('time.month').median(dim = 'time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We group the data by dry season for NDMI\n",
    "\n",
    "dry_months = [4,5,6,7,8,9,10,11]\n",
    "\n",
    "#REtrieve the dry months\n",
    "ndmi_dry = ndmi[ndmi['time.month'].isin(dry_months)]\n",
    "ndmi_dry = ndmi_dry.groupby('time.month').median(dim = 'time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the linear regression on the monthly ndvi\n",
    "cov,cor,slope,intercept,pval,stderr = linregress_3D(ndvi_dry.month, ndvi_dry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the linear regression on the monthly ndmi\n",
    "cov,cor,slope,intercept,pval,stderr = linregress_3D(ndmi_dry.month, ndmi_dry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the slope and correlation coefficient\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (14,4),\n",
    "                              sharey = True, sharex = True)\n",
    "\n",
    "\n",
    "im1 = slope.plot(ax = ax1, vmin = slope.min(),\n",
    "                vmax = 0.)\n",
    "ax1.set_title('Slope')\n",
    "\n",
    "\n",
    "r_squ = cor**2\n",
    "\n",
    "im2 = r_squ.plot(ax = ax2)\n",
    "ax2.set_title('r-squared')\n",
    "\n",
    "# Better\n",
    "ax1.xaxis.set_ticks(np.arange(ax1.get_xlim()[0],\n",
    "                    ax1.get_xlim()[-1],2000))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the slope and correlation coefficient for NDMI\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (14,4),\n",
    "                              sharey = True, sharex = True)\n",
    "\n",
    "\n",
    "im1 = slope.plot(ax = ax1, vmin = slope.min(),\n",
    "                vmax = 0.)\n",
    "ax1.set_title('Slope')\n",
    "\n",
    "\n",
    "r_squ = cor**2\n",
    "\n",
    "im2 = r_squ.plot(ax = ax2)\n",
    "ax2.set_title('r-squared')\n",
    "\n",
    "# Better\n",
    "ax1.xaxis.set_ticks(np.arange(ax1.get_xlim()[0],\n",
    "                    ax1.get_xlim()[-1],2000))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these plots it appears that most of the veg communities have a negative slope (i.e. declining NDVI/ vegetation condition). High r-squared values suggest a strong linear relationship in these areas. However there is a veg community at ~(463410, 8352460 )  with a positive or small negative slope and a low-rsquared. We conclude that these communities retain their condition during the dry season and thus have a greater probability of groundwater dependence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To illustrate this we plot the points and regression slope for \n",
    "\n",
    "fig, (ax1) = plt.subplots(1, figsize = (10,4), sharey = True)\n",
    "\n",
    "# First pixel is in the high recession veg community\n",
    "\n",
    "scatter_kwargs = {'c': 'r','label': 'high recession'}\n",
    "plot_kwargs = {'c': 'r'}\n",
    "\n",
    "x,y = 386200 , 7810312\n",
    "\n",
    "regression_pixel_drill(x,y, ax1, scatter_kwargs = scatter_kwargs,\n",
    "                       plot_kwargs = plot_kwargs)\n",
    "\n",
    "print('R-squared for high dry season NDVI recession = ', r_squ.sel(x = x, y = y,\n",
    "                       method = 'nearest').values)\n",
    "\n",
    "# Second pixel is in low high recession veg community\n",
    "\n",
    "scatter_kwargs = {'c': 'g','label': 'low recession'}\n",
    "plot_kwargs = {'c': 'g'}\n",
    "\n",
    "x,y = 384607,7809700\n",
    "\n",
    "regression_pixel_drill(x,y, ax1, scatter_kwargs = scatter_kwargs,\n",
    "                       plot_kwargs = plot_kwargs)\n",
    "\n",
    "print('R-squared for low dry season NDVI recession = ', r_squ.sel(x = x, y = y,\n",
    "                       method = 'nearest').values)\n",
    "\n",
    "ax1.set_xticklabels([mnths[n] for n in ax1.get_xticks()])\n",
    "\n",
    "ax1.set_ylabel('median NDVI')\n",
    "\n",
    "ax1.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1.get_xticks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Our conclusion from this investigation is that there are vegetation communities in the area of interest that appear to that show statistically negligible change in condition despite prolonged dry conditions. In contrast, adjacent vegetation communities decline linearly throughout the dry season as soil moisture becomes scarce. We hypothesise that the lack of recession is due to the availability of groundwater within the root zones throughout the dry season. Follow up work including field observations and chemistry are required to validate this."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
