{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform an image segmentation and filter and save selected polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does this notebook do?** This notebook performs an image segmentation to generate a polygon set from an input raster. We are using the [image segmentation module](https://www.rsgislib.org/rsgislib_segmentation.html) provided with the [RSGISLib python package](https://www.rsgislib.org/index.html). This package uses the segmentation algorithm of Shepherd et al. (2014), to segment an input `.kea` file. \n",
    "\n",
    "In it's current form, this workflow cheats by using `GDAL` functions at the command line. In the future, these could be changed to take advantage of the python wrappers for these functions.\n",
    "\n",
    "We use the [`rasterstats` python package](https://pythonhosted.org/rasterstats/index.html) to calculate zonal statistics for each polygon. This package allows this to be done in a single line of code. Here we only calculate the mean value of each polygon, but additional stats can be calculated if required.\n",
    "\n",
    "Finally, the segmented polygon set is filtered based on our requirements. In this example, we only choose to keep polygons where the average maximum NDVI value for the polygon is >= 0.8. The filtered polygon set is then saved to a shapefile.\n",
    "\n",
    "**Requirements**. \n",
    "* This code requires the `GDAL` library to be loaded into the environment. On the NCI, if you have loaded the `DEA` modules prior to starting this notebook, `GDAL` will be included in the imported libraries. \n",
    "* We also require the `rasterstats` python library. This is not currently part of the `DEA` library and so needs to be installed by the user. To do this, type `pip install rasterstats --user` from a terminal window on the VDI. The dependencies of this library do not interfere with the `DEA` libraries.\n",
    "\n",
    "**Date:** May 2018\n",
    "\n",
    "**Author:** Claire Krause"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`RSGISLib`, :index:`image segmentation`, :index:`shapefile`, :index:`rasterstats`, :index:`zonal_stats`, :index:`descartes`, :index:`GDAL`, :index:`plot polygons`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T01:50:49.807329Z",
     "start_time": "2018-06-01T01:50:46.912018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/dea-env/20180405/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%pylab notebook\n",
    "\n",
    "import rsgislib\n",
    "from rsgislib.segmentation import segutils\n",
    "from rsgislib.rastergis import ratutils\n",
    "from rasterstats import zonal_stats\n",
    "from descartes import PolygonPatch\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import fiona\n",
    "import json\n",
    "from fiona.crs import from_epsg\n",
    "from shapely.geometry import Polygon, shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the required input and output file names for this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T05:41:59.132321Z",
     "start_time": "2018-06-01T05:41:59.127115Z"
    }
   },
   "outputs": [],
   "source": [
    "# year = '2017'\n",
    "# nyear = int(year[-2:]) + 1\n",
    "\n",
    "# This is the .tif file to be segmented\n",
    "InputNDVIStats = '/g/data/r78/rjd547/groundwater_activities/Burdekin/SegTest/tcbgw_ub_dry_2013_ls8_grn_700.tif'\n",
    "\n",
    "# These are interim outputs for this workflow\n",
    "KEAFile = '/g/data/r78/rjd547/groundwater_activities/Burdekin/SegTest/tcbgw_ub_dry_2013_ls8_grn_700.kea'#.format(year, str(nyear))\n",
    "SegmentedKEAFile = '/g/data/r78/rjd547/groundwater_activities/Burdekin/SegTest/tcbgw_ub_dry_2013_ls8_grn_700_ShepherdSeg_Cl20.kea'#.format(year, str(nyear))\n",
    "SegmentedTiffFile = '/g/data/r78/rjd547/groundwater_activities/Burdekin/SegTest/tcbgw_ub_dry_2013_ls8_grn_700_ShepherdSeg_Cl20.tiff'#.format(year, str(nyear))\n",
    "SegmentedPolygons = '/g/data/r78/rjd547/groundwater_activities/Burdekin/SegTest/tcbgw_ub_dry_2013_ls8_grn_700'#.format(year, str(nyear))\n",
    "\n",
    "# Figure output of the final polygons\n",
    "PolygonPic = '/g/data/r78/rjd547/groundwater_activities/Burdekin/SegTest/PolygonFiltering.jpg'#.format(year, str(nyear))\n",
    "\n",
    "# This is the final output polygon set\n",
    "IrrigatedPolygonShp = '/g/data/r78/rjd547/groundwater_activities/Burdekin/SegTest/thing.shp'#.format(year, str(nyear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a .kea file for the image segmentation package\n",
    "The image segmentation package requires a `.kea` file as an input. We are using `gdal_translate` from the command line to translate a `.tiff` file to a `.kea` file. \n",
    "\n",
    "*N.B This command works with a `.tiff` file with a single input band. It has yet to be tested for a `.tiff` file containing multiple bands.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T02:10:57.490337Z",
     "start_time": "2018-06-01T02:00:17.837400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file size is 16000, 16000\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "!gdal_translate -of KEA -a_srs EPSG:3577 $InputNDVIStats $KEAFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the image segmentation with RSGISLib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `segutils.runShepherdSegmentation` function allows a reasonable degree of tuning, based on the requirements of the user. The default configuration is shown here:\n",
    "\n",
    "```\n",
    "segutils.runShepherdSegmentation(inputImg, outputClumps, outputMeanImg=None, tmpath='.', gdalformat='KEA', \n",
    "                                 noStats=False, noStretch=False, noDelete=False, numClusters=60, minPxls=100,                   \n",
    "                                 distThres=100, bands=None, sampling=100, kmMaxIter=200, processInMem=False, \n",
    "                                 saveProcessStats=False, imgStretchStats='', kMeansCentres='', \n",
    "                                 imgStatsJSONFile='')\n",
    "                                 ```\n",
    "The key parameters for this function are:\n",
    "- `inputImg`: string containing the name of the input .kea file\n",
    "- `outputClumps`: string containing the name of the output .kea file\n",
    "- `numClusters`: int which specifies the number of clusters within the KMeans clustering (default = 60)\n",
    "- `minPxls`: int which specifies the minimum number pixels within a segments (default = 100)\n",
    "- `distThres`: the distance threshold for joining the segments (default = 100)\n",
    "- `sampling`: subsampling of the image for the data used within the KMeans (default = 100; 1 = no subsampling)\n",
    "- `kMaxIter`: maximum iterations for KMeans\n",
    "\n",
    "See the [function documentation](https://www.rsgislib.org/rsgislib_segmentation.html) for additional parameter descriptions.\n",
    "\n",
    "More information about the segmentation method is available in the following paper:\n",
    "\n",
    "Daniel Clewley, Peter Bunting, James Shepherd, Sam Gillingham, Neil Flood, John Dymond, Richard Lucas, John Armston and Mahta Moghaddam. 2014. A Python-Based Open Source System for Geographic Object-Based Image Analysis (GEOBIA) Utilizing Raster Attribute Tables. Remote Sensing. Volume 6, Pages 6111-6135. http://www.mdpi.com/2072-4292/6/7/6111\n",
    "\n",
    "**For finding crop field polygons, we use 20 clusters, and 200 minimum pixels. All other options are left as default**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T04:28:34.773791Z",
     "start_time": "2018-06-01T02:10:57.493340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stretch Input Image\n",
      "Add 1 to stretched file to ensure there are no all zeros (i.e., no data) regions created.\n",
      "Create Input Image Mask.\n",
      "Mask stretched Image.\n",
      "Deleting file: ./tcbgw_ub_dry_2013_ls8_grn_700_stchdonly.kea\n",
      "Deleting file: ./tcbgw_ub_dry_2013_ls8_grn_700_stchdonlyOff.kea\n",
      "Deleting file: ./tcbgw_ub_dry_2013_ls8_grn_700_stchdmaskonly.kea\n",
      "Performing KMeans.\n",
      "Apply KMeans to image.\n",
      "Eliminate Single Pixels.\n",
      "Perform clump.\n",
      "Eliminate small pixels.\n",
      "Relabel clumps.\n",
      "Calculate image statistics and build pyramids.\n",
      "Deleting file: ./tcbgw_ub_dry_2013_ls8_grn_700_kmeansclusters.gmtxt\n",
      "Deleting file: ./tcbgw_ub_dry_2013_ls8_grn_700_kmeans.kea\n",
      "Deleting file: ./tcbgw_ub_dry_2013_ls8_grn_700_kmeans.kea.aux.xml\n",
      "Deleting file: ./tcbgw_ub_dry_2013_ls8_grn_700_kmeans_nosgl.kea\n",
      "Deleting file: ./tcbgw_ub_dry_2013_ls8_grn_700_kmeans_nosglTMP.kea\n",
      "Deleting file: ./tcbgw_ub_dry_2013_ls8_grn_700_clumps.kea\n",
      "Deleting file: ./tcbgw_ub_dry_2013_ls8_grn_700_clumps_elim.kea\n",
      "Deleting file: ./tcbgw_ub_dry_2013_ls8_grn_700_stchd.kea\n"
     ]
    }
   ],
   "source": [
    "segutils.runShepherdSegmentation(KEAFile, SegmentedKEAFile, numClusters=20, minPxls = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the output .kea file\n",
    "This can be done within a program called [`TuiView`](https://bitbucket.org/chchrsc/tuiview). To run this program, type `/g/data/v10/public/tuiview/bin/tuiview &` into a new terminal window. Basic instructions for this program can be found in the [TuiView Wiki](https://bitbucket.org/chchrsc/tuiview/wiki/Home). You can drag and drop the file into this program from the `File Browser`, and interrogate the attribute table using the `Query Tool`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate back from .kea to .tif to make the file easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T06:12:32.722130Z",
     "start_time": "2018-06-01T05:42:10.354697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file size is 16000, 16000\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!gdal_translate -of GTIFF -a_srs EPSG:3577 $SegmentedKEAFile $SegmentedTiffFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the segments from the .tif file as polygons in a shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T05:41:54.473601Z",
     "start_time": "2018-06-01T05:41:51.400428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR 4: /g/data/r78/rjd547/groundwater_activities/Burdekin/SegTest/tcbgw_ub_dry_2013_ls8_grn_700_ShepherdSeg_Cl20.tiff: No such file or directory\r\n",
      "Unable to open /g/data/r78/rjd547/groundwater_activities/Burdekin/SegTest/tcbgw_ub_dry_2013_ls8_grn_700_ShepherdSeg_Cl20.tiff\r\n"
     ]
    }
   ],
   "source": [
    "!gdal_polygonize.py $SegmentedTiffFile -f \"ESRI Shapefile\" $SegmentedPolygons MaxNDVISummer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate zonal statistics for each polygon\n",
    "\n",
    "This step requires the [`rasterstats` python package](https://pythonhosted.org/rasterstats/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T05:41:55.844157Z",
     "start_time": "2018-06-01T05:41:54.477445Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ParseException: Unknown type: '/G/DATA/R78/RJD547/GROUNDWATER_ACTIVITIES/BURDEKIN/SEGTEST/TCBGW_UB_DRY_2013_LS8_GRN_700/MAXNDVISUMMER.SHP'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't parse /g/data/r78/rjd547/groundwater_activities/Burdekin/SegTest/tcbgw_ub_dry_2013_ls8_grn_700/MaxNDVISummer.shp as a geojson Feature object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/.digitalearthau/20180405/local/lib/python3.6/site-packages/rasterstats/io.py\u001b[0m in \u001b[0;36mread_features\u001b[0;34m(obj, layer)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'type'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'FeatureCollection'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20180405/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20180405/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20180405/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f01a2b2cd039>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m polygon_stats = zonal_stats('{0}/MaxNDVISummer.shp'.format(SegmentedPolygons), InputNDVIStats, \n\u001b[0;32m----> 2\u001b[0;31m                             stats = 'mean', geojson_out = True, nodata = -9999)\n\u001b[0m",
      "\u001b[0;32m~/.digitalearthau/20180405/local/lib/python3.6/site-packages/rasterstats/main.py\u001b[0m in \u001b[0;36mzonal_stats\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0monly\u001b[0m \u001b[0mdifference\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzonal_stats\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     return a list rather than a generator.\"\"\"\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_zonal_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.digitalearthau/20180405/local/lib/python3.6/site-packages/rasterstats/main.py\u001b[0m in \u001b[0;36mgen_zonal_stats\u001b[0;34m(vectors, raster, layer, band, nodata, affine, stats, all_touched, categorical, category_map, add_stats, zone_func, raster_out, prefix, geojson_out, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mRaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mband\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrast\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mfeatures_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mgeom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geometry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.digitalearthau/20180405/local/lib/python3.6/site-packages/rasterstats/io.py\u001b[0m in \u001b[0;36mread_features\u001b[0;34m(obj, layer)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;31m# Single feature-like string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mfeatures_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparse_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'type'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'FeatureCollection'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.digitalearthau/20180405/local/lib/python3.6/site-packages/rasterstats/io.py\u001b[0m in \u001b[0;36mparse_feature\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't parse %s as a geojson Feature object\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't parse /g/data/r78/rjd547/groundwater_activities/Burdekin/SegTest/tcbgw_ub_dry_2013_ls8_grn_700/MaxNDVISummer.shp as a geojson Feature object"
     ]
    }
   ],
   "source": [
    "polygon_stats = zonal_stats('{0}/MaxNDVISummer.shp'.format(SegmentedPolygons), InputNDVIStats, \n",
    "                            stats = 'mean', geojson_out = True, nodata = -9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And plot the mean value for each polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T05:41:55.846031Z",
     "start_time": "2018-06-01T02:10:55.412Z"
    }
   },
   "outputs": [],
   "source": [
    "cmap= plt.cm.BrBG\n",
    "# create normalization instance\n",
    "norm = matplotlib.colors.Normalize(vmin=0, vmax=1) \n",
    "# create a scalarmappable from the colormap\n",
    "sm = matplotlib.cm.ScalarMappable(cmap=cmap, norm=norm)   \n",
    "sm.set_array([])  \n",
    "\n",
    "fig = plt.figure(figsize = [9,9])\n",
    "ax = fig.gca()\n",
    "for i in range(len(polygon_stats)):\n",
    "    meanVal = polygon_stats[i]['properties']['mean']\n",
    "    ax.add_patch(PolygonPatch(polygon_stats[i]['geometry'], facecolor = cmap(norm(meanVal))))\n",
    "ax.axis('scaled')\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the area of each polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T05:41:55.851032Z",
     "start_time": "2018-06-01T02:10:57.538Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(polygon_stats)):\n",
    "    polyArea = Polygon(polygon_stats[i]['geometry']['coordinates'][0]).area\n",
    "    polygon_stats[i]['properties']['area'] = polyArea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select only polygons where the mean max NDVI is >= 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T05:41:55.852384Z",
     "start_time": "2018-06-01T02:11:01.248Z"
    }
   },
   "outputs": [],
   "source": [
    "MeanValues = [polygon_stats[i]['properties']['mean'] for i in range(len(polygon_stats))]\n",
    "MeanValuesIndex = [i for i, x in enumerate(MeanValues) if x >= 0.8]\n",
    "IrrigatedPolygons = [polygon_stats[x] for x in MeanValuesIndex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And where the polygon area is less than 5,500,000 m2 (5.5 km2)\n",
    "(number chosen based on a judgement call of valid vs not-useful polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T05:41:55.853996Z",
     "start_time": "2018-06-01T02:11:02.256Z"
    }
   },
   "outputs": [],
   "source": [
    "Areas = [IrrigatedPolygons[i]['properties']['area'] for i in range(len(IrrigatedPolygons))]\n",
    "AreasIndex = [i for i, x in enumerate(Areas) if x < 5500000]\n",
    "SmallIrrigatedPolygons = [IrrigatedPolygons[x] for x in AreasIndex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And remove any polygons that overlap with a major river\n",
    "To remove erroneous riperian polygons, using [The Surface Hydrology Lines (Regional)](http://pid.geoscience.gov.au/dataset/ga/83107) dataset (2015) from Geoscience Australia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T05:41:55.855429Z",
     "start_time": "2018-06-01T02:11:03.312Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "from geopandas.tools import sjoin\n",
    "MajorRivers = gp.GeoDataFrame.from_file('/g/data/r78/cek156/dea-notebooks/SurfaceHydrologyLinesRegionalFilteredMAJOR.shp') \n",
    "\n",
    "# Grab the geometeries\n",
    "for poly in SmallIrrigatedPolygons:\n",
    "    poly['geometryold'] = poly['geometry']\n",
    "    poly['geometry'] = shape(poly['geometry'])\n",
    "    \n",
    "IrrigatedPolygons2p0 = gp.GeoDataFrame(SmallIrrigatedPolygons).set_geometry('geometry')\n",
    "Intersections= gp.sjoin(MajorRivers, IrrigatedPolygons2p0, how=\"inner\", op='intersects')\n",
    "IntersectIndex = sorted(list(set(Intersections['index_right'])))\n",
    "\n",
    "SmallFilteredIrrigatedPolygons = [SmallIrrigatedPolygons[x] for x in range(len(SmallIrrigatedPolygons)) \n",
    "                                  if x not in IntersectIndex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And plot our filtered polygon set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T05:41:55.856936Z",
     "start_time": "2018-06-01T02:11:22.212Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmap= plt.cm.BrBG\n",
    "# create normalization instance\n",
    "norm = matplotlib.colors.Normalize(vmin=0, vmax=1) \n",
    "# create a scalarmappable from the colormap\n",
    "sm = matplotlib.cm.ScalarMappable(cmap=cmap, norm=norm)   \n",
    "sm.set_array([])  \n",
    "\n",
    "label1_added = False\n",
    "label2_added = False\n",
    "label3_added = False\n",
    "\n",
    "fig = plt.figure(figsize = [9,9])\n",
    "ax = fig.gca()\n",
    "for i in range(len(IrrigatedPolygons)):\n",
    "    meanVal = IrrigatedPolygons[i]['properties']['mean']\n",
    "    if not label1_added:\n",
    "        ax.add_patch(PolygonPatch(IrrigatedPolygons[i]['geometry'], \n",
    "                                  edgecolor = 'g', facecolor = 'g', \n",
    "                                  label = 'NDVI > 0.8'))\n",
    "        label1_added = True\n",
    "    else:\n",
    "        ax.add_patch(PolygonPatch(IrrigatedPolygons[i]['geometry'], \n",
    "                                  edgecolor = 'g', facecolor = 'g'))\n",
    "for i in range(len(SmallIrrigatedPolygons)):      \n",
    "    meanVal = SmallIrrigatedPolygons[i]['properties']['mean']\n",
    "    if not label2_added:  \n",
    "        ax.add_patch(PolygonPatch(SmallIrrigatedPolygons[i]['geometry'], \n",
    "                                  edgecolor = 'dodgerblue', facecolor = 'dodgerblue',\n",
    "                                  label = 'NDVI + smaller than 5.5km2'))\n",
    "        label2_added = True\n",
    "    else:\n",
    "        ax.add_patch(PolygonPatch(SmallIrrigatedPolygons[i]['geometry'], \n",
    "                                  edgecolor = 'dodgerblue', facecolor = 'dodgerblue'))\n",
    "for i in range(len(SmallFilteredIrrigatedPolygons)):\n",
    "    meanVal = SmallFilteredIrrigatedPolygons[i]['properties']['mean']\n",
    "    if not label3_added:\n",
    "        ax.add_patch(PolygonPatch(SmallFilteredIrrigatedPolygons[i]['geometry'], \n",
    "                                  edgecolor = 'crimson', facecolor = 'crimson',\n",
    "                                  label = 'NDVI + small + doesn\\'t intersect major river'))\n",
    "        label3_added = True\n",
    "    else:\n",
    "        ax.add_patch(PolygonPatch(SmallFilteredIrrigatedPolygons[i]['geometry'], \n",
    "                                  edgecolor = 'crimson', facecolor = 'crimson'))\n",
    "ax.axis('scaled')\n",
    "plt.draw()\n",
    "plt.show()\n",
    "plt.legend()\n",
    "savefig(PolygonPic, dpi = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export our chosen polygons to a shape file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T01:18:31.631748Z",
     "start_time": "2018-06-01T01:18:31.184887Z"
    }
   },
   "outputs": [],
   "source": [
    "schema = {'geometry': 'Polygon','properties': {'mean': 'str', 'area': 'str'}}\n",
    "\n",
    "with fiona.open(IrrigatedPolygonShp, \"w\", crs = from_epsg(3577), driver = 'ESRI Shapefile', schema = schema) as output:\n",
    "    for i in range(len(SmallFilteredIrrigatedPolygons)):\n",
    "        output.write({'properties': {'mean': SmallFilteredIrrigatedPolygons[i]['properties']['mean'], \n",
    "                                     'area': SmallFilteredIrrigatedPolygons[i]['properties']['area']},\n",
    "                    'geometry': SmallFilteredIrrigatedPolygons[i]['geometryold']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
